<!DOCTYPE html>
<html lang="en" class="no-js">
    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="applicable-device" content="pc,mobile">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        
        
        
            <meta name="robots" content="max-image-preview:large">
            <meta name="access" content="Yes">

        
        <meta name="360-site-verification" content="1268d79b5e96aecf3ff2a7dac04ad990" />

        <title>Speech Enabled Reading Fluency Assessment: a Validation Study | International Journal of Artificial Intelligence in Education</title>

        
            
    
    <meta name="twitter:site" content="@SpringerLink"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Speech Enabled Reading Fluency Assessment: a Validation Study"/>
    <meta name="twitter:description" content="International Journal of Artificial Intelligence in Education - Although the ability to comprehend what one is reading is one of the most fundamental necessities to function within society, the..."/>
    <meta name="twitter:image" content="https://static-content.springer.com/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig1_HTML.png"/>
    <meta name="journal_id" content="40593"/>
    <meta name="dc.title" content="Speech Enabled Reading Fluency Assessment: a Validation Study"/>
    <meta name="dc.source" content="International Journal of Artificial Intelligence in Education 2025"/>
    <meta name="dc.format" content="text/html"/>
    <meta name="dc.publisher" content="Springer"/>
    <meta name="dc.date" content="2025-05-14"/>
    <meta name="dc.type" content="OriginalPaper"/>
    <meta name="dc.language" content="En"/>
    <meta name="dc.copyright" content="2025 The Author(s)"/>
    <meta name="dc.rights" content="2025 The Author(s)"/>
    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="dc.description" content="Although the ability to comprehend what one is reading is one of the most fundamental necessities to function within society, the reading comprehension skills of students have recently been on the decline in many countries. An essential prerequisite to reading comprehension is the ability to read fluently, which is defined as the ability to read (aloud) with accuracy, speed, automaticity and prosody. Current oral reading fluency assessment instruments seldom provide detailed diagnostics however, and bestow a heavy testing burden on practitioners. Recent developments in Artificial Intelligence-based assessment methodology might provide a solution to current assessment issues, but thorough validations of such procedures have proven scarce. This study evaluates whether valid word decoding and passage reading measures (accuracy, speed and automaticity) can be generated for a semi-transparent language, using an automatic speech recognition (ASR) based oral reading fluency assessment instrument. A validation study was conducted, using the Argument-Based Approach to Validation. Data concerned 176 h of speech data, and the results of 569 and 622 oral word- and passage reading tests that are currently administered in primary schools, from 653 children attending the second- or third grade of Dutch primary education. The results of the validation indicate that it is possible to generate fluency metrics for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument. Future researchers are advised to further optimize the ASR, evaluate its errors, and realize a prosody component, completing the envisioned reading fluency assessment instrument, thereby improving reading fluency assessment throughout primary education."/>
    <meta name="prism.issn" content="1560-4306"/>
    <meta name="prism.publicationName" content="International Journal of Artificial Intelligence in Education"/>
    <meta name="prism.publicationDate" content="2025-05-14"/>
    <meta name="prism.section" content="OriginalPaper"/>
    <meta name="prism.startingPage" content="1"/>
    <meta name="prism.endingPage" content="27"/>
    <meta name="prism.copyright" content="2025 The Author(s)"/>
    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>
    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s40593-025-00480-y"/>
    <meta name="prism.doi" content="doi:10.1007/s40593-025-00480-y"/>
    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s40593-025-00480-y.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s40593-025-00480-y"/>
    <meta name="citation_journal_title" content="International Journal of Artificial Intelligence in Education"/>
    <meta name="citation_journal_abbrev" content="Int J Artif Intell Educ"/>
    <meta name="citation_publisher" content="Springer New York"/>
    <meta name="citation_issn" content="1560-4306"/>
    <meta name="citation_title" content="Speech Enabled Reading Fluency Assessment: a Validation Study"/>
    <meta name="citation_online_date" content="2025/05/14"/>
    <meta name="citation_firstpage" content="1"/>
    <meta name="citation_lastpage" content="27"/>
    <meta name="citation_article_type" content="ARTICLE"/>
    <meta name="citation_fulltext_world_readable" content=""/>
    <meta name="citation_language" content="en"/>
    <meta name="dc.identifier" content="doi:10.1007/s40593-025-00480-y"/>
    <meta name="DOI" content="10.1007/s40593-025-00480-y"/>
    <meta name="size" content="201641"/>
    <meta name="citation_doi" content="10.1007/s40593-025-00480-y"/>
    <meta name="citation_springer_api_url" content="http://api.springer.com/xmldata/jats?q=doi:10.1007/s40593-025-00480-y&amp;api_key="/>
    <meta name="description" content="Although the ability to comprehend what one is reading is one of the most fundamental necessities to function within society, the reading comprehension ski"/>
    <meta name="dc.creator" content="van der Velde, Max"/>
    <meta name="dc.creator" content="Harmsen, Wieke"/>
    <meta name="dc.creator" content="Veldkamp, Bernard P."/>
    <meta name="dc.creator" content="Feskens, Remco"/>
    <meta name="dc.creator" content="Keuning, Jos"/>
    <meta name="dc.creator" content="Swart, Nicole"/>
    <meta name="dc.subject" content="Artificial Intelligence"/>
    <meta name="dc.subject" content="Educational Technology"/>
    <meta name="dc.subject" content="User Interfaces and Human Computer Interaction"/>
    <meta name="dc.subject" content="Computers and Education"/>
    <meta name="citation_reference" content="citation_journal_title=Theory and Practice in Language Studies; citation_title=Theories and Research on Oral ReadingFluency: What Is Needed?; citation_author=ZR Aldhanhani, EA Abu-Ayyash; citation_volume=10; citation_issue=4; citation_publication_date=2020; citation_pages=379-388; citation_doi=10.17507/tpls.1004.05; citation_id=CR1"/>
    <meta name="citation_reference" content="Bai, Y., Hubers, F. C. W., Cucchiarini, C., &amp; Strik, H. (2020). ASR-Based Evaluation and Feedback for Individualized Reading Practice. INTERSPEECH 2020: Shanghai, China. 
                https://www.isca-archive.org/interspeech_2020/bai20b_interspeech.pdf
                
              "/>
    <meta name="citation_reference" content="Bai, Y., Hubers, F. C. W., Cucchiarini, C., &amp; Strik, H. (2021). An ASR-based Reading Tutor for Practicing Reading Skills in the First Grade: Improving Performance through Threshold Adjustment. IberSPEECH 2021: Valladolid, Spain. 
                https://repository.ubn.ru.nl/bitstream/handle/2066/245151/245151.pdf
                
              ."/>
    <meta name="citation_reference" content="Baker, F. B. (2001).&#160;The basics of item response theory. 
                http://ericae.net/irt/baker
                
              ."/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Evaluation and Research in Education; citation_title=Item Response Theory: An Introduction to Latent Trait Models to Test and Item Development; citation_author=AA Bichi, R Talib; citation_volume=7; citation_issue=2; citation_publication_date=2018; citation_pages=142-151; citation_doi=10.11591/ijere.v7i2.12900; citation_id=CR5"/>
    <meta name="citation_reference" content="Boersma, P., &amp; Weenink, D. (2024). Praat: doing phonetics by computer [Computer program]. Version 6.4.13, retrieved 10 June 2024 from 
                http://www.praat.org/
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Educational Psychology; citation_title=Human and automated assessment of oral reading fluency; citation_author=D Bola&#241;os, RA Cole, WH Ward, GA Tindal, J Hasbrouck, PJ Schwanenflugel; citation_volume=105; citation_issue=4; citation_publication_date=2013; citation_pages=1142-1151; citation_doi=10.1037/a0031479; citation_id=CR7"/>
    <meta name="citation_reference" content="citation_journal_title=Written Language &amp; Literacy; citation_title=Word-initial entropy in five languages: Letter to sound, and sound to letter; citation_author=SR Borgwaldt, FM Hellwig, AM Groot; citation_volume=7; citation_issue=2; citation_publication_date=2004; citation_pages=165-184; citation_doi=10.1075/wll.7.2.03bor; citation_id=CR8"/>
    <meta name="citation_reference" content="citation_title=Make learning personal; citation_publication_date=2015; citation_id=CR9; citation_author=B Bray; citation_author=K McClaskey; citation_publisher=SAGE Publications Ltd., USA"/>
    <meta name="citation_reference" content="Cheng, J., &amp; Shen, J. (2010). Towards accurate recognition for children&#39;s oral reading fluency. IEEE Spoken Language Technology Workshop: Berkeley, USA. 
                https://doi.org/10.1109/SLT.2010.5700830
                
              "/>
    <meta name="citation_reference" content="Cheng, J. (2018). Real-time scoring of an oral reading assessment on mobile devices. INTERSPEECH 2018: Hyderabad. 
                https://doi.org/10.21437/Interspeech.2018-34
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Ieee Access; citation_title=The Matthews correlation coefficient (MCC) is more informative than Cohen&#8217;s Kappa and Brier score in binary classification assessment; citation_author=D Chicco, MJ Warrens, G Jurman; citation_volume=9; citation_publication_date=2021; citation_pages=78368-78381; citation_doi=10.1109/ACCESS.2021.3084050; citation_id=CR12"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Research on Technology in Education; citation_title=Assessment, technology, and change; citation_author=J Clarke-Midura, C Dede; citation_volume=42; citation_issue=3; citation_publication_date=2010; citation_pages=309-328; citation_doi=10.1080/15391523.2010.10782553; citation_id=CR13"/>
    <meta name="citation_reference" content="citation_journal_title=Policy Insights from the Behavioral and Brain Sciences; citation_title=Individualizing student instruction in reading: Implications for policy and practice; citation_author=CM Connor, FJ Morrison; citation_volume=3; citation_issue=1; citation_publication_date=2016; citation_pages=54-61; citation_doi=10.1177/2372732215624931; citation_id=CR14"/>
    <meta name="citation_reference" content="citation_journal_title=Speech Communication; citation_title=Oral proficiency training in Dutch L2: The contribution of ASR-based corrective feedback; citation_author=C Cucchiarini, A Neri, H Strik; citation_volume=51; citation_issue=10; citation_publication_date=2009; citation_pages=853-863; citation_doi=10.1016/j.specom.2009.03.003; citation_id=CR15"/>
    <meta name="citation_reference" content="Cucchiarini, C., van Hamme, H., Driesen, J., Sanders, E. (2008). THE JASMIN-CGN: CORPUS Design, recording, transcription and structure of the corpus"/>
    <meta name="citation_reference" content="citation_journal_title=Computer Speech &amp; Language; citation_title=Towards inclusive automatic speech recognition; citation_author=S Feng, BM Halpern, O Kudina, O Scharenborg; citation_volume=84; citation_publication_date=2024; citation_pages=101567; citation_doi=10.1016/j.csl.2023.101567; citation_id=CR17"/>
    <meta name="citation_reference" content="Fox, J. P., Klotzke, K., &amp; Simsek, A. S. (2021). LNIRT: An R package for joint modeling of response accuracy and times.&#160;arXiv preprint 
                arXiv:2106.10144
                
              . 
                https://arxiv.org/abs/2106.10144
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Scient Stud Read.; citation_title=Oral reading fluency as an indicator of reading competence: A theoretical, empirical, and historical analysis; citation_author=L Fuchs, D Fuchs, M Hosp, J Jenkins; citation_volume=5; citation_publication_date=2001; citation_pages=239-256; citation_doi=10.1207/S1532799XSSR0503_3; citation_id=CR19"/>
    <meta name="citation_reference" content="citation_journal_title=Perception &amp; Psychophysics; citation_title=Neighborhood frequency effects in visual word recognition: A comparison of lexical decision and masked identification latencies; citation_author=J Grainger, J Segui; citation_volume=47; citation_publication_date=1990; citation_pages=191-198; citation_doi=10.3758/BF03205983; citation_id=CR20"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Research in Reading; citation_title=The role of prosody in reading comprehension: Evidence from poor comprehenders; citation_author=MA Groen, NJ Veenendaal, L Verhoeven; citation_volume=42; citation_issue=1; citation_publication_date=2018; citation_pages=37-57; citation_doi=10.1111/1467-9817.12133; citation_id=CR21"/>
    <meta name="citation_reference" content="Hambleton, R. K., &amp; Swaminathan, H. (1985). Item response theory: Principles and applications. Springer. 
                https://link.springer.com/book/10.1007/978-94-017-1988-9
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Reading and Writing; citation_title=The simple view of reading; citation_author=WA Hoover, PB Gough; citation_volume=2; citation_publication_date=1990; citation_pages=127-160; citation_doi=10.1007/BF00401799; citation_id=CR23"/>
    <meta name="citation_reference" content="Inspectorate of Education. (2024). Schoolweging primair onderwijs [Schoolweightprimary education]. 
                https://www.onderwijsinspectie.nl/trends-en-ontwikkelingen/onderwijsdata/schoolweging-po
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Psychological Bulletin; citation_title=An argument-based approach to validity; citation_author=MT Kane; citation_volume=112; citation_publication_date=1992; citation_pages=527-535; citation_doi=10.1037/0033-2909.112.3.527; citation_id=CR25"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Educational Measurement; citation_title=Validating the interpretations and uses of test scores; citation_author=MT Kane; citation_volume=50; citation_publication_date=2013; citation_pages=1-73; citation_doi=10.1111/jedm.12000; citation_id=CR26"/>
    <meta name="citation_reference" content="Kane, M. T. (2006). Validation. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 17&#8211;64). Washington: American Council on Education/Praeger"/>
    <meta name="citation_reference" content="Kheir, Y. E., Ali, A., &amp; Chowdhury, S. A. (2023). Automatic Pronunciation Assessment--A Review. arXiv preprint 
                arXiv:2310.13974
                
              . 
                https://doi.org/10.48550/arXiv.2310.13974
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=A longitudinal investigation. Developmental Psychology; citation_title=What is text reading fluency and is it a predictor or an outcome of reading comprehension?; citation_author=YSG Kim, JM Quinn, Y Petscher; citation_volume=57; citation_issue=5; citation_publication_date=2021; citation_pages=718-732 ; citation_doi=10.1037/2Fdev0001167; citation_id=CR29"/>
    <meta name="citation_reference" content="citation_journal_title=Reading Research Quarterly; citation_title=Aligning theory and assessment of reading fluency: Automaticity, prosody, and definitions of fluency; citation_author=M Kuhn, P Schwanenflugel, E Meisinger; citation_volume=45; citation_issue=2; citation_publication_date=2010; citation_pages=232-253; citation_doi=10.1598/RRQ.45.2.4; citation_id=CR30"/>
    <meta name="citation_reference" content="Levis, J., &amp; Suvorov, R. (2012). Automatic speech recognition. InThe encyclopedia of applied linguistics.&#160;Chapelle, C. A. (2012). Hoboken : John Wiley &amp; Sons"/>
    <meta name="citation_reference" content="citation_journal_title=Psychological Review; citation_title=Toward an instance theory of automatization; citation_author=GD Logan; citation_volume=95; citation_issue=4; citation_publication_date=1988; citation_pages=492-527; citation_doi=10.1037/0033-295X.95.4.492; citation_id=CR32"/>
    <meta name="citation_reference" content="Loukina, A., Klebanov, B. B., Lange, P. L., Qian, Y., Gyawali, B., Madnani, N., Misra, A., Zechner, K., Wang, Z., &amp; Sabatini, J. (2019). Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead. INTERSPEECH 2019: Graz, Austria. 
                https://www.iscaarchive.org/interspeech_2019/loukina19_interspeech.pdf
                
              "/>
    <meta name="citation_reference" content="Malmberg (n.d.).Lijn 3 aanvankelijk lezen groep 3 basisonderwijs [Line 3 initial reading grade 1 primary education]. Malmberg"/>
    <meta name="citation_reference" content="citation_journal_title=Remedial and Special Education; citation_title=Best practices in promoting reading comprehension in students with learning disabilities 1976 to 1996; citation_author=MA Mastropieri, TE Scruggs; citation_volume=18; citation_publication_date=1997; citation_pages=197-213; citation_doi=10.1177/074193259701800402; citation_id=CR35"/>
    <meta name="citation_reference" content="Meelissen, M. R. M., Maassen, N. A. M., Gubbels, J., van Langen, A. M. L., Valk, J., Dood, C., Derks, I., In &#8217;t Zandt, M., &amp; Wolbers, M. (2023). Resultaten PISA-2022 in vogelvlucht [Results PISA-2022-An overview]. Enschede: Universiteit Twente. 
                https://doi.org/10.3990/1.9789036559461
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Reading Research Quarterly; citation_title=A longitudinal study of the development of reading prosody as a dimension of oral reading fluency in early elementary school children; citation_author=J Miller, PJ Schwanenflugel; citation_volume=43; citation_issue=4; citation_publication_date=2008; citation_pages=336-354; citation_doi=10.1598/RRQ.43.4.2; citation_id=CR37"/>
    <meta name="citation_reference" content="citation_journal_title=Reading &amp; Writing Quarterly; citation_title=Using a sight word measure to predict reading fluency problems in grades 1 to 3; citation_author=D Morris, J Perney; citation_volume=34; citation_issue=4; citation_publication_date=2018; citation_pages=338-348; citation_doi=10.1080/10573569.2018.1446857; citation_id=CR38"/>
    <meta name="citation_reference" content="citation_journal_title=Education Sciences; citation_title=Assessing expressive oral reading fluency; citation_author=TG Morrison, B Wilcox; citation_volume=10; citation_issue=3; citation_publication_date=2020; citation_pages=59; citation_doi=10.3390/educsci10030059; citation_id=CR39"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Educational Computing Research; citation_title=Evaluation of an automated reading tutor that listens: Comparison to human tutoring and classroom instruction; citation_author=J Mostow, G Aist, P Burkhead, A Corbett, A Cuneo, S Eitelman, B Tobin; citation_volume=29; citation_publication_date=2003; citation_pages=61-117; citation_doi=10.2190/06AX-QW99-EQ5G-RDCF; citation_id=CR40"/>
    <meta name="citation_reference" content="Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., &amp; Wry, E. (2023).&#160;PIRLS 2021 International Results in Reading.&#160;Boston College, TIMSS &amp; PIRLS International Study Center.&#160;
                https://doi.org/10.6017/lse.tpisc.tr2103.kb5342
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=Scientific Studies of Reading; citation_title=Word knowledge in a theory of reading comprehension; citation_author=C Perfetti, J Stafura; citation_volume=18; citation_issue=1; citation_publication_date=2014; citation_pages=22-37; citation_doi=10.1080/10888438.2013.827687; citation_id=CR42"/>
    <meta name="citation_reference" content="Perfetti, C. (1985). Reading ability. New York: Oxford University Press"/>
    <meta name="citation_reference" content="citation_journal_title=The Reading Teacher; citation_title=Fluency: Bridge between decoding comprehension; citation_author=JJ Pikulski, DJ Chard; citation_volume=58; citation_issue=6; citation_publication_date=2005; citation_pages=510-519; citation_doi=10.1598/RT.58.6.2; citation_id=CR44"/>
    <meta name="citation_reference" content="Posit team (2023). RStudio: Integrated Development Environment for R, version 4.3.1. [Computer software] Posit Software, PBC, Boston, MA. 
                http://www.posit.co/
                
              ."/>
    <meta name="citation_reference" content="citation_journal_title=Speech Communication; citation_title=Automatic evaluation of reading aloud performance in children; citation_author=J Proen&#231;a, C Lopes, M Tjalve, A Stolcke, S Candeias, F Perdig&#227;o; citation_volume=94; citation_publication_date=2017; citation_pages=1-14; citation_doi=10.1016/j.specom.2017.08.006; citation_id=CR46"/>
    <meta name="citation_reference" content="Proen&#231;a, J., Celorico, D., Candeias, S., Lopes, C., &amp; Perdig&#227;o, F. (2015). Children&#39;s Reading Aloud Performance: A Database and Automatic Detection of Disfluencies. INTERSPEECH 2015: Dresden, Germany. 
                https://doi.org/10.21437/Interspeech.2015-382
                
              "/>
    <meta name="citation_reference" content="Reeder, K., Shapiro, J., &amp; Wakefield, J. (2007). The effectiveness of speech recognition technology in promoting reading proficiency and attitudes for Canadian immigrant children. Proceedings of the 9th European Conference on Reading"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Educational Research; citation_title=Effects of fluency training on second graders reading comprehension; citation_author=DR Reutzel, PM Hollingsworth; citation_volume=86; citation_publication_date=1993; citation_pages=325-331; citation_doi=10.1080/00220671.1993.9941225; citation_id=CR49"/>
    <meta name="citation_reference" content="Rokade, A. A. (2018).&#160;Automated Grading System Using Natural Language Processing.International Conference on Inventive Communication and Computational Technologies 2018: Coimbatore, India. 
                https://doi.org/10.1109/ICICCT.2018.8473170
                
              "/>
    <meta name="citation_reference" content="citation_journal_title=CSI Transactions on ICT; citation_title=Automatic assessment of children&#8217;s oral reading using speech recognition and prosody modeling; citation_author=K Sabu, P Rao; citation_volume=6; citation_publication_date=2018; citation_pages=221-225; citation_doi=10.1007/s40012-018-0202-3; citation_id=CR51"/>
    <meta name="citation_reference" content="citation_journal_title=British Journal of Psychology; citation_title=Foundation literacy acquisition in European orthographies; citation_author=PHK Seymour, M Aro, JM Erskine; citation_volume=94; citation_publication_date=2003; citation_pages=143-174; citation_doi=10.1348/000712603321661859; citation_id=CR52"/>
    <meta name="citation_reference" content="citation_journal_title=Psychological Bulletin; citation_title=On the Anglocentricities of current reading research and practice: The perils of overreliance on an&quot; outlier&quot; orthography; citation_author=DL Share; citation_volume=134; citation_issue=4; citation_publication_date=2008; citation_pages=584-615; citation_doi=10.1037/0033-2909.134.4.584; citation_id=CR53"/>
    <meta name="citation_reference" content="citation_journal_title=International Journal of Distance Education Technologies; citation_title=A framework for large-scale automatic fluency assessment; citation_author=WA Silva, LC Carchedi, JG Junior, JV Souza, E Barrere, JF Souza; citation_volume=19; citation_issue=3; citation_publication_date=2021; citation_pages=70-88; citation_doi=10.4018/IJDET.2021070105; citation_id=CR54"/>
    <meta name="citation_reference" content="citation_journal_title=Psychological Review; citation_title=The effect of orthographic systems on the developing reading system: Typological and computational analyses; citation_author=AC Smith, P Monaghan, F Huettig; citation_volume=128; citation_issue=1; citation_publication_date=2021; citation_pages=125-159; citation_doi=10.1037/rev0000257; citation_id=CR55"/>
    <meta name="citation_reference" content="Torgesen, J. K., Wagner, R., &amp; Rashotte, C. (1997). Test of word reading efficiency. Austin, TX: PRO-ED"/>
    <meta name="citation_reference" content="Toulmin, S. E. (2003). The uses of argument. Cambridge University Press. 
                https://doi.org/10.1017/CBO9780511840005
                
              "/>
    <meta name="citation_reference" content="University of Oregon (2020). 8th Edition of Dynamic Indicators of Basic Early Literacy Skills (DIBELS&#174;): Administration and Scoring Guide. Eugene, OR: University of Oregon. 
                https://dibels.uoregon.edu
                
              "/>
    <meta name="citation_reference" content="van der Velde, M. E., Molenaar, B., Veldkamp, B. P., Feskens, R. C. W., &amp; Keuning, J. (2024a). What do they say? Assessment of oral reading fluency in early primary school children: A scoping review.&#160;International Journal of Educational Research, 128, 102444. 
                https://doi.org/10.1016/j.ijer.2024.102444
                
              "/>
    <meta name="citation_reference" content="Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ran&#273;elovi&#263; B., Karali&#263; E., Aleksi&#263; K., &#272;uki&#263; D. (Eds.), E-testing and computer-based assessment. CIDREE Yearbook 2024 (pp. 99&#8211;123). CIDREE. 
                https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf
                
              "/>
    <meta name="citation_reference" content="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., Vloedgraven, J. &amp; De Wijs, A. (2018a). Wetenschappelijke verantwoording DMT [Scientific Justification DMT]. Cito: Arnhem"/>
    <meta name="citation_reference" content="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., &amp; De Wijs, A. (2018b). Wetenschappelijke verantwoording AVI [Scientific Justification AVI]. Cito: Arnhem."/>
    <meta name="citation_reference" content="citation_journal_title=Psychometrika; citation_title=A Hierarchical Framework for Modeling Speed and Accuracy on Test Items; citation_author=WJ Linden; citation_volume=72; citation_publication_date=2007; citation_pages=287-308; citation_doi=10.1007/s11336-006-1478-z; citation_id=CR63"/>
    <meta name="citation_reference" content="citation_journal_title=Journal of Research in Reading; citation_title=What speech text reading fluency can reveal about reading comprehension; citation_author=NJ Veenendaal, MA Groen, L Verhoeven; citation_volume=38; citation_issue=3; citation_publication_date=2015; citation_pages=213-225; citation_doi=10.1111/1467-9817.12024; citation_id=CR64"/>
    <meta name="citation_reference" content="citation_journal_title=Scientific Studies of Reading.; citation_title=Bidirectional Relations between Text Reading Prosody and Reading Comprehension in the Upper Primary School Grades: A Longitudinal Perspective; citation_author=NJ Veenendaal, MA Groen, L Verhoeven; citation_volume=20; citation_issue=3; citation_publication_date=2016; citation_pages=189-202; citation_doi=10.1080/10888438.2015.1128939; citation_id=CR65"/>
    <meta name="citation_reference" content="citation_journal_title=Scientific Studies of Reading; citation_title=Modeling the Growth of Word-Decoding Skills: Evidence From Dutch; citation_author=L Verhoeven, J Leeuwe; citation_volume=13; citation_issue=3; citation_publication_date=2009; citation_pages=205-223; citation_doi=10.1080/10888430902851356; citation_id=CR66"/>
    <meta name="citation_reference" content="citation_journal_title=Speech Communication; citation_title=Automatic speech recognition and pronunciation error detection of Dutch non-native speech: Cumulating speech resources in a pluricentric language; citation_author=X Wei, C Cucchiarini, RWNM Hout, H Strik; citation_volume=144; citation_publication_date=2022; citation_pages=1-9; citation_doi=10.1016/j.specom.2022.08.004; citation_id=CR67"/>
    <meta name="citation_reference" content="citation_journal_title=Cognition; citation_title=The influence of orthographic consistency on reading development: Word recognition in English and German children; citation_author=H Wimmer, U Goswami; citation_volume=51; citation_publication_date=1994; citation_pages=91-103; citation_doi=10.1016/0010-0277(94)90010-8; citation_id=CR68"/>
    <meta name="citation_reference" content="citation_journal_title=Cadmo; citation_title=Evaluation of validity and validation by means of the argument-based approach; citation_author=S Wools, TJHM Eggen, PF Sanders; citation_volume=18; citation_issue=1; citation_publication_date=2010; citation_pages=63-82; citation_doi=10.3280/CAD2010-001007; citation_id=CR69"/>
    <meta name="citation_reference" content="Zwijsen Educatieve Uitgeverij. (2023). Veilig leren lezen: KIM-versie [Learning to read safely: KIM-version]. Zwijsen"/>
    <meta name="citation_author" content="van der Velde, Max"/>
    <meta name="citation_author_email" content="m.e.vandervelde@utwente.nl"/>
    <meta name="citation_author_institution" content="Cognition, Data and Education Section, Faculty of BMS, University of Twente, Enschede, The Netherlands"/>
    <meta name="citation_author_institution" content="CitoLab, Cito, Arnhem, The Netherlands"/>
    <meta name="citation_author" content="Harmsen, Wieke"/>
    <meta name="citation_author_email" content="wieke.harmsen@ru.nl"/>
    <meta name="citation_author_institution" content="Centre for Language Studies, Radboud University, Nijmegen, The Netherlands"/>
    <meta name="citation_author" content="Veldkamp, Bernard P."/>
    <meta name="citation_author_email" content="b.p.veldkamp@utwente.nl"/>
    <meta name="citation_author_institution" content="Cognition, Data and Education Section, Faculty of BMS, University of Twente, Enschede, The Netherlands"/>
    <meta name="citation_author" content="Feskens, Remco"/>
    <meta name="citation_author_email" content="remco.feskens@cito.nl"/>
    <meta name="citation_author_institution" content="Cognition, Data and Education Section, Faculty of BMS, University of Twente, Enschede, The Netherlands"/>
    <meta name="citation_author_institution" content="CitoLab, Cito, Arnhem, The Netherlands"/>
    <meta name="citation_author" content="Keuning, Jos"/>
    <meta name="citation_author_email" content="jos.keuning@cito.nl"/>
    <meta name="citation_author_institution" content="CitoLab, Cito, Arnhem, The Netherlands"/>
    <meta name="citation_author" content="Swart, Nicole"/>
    <meta name="citation_author_email" content="n.swart@expertisecentrumnederlands.nl"/>
    <meta name="citation_author_institution" content="Expertisecentrum Nederlands, Nijmegen, The Netherlands"/>
    <meta name="format-detection" content="telephone=no"/>
    

            
    
    <meta property="og:url" content="https://link.springer.com/article/10.1007/s40593-025-00480-y"/>
    <meta property="og:type" content="article"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:title" content="Speech Enabled Reading Fluency Assessment: a Validation Study - International Journal of Artificial Intelligence in Education"/>
    <meta property="og:description" content="Although the ability to comprehend what one is reading is one of the most fundamental necessities to function within society, the reading comprehension skills of students have recently been on the decline in many countries. An essential prerequisite to reading comprehension is the ability to read fluently, which is defined as the ability to read (aloud) with accuracy, speed, automaticity and prosody. Current oral reading fluency assessment instruments seldom provide detailed diagnostics however, and bestow a heavy testing burden on practitioners. Recent developments in Artificial Intelligence-based assessment methodology might provide a solution to current assessment issues, but thorough validations of such procedures have proven scarce. This study evaluates whether valid word decoding and passage reading measures (accuracy, speed and automaticity) can be generated for a semi-transparent language, using an automatic speech recognition (ASR) based oral reading fluency assessment instrument. A validation study was conducted, using the Argument-Based Approach to Validation. Data concerned 176 h of speech data, and the results of 569 and 622 oral word- and passage reading tests that are currently administered in primary schools, from 653 children attending the second- or third grade of Dutch primary education. The results of the validation indicate that it is possible to generate fluency metrics for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument. Future researchers are advised to further optimize the ASR, evaluate its errors, and realize a prosody component, completing the envisioned reading fluency assessment instrument, thereby improving reading fluency assessment throughout primary education."/>
    <meta property="og:image" content="https://static-content.springer.com/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig1_HTML.png"/>
    

        

        <meta name="format-detection" content="telephone=no">

        
    
        
    
    
    

    


        <link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/img/favicons/darwin/apple-touch-icon-6ef0829b9c.png>
<link rel="icon" type="image/png" sizes="192x192" href=/oscar-static/img/favicons/darwin/android-chrome-192x192.png>
<link rel="icon" type="image/png" sizes="32x32" href=/oscar-static/img/favicons/darwin/favicon-32x32.png>
<link rel="icon" type="image/png" sizes="16x16" href=/oscar-static/img/favicons/darwin/favicon-16x16.png>
<link rel="shortcut icon" data-test="shortcut-icon" href=/oscar-static/img/favicons/darwin/favicon-de0c289efe.ico>

<meta name="theme-color" content="#e6e6e6">


        



<link rel="stylesheet" media="print" href=/oscar-static/app-springerlink/css/print-b8af42253b.css>



    
        
            
    <style> html{line-height:1.15;text-size-adjust:100%}body{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;margin:0}details,main{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#025e8d}b{font-weight:bolder}sub{bottom:-.25em;font-size:75%;line-height:0;position:relative;vertical-align:baseline}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input{font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible}button{text-transform:none}[type=button],[type=submit],button{-webkit-appearance:button}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}summary{display:list-item}[hidden]{display:none}button{cursor:pointer}svg{height:1rem;width:1rem}.eds-c-header__brand img{max-width:100%}@media only screen and (min-width:768px){.eds-c-header__brand img{max-width:340px}} </style>
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  body{background:#fff;color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;line-height:1.8;min-height:100%}a{color:#025e8d;padding:initial;text-decoration:underline;text-decoration-skip-ink:auto}button{cursor:pointer}img{border:0;height:auto;max-width:100%;vertical-align:middle}html{box-sizing:border-box;font-size:100%;height:100%;overflow-y:scroll}h1{font-size:2.25rem}h2{font-size:1.75rem}h1,h2,h3{font-weight:700;line-height:1.2}h3{font-size:1.5rem}body{font-size:1.125rem}*{box-sizing:inherit}p{margin-bottom:2rem;margin-top:0}p:last-of-type{margin-bottom:0}.c-ad{text-align:center}@media only screen and (min-width:480px){.c-ad{padding:8px}}.c-ad--728x90{display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:876px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-status-message{align-items:center;box-sizing:border-box;display:flex;width:100%}.c-status-message__heading{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;transform:translate(0);vertical-align:text-top}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.eds-c-button{border-radius:32px;cursor:pointer;display:inline-block;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;font-weight:700;line-height:1.5;margin:0;padding:.5rem 1.5rem;position:relative;text-align:center;text-decoration:none;transition:all .2s ease 0s;width:100%}.eds-c-button span,.eds-c-button svg{vertical-align:middle}.eds-c-button svg{height:1.5rem;width:1.5rem}.eds-c-button svg:last-child{margin-left:8px}@media only screen and (min-width:480px){.eds-c-button{width:auto}}.eds-c-button--primary{background-color:#025e8d;background-image:none;border:2px solid transparent;box-shadow:none;color:#fff;text-decoration:none}.eds-c-button--primary svg,.eds-c-button--secondary svg{fill:currentcolor}.eds-c-button--secondary{background-color:#fff;background-image:none;border:2px solid #025e8d;box-shadow:none;color:#025e8d;text-decoration:none}.eds-c-header{background-color:#fff;border-bottom:2px solid #01324b;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;line-height:1.5;padding:8px 0 0}.eds-c-header__container{align-items:center;display:flex;flex-wrap:nowrap;gap:8px 16px;justify-content:space-between;margin:0 auto 8px;max-width:1280px;padding:0 8px;position:relative}.eds-c-header__nav{border-top:2px solid #c5e0f4;padding-top:4px;position:relative}.eds-c-header__nav-container{align-items:center;display:flex;flex-wrap:wrap;margin:0 auto 4px;max-width:1280px;padding:0 8px;position:relative}.eds-c-header__nav-container>:not(:last-child){margin-right:32px}.eds-c-header__link-container{align-items:center;display:flex;flex:1 0 auto;gap:8px 16px;justify-content:space-between}.eds-c-header__list{list-style:none;margin:0;padding:0}.eds-c-header__list-item{font-weight:700;margin:0 auto;max-width:1280px;padding:8px}.eds-c-header__list-item:not(:last-child){border-bottom:2px solid #c5e0f4}.eds-c-header__item{color:inherit}@media only screen and (min-width:768px){.eds-c-header__item--menu{display:none;visibility:hidden}.eds-c-header__item--menu:first-child+*{margin-block-start:0}}.eds-c-header__item--inline-links{display:none;visibility:hidden}@media only screen and (min-width:768px){.eds-c-header__item--inline-links{display:flex;gap:16px 16px;visibility:visible}}.eds-c-header__item--divider:before{border-left:2px solid #c5e0f4;content:"";height:calc(100% - 16px);margin-left:-15px;position:absolute;top:8px}.eds-c-header__brand{padding:16px 8px}.eds-c-header__brand a{display:block;line-height:1;text-decoration:none}.eds-c-header__brand img{height:1.5rem;width:auto}.eds-c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.eds-c-header__icon{fill:currentcolor;display:inline-block;font-size:1.5rem;height:1em;transform:translate(0);vertical-align:bottom;width:1em}.eds-c-header__icon+*{margin-left:8px}.eds-c-header__expander{background-color:#f0f7fc}.eds-c-header__search{display:block;padding:24px 0}@media only screen and (min-width:768px){.eds-c-header__search{max-width:70%}}.eds-c-header__search-container{position:relative}.eds-c-header__search-label{color:inherit;display:inline-block;font-weight:700;margin-bottom:8px}.eds-c-header__search-input{background-color:#fff;border:1px solid #000;padding:8px 48px 8px 8px;width:100%}.eds-c-header__search-button{background-color:transparent;border:0;color:inherit;height:100%;padding:0 8px;position:absolute;right:0}.has-tethered.eds-c-header__expander{border-bottom:2px solid #01324b;left:0;margin-top:-2px;top:100%;width:100%;z-index:10}@media only screen and (min-width:768px){.has-tethered.eds-c-header__expander--menu{display:none;visibility:hidden}}.has-tethered .eds-c-header__heading{display:none;visibility:hidden}.has-tethered .eds-c-header__heading:first-child+*{margin-block-start:0}.has-tethered .eds-c-header__search{margin:auto}.eds-c-header__heading{margin:0 auto;max-width:1280px;padding:16px 16px 0}.eds-c-pagination,.js .eds-c-modal--open{align-items:center;display:flex;justify-content:center}.eds-c-pagination{flex-wrap:wrap;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;gap:16px 0;line-height:1.4;list-style:none;margin:0;padding:32px 0}@media only screen and (min-width:480px){.eds-c-pagination{padding:32px 16px}}.eds-c-pagination__item{margin-right:8px}.eds-c-pagination__item--prev{margin-right:16px}.eds-c-pagination__item--next .eds-c-pagination__link,.eds-c-pagination__item--prev .eds-c-pagination__link{padding:16px 8px}.eds-c-pagination__item--next{margin-left:8px}.eds-c-pagination__item:last-child{margin-right:0}.eds-c-pagination__link{align-items:center;color:#222;cursor:pointer;display:inline-block;font-size:1rem;margin:0;padding:16px 24px;position:relative;text-align:center;transition:all .2s ease 0s}.eds-c-pagination__link:visited{color:#222}.eds-c-pagination__link--disabled{border-color:#555;color:#555;cursor:default}.eds-c-pagination__link--active{background-color:#01324b;background-image:none;border-radius:8px;color:#fff}.eds-c-pagination__link--active:focus,.eds-c-pagination__link--active:hover,.eds-c-pagination__link--active:visited{color:#fff}.eds-c-pagination__link-container{align-items:center;display:flex}.eds-c-pagination__icon{fill:#222;height:1.5rem;width:1.5rem}.eds-c-pagination__icon--disabled{fill:#555}.eds-c-pagination__visually-hidden{border:0;clip:rect(0,0,0,0);clip-path:inset(50%);height:1px;overflow:hidden;padding:0;position:absolute!important;white-space:nowrap;width:1px}.c-breadcrumbs{color:#333;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs>li{display:inline}svg.c-breadcrumbs__chevron{margin:0 .25rem;fill:#333;height:10px;width:10px}.c-breadcrumbs--contrast,.c-breadcrumbs--contrast .c-breadcrumbs__link,.c-breadcrumbs--contrast .c-breadcrumbs__link.hover,.c-breadcrumbs--contrast .c-breadcrumbs__link.visited,.c-breadcrumbs--contrast .c-breadcrumbs__link:hover,.c-breadcrumbs--contrast .c-breadcrumbs__link:visited{color:#fff}.c-breadcrumbs--contrast svg.c-breadcrumbs__chevron{fill:#fff}@media only screen and (max-width:479px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-header__link{color:inherit;display:inline-block;font-weight:700;padding:16px 8px;position:relative;text-decoration-color:transparent;white-space:nowrap;word-break:normal}.l-with-sidebar{display:flex;flex-wrap:wrap}.l-with-sidebar>*{margin:0}.l-with-sidebar__sidebar{flex-basis:var(--with-sidebar--basis,400px);flex-grow:1}.l-with-sidebar>:not(.l-with-sidebar__sidebar){flex-basis:0px;flex-grow:999;min-width:var(--with-sidebar--min,52%)}.l-with-sidebar>:first-child{padding-right:4rem}@supports (gap:1em){.l-with-sidebar>:first-child{padding-right:0}.l-with-sidebar{gap:var(--with-sidebar--gap,4rem)}}.c-meta__link:visited,.c-status-message a{color:#000}.c-skip-link,.js .c-popup{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;position:absolute}.c-skip-link{background:#01324b;bottom:auto;color:#fff;font-size:1rem;padding:8px;text-align:center;transform:translateY(-100%);width:100%;z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:active,.c-skip-link:hover,.c-skip-link:link,.c-skip-link:visited{color:#fff}.c-skip-link:focus{transform:translateY(0)}.c-status-message{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-weight:400;position:relative}.c-status-message :last-child{margin-bottom:0}.c-status-message--bold{font-weight:700}.c-status-message--boxed{background-color:#fff;border:1px solid #dadada;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.4;overflow:hidden;padding:16px}.c-status-message--banner{background-color:#fff;line-height:1.4;padding:16px 0}.c-status-message--banner .c-status-message__container{justify-content:center;padding:0 16px}.c-status-message--sticky{position:sticky;top:0;z-index:999}.c-status-message__container{align-items:center;display:flex;justify-content:flex-start}.c-status-message__icon{align-self:flex-start;flex-shrink:0;height:21px;margin-right:8px;width:21px}.c-status-message__message :first-child,.c-status-message__message :last-child{margin-top:0}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#0070a8}.c-status-message--banner.c-status-message--info{border-bottom:4px solid #0070a8}.c-status-message--boxed.c-status-message--info .c-status-message__bottom-border{background:#0070a8;bottom:0;content:"";height:4px;left:0;position:absolute;width:100%}.c-status-message--info .c-status-message__icon{fill:#0070a8}.c-status-message--error .c-status-message__icon{color:#be1818}.c-status-message--banner.c-status-message--error{border-bottom:4px solid #be1818}.c-status-message--boxed.c-status-message--error .c-status-message__bottom-border{background:#be1818;bottom:0;content:"";height:4px;left:0;position:absolute;width:100%}.c-status-message--error .c-status-message__icon{fill:#be1818}.c-status-message--success .c-status-message__icon{color:#00a69d}.c-status-message--banner.c-status-message--success{border-bottom:4px solid #00a69d}.c-status-message--boxed.c-status-message--success .c-status-message__bottom-border{background:#00a69d;bottom:0;content:"";height:4px;left:0;position:absolute;width:100%}.c-status-message--success .c-status-message__icon{fill:#00a69d}.c-status-message--warning .c-status-message__icon{color:#f58220}.c-status-message--banner.c-status-message--warning{border-bottom:4px solid #f58220}.c-status-message--boxed.c-status-message--warning .c-status-message__bottom-border{background:#f58220;bottom:0;content:"";height:4px;left:0;position:absolute;width:100%}.c-status-message--warning .c-status-message__icon{fill:#f58220}:root{--header-height:58px}.app-masthead__colour-4{--background-color:#ff9500;--gradient-light:rgba(0,0,0,.5);--gradient-dark:rgba(0,0,0,.8)}.app-masthead--pastel{--gradient-light:hsla(0,0%,100%,.9);--gradient-dark:hsla(0,0%,100%,.75);--masthead-color:#000}.app-masthead{background:var(--background-color,#0070a8);position:relative}.app-masthead:after{background:radial-gradient(circle at top right,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)));bottom:0;content:"";left:0;position:absolute;right:0;top:0}.app-masthead--pastel .app-masthead{background:var(--background-color,#6ac)}@media only screen and (max-width:479px){.app-masthead:after{background:linear-gradient(225deg,var(--gradient-light,rgba(0,0,0,.4)),var(--gradient-dark,rgba(0,0,0,.7)))}}.app-masthead__container{color:var(--masthead-color,#fff);margin:0 auto;max-width:1280px;padding:0 16px;position:relative;z-index:1}.u-clear-both{clear:both}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-visually-hidden{border:0;clip:rect(0,0,0,0);clip-path:inset(50%);height:1px;overflow:hidden;padding:0;position:absolute!important;white-space:nowrap;width:1px}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-ma-16{margin:16px}.u-mt-0{margin-top:0}.u-mt-24{margin-top:24px}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-32{margin-bottom:32px}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download,.u-ml-0{margin-left:0}.u-sans-serif{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.u-serif{font-family:Merriweather,serif}h1,h2,h3{-webkit-font-smoothing:antialiased}p{overflow-wrap:break-word;word-break:break-word}.u-h4{font-size:1.25rem;font-weight:700;line-height:1.2}.u-mbs-0{margin-block-start:0!important}.c-article-header{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;padding:0}.c-article-identifiers__item{list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{margin-right:0;padding-right:0}@media only screen and (min-width:876px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:767px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#025e8d;border-color:transparent;color:#fff}.c-article-body .c-article-access-provider{padding:8px 16px}.c-article-body .c-article-access-provider,.c-notes{border:1px solid #d5d5d5;border-image:initial;border-left:none;border-right:none;margin:24px 0}.c-article-body .c-article-access-provider__text{color:#555}.c-article-body .c-article-access-provider__text,.c-notes__text{font-size:1rem;margin-bottom:0;padding-bottom:2px;padding-top:2px;text-align:center}.c-article-body .c-article-author-affiliation__address{color:inherit;font-weight:700;margin:0}.c-article-body .c-article-author-affiliation__authors-list{list-style:none;margin:0;padding:0}.c-article-body .c-article-author-affiliation__authors-item{display:inline;margin-left:0}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-body .c-article-subject-list--no-mb{margin-bottom:0}.c-code-block{border:1px solid #fff;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;margin-bottom:24px}.c-article-share-box__description{font-size:1rem;margin-bottom:8px}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__additional-info{color:#626262;font-size:.813rem}.c-article-share-box__button{background:#fff;box-sizing:content-box;text-align:center}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#025e8d;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{font-size:1rem}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;font-size:1.25rem;font-weight:700;line-height:1.2;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-article-section__figure-caption{display:block;margin-bottom:8px;word-break:break-word}.c-article-section__figure .video,p.app-article-masthead__access--above-download{margin:0 0 16px}.c-cod{display:block;font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex:1 1 auto;margin:0;padding:13px}.c-cod__input--submit{background-color:#025e8d;border:1px solid #025e8d;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#025e8d}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:767px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container--flex-start{justify-content:flex-start}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container{flex-wrap:wrap;width:100%}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}@media only screen and (min-width:768px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-pdf-container{display:block}.c-article-body .c-article-recommendations-list,.c-book-body .c-article-recommendations-list{display:flex;flex-direction:row;gap:16px 16px;margin:0;max-width:100%;padding:16px 0 0}.c-article-body .c-article-recommendations-list__item,.c-book-body .c-article-recommendations-list__item{flex:1 1 0%}@media only screen and (max-width:767px){.c-article-body .c-article-recommendations-list,.c-book-body .c-article-recommendations-list{flex-direction:column}}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:767px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-body .c-article-history{margin-top:24px}.app-article-metrics-bar p{margin:0}.app-article-masthead{display:flex;flex-direction:column;gap:16px 16px;padding:16px 0 24px}.app-article-masthead__info{display:flex;flex-direction:column;flex-grow:1}.app-article-masthead__brand{border-top:1px solid hsla(0,0%,100%,.8);display:flex;flex-direction:column;flex-shrink:0;gap:8px 8px;min-height:96px;padding:16px 0 0}.app-article-masthead__brand img{border:1px solid #fff;border-radius:8px;box-shadow:0 4px 15px 0 hsla(0,0%,50%,.25);height:auto;left:0;position:absolute;width:72px}.app-article-masthead__journal-link{display:block;font-size:1.125rem;font-weight:700;margin:0 0 8px;max-width:400px;padding:0 0 0 88px;position:relative}.app-article-masthead__journal-title{display:-webkit-box;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:3}.app-article-masthead__submission-link{align-items:center;display:flex;font-size:1rem;gap:4px 4px;margin:0 0 0 88px}.app-article-masthead__access{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;font-weight:300;gap:4px 4px;line-height:1.4;margin:0}.app-article-masthead__buttons{display:flex;flex-flow:column wrap;gap:16px 16px}.app-article-masthead__access svg{fill:currentcolor}.app-article-masthead a{color:#fff}.app-article-masthead a.c-pdf-download__link,.app-article-masthead__syndicated-card a,.app-article-masthead__syndicated-card a:visited,.app-masthead--pastel .app-article-masthead .c-article-identifiers *,.app-masthead--pastel .app-article-masthead .c-article-identifiers a:focus,.app-masthead--pastel .app-article-masthead .c-article-identifiers a:hover,.app-masthead--pastel .app-article-masthead a,.app-masthead--pastel .app-article-masthead a:visited{color:#000}.app-masthead--pastel .app-article-masthead .c-article-identifiers__item{border-left:1px solid #000}.app-masthead--pastel .c-pdf-download a.u-button--primary,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--primary{background-color:#025e8d;border:2px solid transparent;box-shadow:none;color:#fff;font-weight:700}.app-masthead--pastel .c-pdf-download a.u-button--primary:focus,.app-masthead--pastel .c-pdf-download a.u-button--primary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--primary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--primary:hover{background:0 0;border:2px solid #025e8d;box-shadow:none;color:#025e8d}.app-masthead--pastel .c-pdf-download a.u-button--secondary,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--secondary{background:0 0;border:2px solid #025e8d;color:#025e8d}.app-masthead--pastel .c-pdf-download a.u-button--secondary:focus,.app-masthead--pastel .c-pdf-download a.u-button--secondary:hover,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--secondary:focus,.c-context-bar--sticky .c-context-bar__container .c-pdf-download a.u-button--secondary:hover{background-color:#025e8d;border:2px solid transparent;color:#fff}@media only screen and (min-width:768px){.app-article-masthead{flex-direction:row;gap:64px 64px;padding:24px 0}.app-article-masthead__brand{border:0;padding:0}.app-article-masthead__brand img{height:auto;position:static;width:auto}.app-article-masthead__buttons{align-items:normal;margin-top:auto}.app-article-masthead__journal-link{display:flex;flex-direction:column;gap:24px 24px;margin:0 0 8px;padding:0}.app-article-masthead__submission-link{margin:0}.app-article-masthead .c-pdf-container{flex-grow:0}}@media only screen and (min-width:1024px){.app-article-masthead__brand{flex-basis:400px}}.app-article-masthead__buttons .c-pdf-container{justify-content:flex-start}.app-article-masthead .c-article-identifiers{font-size:.875rem;font-weight:300;line-height:1;margin:0 0 8px;overflow:hidden;padding:0}.app-article-masthead .c-article-identifiers--cite-list{margin:0 0 16px}.app-article-masthead .c-article-identifiers *{color:#fff}.app-article-masthead .c-cod{display:none}.app-article-masthead .c-article-identifiers__item{border-left:1px solid #fff;border-right:0;margin:0 17px 8px -9px;padding:0 0 0 8px}.app-article-masthead .c-article-identifiers__item--cite{border-left:0}.app-article-masthead__access-container{align-items:center;display:flex;flex-wrap:wrap;gap:16px 36px;justify-content:center}@media only screen and (min-width:480px){.app-article-masthead__access-container{justify-content:normal}}.app-article-masthead__access-container>*{flex:1 1 auto}@media only screen and (min-width:480px){.app-article-masthead__access-container>*{flex:0 1 auto}}.app-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;padding:16px 0 0;row-gap:24px}.app-article-metrics-bar__item{padding:0 16px 0 0}.app-article-metrics-bar__count{font-weight:700}.app-article-metrics-bar__label{font-weight:400;padding-left:4px}.app-article-metrics-bar__icon{height:auto;margin-right:4px;margin-top:-4px;width:auto}.app-article-metrics-bar__arrow-icon{margin:4px 0 0 4px}.app-article-metrics-bar a{color:#000}.app-article-metrics-bar .app-article-metrics-bar__item--metrics{padding-right:0}.app-overview-section .c-article-author-list,.app-overview-section__authors{line-height:2}.app-article-metrics-bar{margin-top:8px}.c-book-toc-pagination+.c-book-section__back-to-top{margin-top:0}.c-article-body .c-article-access-provider__text--chapter{color:#222;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;padding:20px 0}.c-article-body .c-article-access-provider__text--chapter svg.c-status-message__icon{fill:#003f8d;vertical-align:middle}.c-article-body-section__content--separator{padding-top:40px}.c-pdf-download__link{max-height:44px}@media only screen and (max-width:767px){.app-article-masthead--book__info .c-pdf-container,.app-article-masthead__info .c-pdf-container{flex-direction:column;gap:12px 12px}.app-article-masthead--book__info .c-pdf-container .c-pdf-download+.c-pdf-download,.app-article-masthead__info .c-pdf-container .c-pdf-download+.c-pdf-download{margin:0}}.app-article-access .u-button--primary,.app-article-access .u-button--primary:visited{color:#fff}.c-article-authors-search__list{align-items:center;display:flex;flex-wrap:wrap;gap:16px 16px;justify-content:center}@media only screen and (min-width:480px){.c-article-authors-search__list{justify-content:normal}}.c-article-authors-search__text{align-items:center;display:flex;flex-flow:column wrap;font-size:14px;justify-content:center}@media only screen and (min-width:480px){.c-article-authors-search__text{flex-direction:row;font-size:16px}}.c-article-authors-search__links-text{font-weight:700;margin-right:8px;text-align:center}@media only screen and (min-width:480px){.c-article-authors-search__links-text{text-align:left}}.c-article-authors-search__list-item--left{flex:1 1 100%}@media only screen and (min-width:480px){.c-article-authors-search__list-item--left{flex-basis:auto}}.c-article-authors-search__list-item--right{flex:1 1 auto}.c-article-identifiers{margin:0}.c-article-identifiers__item{border-right:2px solid #cedbe0;color:#222;font-size:14px}@media only screen and (min-width:480px){.c-article-identifiers__item{font-size:16px}}.c-article-identifiers__item:last-child{border-right:none}.c-article-body .app-article-access p,.c-article-body .app-explore-related-subjects__list--no-mb{margin-bottom:0}.c-spp-access-message .c-status-message__icon{color:#00a69d;margin-top:8px}.c-article-sidebar{display:none}@media only screen and (min-width:1024px){.c-article-sidebar{display:block}}.c-cod__form{border-radius:12px}.c-cod__label{font-size:.875rem}.c-cod .c-status-message{align-items:center;justify-content:center;margin-bottom:16px;padding-bottom:16px}@media only screen and (min-width:1024px){.c-cod .c-status-message{align-items:inherit}}.c-cod .c-status-message__icon{margin-top:4px}.c-cod .c-cod__prompt{font-size:1rem;margin-bottom:16px}.c-article-body .app-article-access,.c-book-body .app-article-access{display:block}@media only screen and (min-width:1024px){.c-article-body .app-article-access,.c-book-body .app-article-access{display:none}}.c-article-body .app-card-service{margin-bottom:32px}@media only screen and (min-width:1024px){.c-article-body .app-card-service{display:none}}.app-article-access .buybox__buy .u-button--secondary,.app-article-access .u-button--primary,.c-cod__row .u-button--primary{background-color:#025e8d;border:2px solid #025e8d;box-shadow:none;font-size:1rem;font-weight:700;gap:8px 8px;justify-content:center;line-height:1.4;padding:8px 24px}.app-article-access .buybox__buy .u-button--secondary,.app-article-access .u-button--primary:hover,.c-cod__row .u-button--primary:hover{background-color:#fff;color:#025e8d}.app-article-access .buybox__buy .u-button--secondary:hover{background-color:#025e8d;color:#fff}.buybox__buy .c-notes__text{color:#666;font-size:.875rem;padding:0 16px 8px}.c-cod__input{flex-basis:auto;width:100%}.c-article-title{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:2.25rem;font-weight:700;line-height:1.2;margin:12px 0}.c-reading-companion__figure-item figure{margin:0}@media only screen and (min-width:768px){.c-article-title{margin:16px 0}}.app-article-access{border:1px solid #cedbe0;border-radius:12px;margin:0 0 32px}.app-article-access__heading{border-bottom:1px solid #cedbe0;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1.125rem;font-weight:700;margin:0;padding:16px;text-align:center}@media only screen and (min-width:1024px){.app-article-access{margin:0 0 24px}}.c-status-message{font-size:1rem}.c-article-body{font-size:1.125rem}.c-article-body dl,.c-article-body ol,.c-article-body p,.c-article-body ul{margin-bottom:32px;margin-top:0}.c-article-access-provider__text:last-of-type,.c-article-body .c-notes__text:last-of-type{margin-bottom:0}.c-article-body ol p,.c-article-body ul p{margin-bottom:16px}.c-article-section__figure-caption{font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif}.c-reading-companion__figure-item{border-top-color:#cedbe0}.c-reading-companion__sticky{max-width:400px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;padding:16px 0}.c-reading-companion__reference-item:first-child{padding-top:0}.c-article-share-box__button,.js .c-article-authors-search__item .c-article-button{background:0 0;border:2px solid #025e8d;border-radius:32px;box-shadow:none;color:#025e8d;font-size:1rem;font-weight:700;line-height:1.4;margin:0;padding:8px 24px;transition:all .2s ease 0s}.c-article-authors-search__item .c-article-button{width:100%}.c-pdf-download .c-pdf-download__link{align-items:center;background-color:#fff;border:2px solid #fff;border-radius:32px;box-shadow:none;color:#01324b;cursor:pointer;font-family:Merriweather Sans,Helvetica Neue,Helvetica,Arial,sans-serif;font-size:1rem;font-weight:700;justify-content:center;line-height:1.4;padding:8px 16px;text-decoration:none}.c-context-bar__container .c-pdf-download .c-pdf-download__link{background-color:#025e8d;background-image:none;border:2px solid #025e8d;box-shadow:none;color:#fff;font-size:1rem;font-weight:700;line-height:1.4;padding:8px 16px}@media only screen and (min-width:768px){.c-context-bar__container .c-pdf-download .c-pdf-download__link,.c-pdf-download .c-pdf-download__link{padding:8px 24px}}.c-pdf-download .c-pdf-download__link:hover{background:0 0;border:2px solid #fff;box-shadow:none;color:#fff}.c-pdf-download .c-pdf-download__link:focus{background:0 0;box-shadow:none;color:#fff}.c-context-bar__container .c-pdf-download .c-pdf-download__link:hover{border:2px solid #025e8d;box-shadow:none;color:#025e8d}.c-context-bar__container .c-pdf-download .c-pdf-download__link:focus,.c-pdf-download .c-pdf-download__link:focus{border:2px solid #025e8d}.c-article-share-box__button:focus:focus,.c-article__pill-button:focus:focus,.c-context-bar__container .c-pdf-download .c-pdf-download__link:focus:focus,.c-pdf-download .c-pdf-download__link:focus:focus{outline:3px solid #08c;will-change:transform}.c-pdf-download__link .u-icon{padding-top:0}.c-bibliographic-information__column button{margin-bottom:16px}.c-article-body .c-article-author-affiliation__list p,.c-article-body .c-article-author-information__list p,figure{margin:0}.c-article-share-box__button{margin-right:16px}.c-status-message--boxed{border-radius:12px}.c-article-associated-content__collection-title{font-size:1rem}.app-card-service__description,.c-article-body .app-card-service__description{color:#222;margin-bottom:0;margin-top:8px}.app-article-access__subscriptions a,.app-article-access__subscriptions a:visited,.app-book-series-listing__item a,.app-book-series-listing__item a:hover,.app-book-series-listing__item a:visited,.c-article-author-list a,.c-article-author-list a:visited,.c-article-buy-box a,.c-article-buy-box a:visited,.c-article-peer-review a,.c-article-peer-review a:visited,.c-article-satellite-subtitle a,.c-article-satellite-subtitle a:visited,.c-breadcrumbs__link,.c-breadcrumbs__link:hover,.c-breadcrumbs__link:visited{color:#000}.c-article-author-list svg{height:24px;margin:0 0 0 6px;width:24px}.c-article-header{margin-bottom:32px}@media only screen and (min-width:876px){.js .c-ad--conditional{display:block}}.u-lazy-ad-wrapper{background-color:#fff;display:none;min-height:149px}@media only screen and (min-width:876px){.u-lazy-ad-wrapper{display:block}}p.c-ad__label{margin-bottom:4px}.c-ad--728x90{background-color:#fff;border-bottom:2px solid #cedbe0} } </style>
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .eds-c-header__brand img{height:24px;width:203px}.app-article-masthead__journal-link img{height:93px;width:72px}@media only screen and (min-width:769px){.app-article-masthead__journal-link img{height:161px;width:122px}} } </style>

        
        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href=/oscar-static/app-springerlink/css/core-darwin-9fe647df8f.css media="print" onload="this.media='all';this.onload=null">
        <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css"
              href="/oscar-static/app-springerlink/css/enhanced-darwin-article-d7fe830fea.css" media="print"
              onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">
    

        
        
    <script type="text/javascript">
        config = {
            env: 'live',
            site: '40593.springer.com',
            siteWithPath: '40593.springer.com' + window.location.pathname,
            twitterHashtag: '40593',
            cmsPrefix: 'https://studio-cms.springernature.com/studio/',
            
            
            
            
            publisherBrand: 'Springer',
            mustardcut: false
        };
    </script>

        




    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/s40593-025-00480-y","Page":"article","springerJournal":true,"Publishing Model":"Hybrid Access","Country":"US","japan":false,"doi":"10.1007-s40593-025-00480-y","Journal Id":40593,"Journal Title":"International Journal of Artificial Intelligence in Education","imprint":"Springer","Keywords":"Validation, Reading, Fluency, Assessment, Instrument, Automatic","kwrd":["Validation","Reading","Fluency","Assessment","Instrument","Automatic"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"open","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"vgzm.415900-10.1007-s40593-025-00480-y","Full HTML":"Y","Subject Codes":["SCI","SCI21000","SCO21000","SCI18067","SCI24032"],"pmc":["I","I21000","O21000","I18067","I24032"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"entitlement":{"accessDecision":"OpenAccess"},"content":{"serial":{"eissn":"1560-4306","pissn":"1560-4292"},"type":"Article","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"I","secondarySubjects":{"1":"Artificial Intelligence","2":"Educational Technology","3":"User Interfaces and Human Computer Interaction","4":"Computers and Education"},"secondarySubjectCodes":{"1":"I21000","2":"O21000","3":"I18067","4":"I24032"}},"sucode":"SC6","articleType":"ARTICLE","snt":["Speech Perception","Assessment and Testing","Speech and Audio Processing","Dental patient assessment","Speech and Language Therapy","Psychological Testing"]},"attributes":{"deliveryPlatform":"oscar"}},"page":{"attributes":{"environment":"live"},"category":{"pageType":"article"}},"Event Category":"Article"}];
    </script>











    <script data-test="springer-link-article-datalayer">
        window.dataLayer = window.dataLayer || [];
        window.dataLayer.push({
            ga4MeasurementId: 'G-B3E4QL2TPR',
            ga360TrackingId: 'UA-26408784-1',
            twitterId: 'o47a7',
            baiduId: 'aef3043f025ccf2305af8a194652d70b',
            ga4ServerUrl: 'https://collect.springer.com',
            imprint: 'springerlink',
                page: {
                    attributes:{
                        featureFlags: [
                            
                                { name: 'darwin-orion', active: true },
                            
                                { name: 'show-profile-page-links', active: true },
                            
                                { name: 'download-collection-test', active: false },
                            
                                { name: 'download-issue-test', active: false },
                            
                        ],
                        darwinAvailable: true
                    }
                }
            
        });
    </script>



        <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
            d.classList.remove('no-js');
        }
    })(window, document.documentElement);
</script>


        <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
                window.onArticlePage = true;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-b4356fa7f5.js', 'async': false}
            ];

            var bodyScripts = [
                
                    
                    {'src': '/oscar-static/js/global-article-es5-bundle-f45c6eaf2d.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-09cde44cd7.js', 'async': false, 'module': true}
                    
                
                
                    
                
                
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>



        
            
            
                
    <script data-test="gtm-head">
        window.initGTM = function () {
            if (window.config.mustardcut) {
                (function (w, d, s, l, i) {
                    w[l] = w[l] || [];
                    w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                    var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                    j.async = true;
                    j.src = 'https://sgtm.springer.com/gtm.js?id=' + i + dl;
                    f.parentNode.insertBefore(j, f);
                    performance.mark('SN GPT Ads gtm-container-fired');
                })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
            }
        }
    </script>

            
            
            
        

        <script>
(function (w, d, t) {
    function cc() {
        var h = w.location.hostname;
        var e = d.createElement(t),
        s = d.getElementsByTagName(t)[0];

        
        if (h.indexOf('springer.com') > -1 && h.indexOf('biomedcentral.com') === -1 && h.indexOf('springeropen.com') === -1) {
            e.src = 'https://cmp.springer.com/production_live/en/consent-bundle-17-71.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
        } else if (h.indexOf('biomedcentral.com') > -1) {
            e.src = 'https://cmp.biomedcentral.com/production_live/en/consent-bundle-15-46.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
        } else if (h.indexOf('springeropen.com') > -1) {
            e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-16-42.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
        } else if (h.indexOf('springernature.com') > -1) {
            e.src = 'https://cmp.springernature.com/production_live/en/consent-bundle-49-65.js';
            e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-NK22KLS')");
        } else {
            e.src = '/oscar-static/js/cookie-consent-es5-bundle-8d962b73c2.js';
            e.setAttribute('data-consent', h);
        }
        s.insertAdjacentElement('afterend', e);
    }

    cc();
})(window, document, 'script');
</script>


        
        
        
    
        
    

        
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s40593-025-00480-y"/>
    

        
        
        
        
        
    <script type="application/ld+json">{"mainEntity":{"headline":"Speech Enabled Reading Fluency Assessment: a Validation Study","description":"Although the ability to comprehend what one is reading is one of the most fundamental necessities to function within society, the reading comprehension skills of students have recently been on the decline in many countries. An essential prerequisite to reading comprehension is the ability to read fluently, which is defined as the ability to read (aloud) with accuracy, speed, automaticity and prosody. Current oral reading fluency assessment instruments seldom provide detailed diagnostics however, and bestow a heavy testing burden on practitioners. Recent developments in Artificial Intelligence-based assessment methodology might provide a solution to current assessment issues, but thorough validations of such procedures have proven scarce. This study evaluates whether valid word decoding and passage reading measures (accuracy, speed and automaticity) can be generated for a semi-transparent language, using an automatic speech recognition (ASR) based oral reading fluency assessment instrument. A validation study was conducted, using the Argument-Based Approach to Validation. Data concerned 176 h of speech data, and the results of 569 and 622 oral word- and passage reading tests that are currently administered in primary schools, from 653 children attending the second- or third grade of Dutch primary education. The results of the validation indicate that it is possible to generate fluency metrics for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument. Future researchers are advised to further optimize the ASR, evaluate its errors, and realize a prosody component, completing the envisioned reading fluency assessment instrument, thereby improving reading fluency assessment throughout primary education.","datePublished":"2025-05-14T00:00:00Z","dateModified":"2025-05-14T00:00:00Z","pageStart":"1","pageEnd":"27","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1007/s40593-025-00480-y","keywords":["Validation","Reading","Fluency","Assessment","Instrument","Automatic","Artificial Intelligence","Educational Technology","User Interfaces and Human Computer Interaction","Computers and Education"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig1_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig2_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig3_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig4_HTML.png","https://media.springernature.com/lw1200/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig5_HTML.png"],"isPartOf":{"name":"International Journal of Artificial Intelligence in Education","issn":["1560-4306","1560-4292"],"@type":["Periodical"]},"publisher":{"name":"Springer New York","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Max van der Velde","url":"http://orcid.org/0000-0003-4940-2521","affiliation":[{"name":"Cognition, Data and Education Section, Faculty of BMS, University of Twente","address":{"name":"Cognition, Data and Education Section, Faculty of BMS, University of Twente, Enschede, The Netherlands","@type":"PostalAddress"},"@type":"Organization"},{"name":"CitoLab, Cito","address":{"name":"CitoLab, Cito, Arnhem, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"email":"m.e.vandervelde@utwente.nl","@type":"Person"},{"name":"Wieke Harmsen","affiliation":[{"name":"Centre for Language Studies, Radboud University","address":{"name":"Centre for Language Studies, Radboud University, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Bernard P. Veldkamp","affiliation":[{"name":"Cognition, Data and Education Section, Faculty of BMS, University of Twente","address":{"name":"Cognition, Data and Education Section, Faculty of BMS, University of Twente, Enschede, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Remco Feskens","affiliation":[{"name":"Cognition, Data and Education Section, Faculty of BMS, University of Twente","address":{"name":"Cognition, Data and Education Section, Faculty of BMS, University of Twente, Enschede, The Netherlands","@type":"PostalAddress"},"@type":"Organization"},{"name":"CitoLab, Cito","address":{"name":"CitoLab, Cito, Arnhem, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Jos Keuning","affiliation":[{"name":"CitoLab, Cito","address":{"name":"CitoLab, Cito, Arnhem, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Nicole Swart","affiliation":[{"name":"Expertisecentrum Nederlands","address":{"name":"Expertisecentrum Nederlands, Nijmegen, The Netherlands","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org","@type":"WebPage"}</script>

        
        
    </head>

    <body class=""
    
          >
        <div class="u-visually-hidden" aria-hidden="true" data-test="darwin-icons">
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><clipPath id="a"><path d="M.5 0h24v24H.5z"/></clipPath><clipPath id="youtube-icon"><rect width="24" height="24"/></clipPath></defs><symbol id="icon-eds-i-accesses-medium" viewBox="0 0 24 24"><path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742H15a1 1 0 0 1 0-2h4.455a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM8 13c2.052 0 4.66 1.61 6.36 3.4l.124.141c.333.41.516.925.516 1.459 0 .6-.232 1.178-.64 1.599C12.666 21.388 10.054 23 8 23c-2.052 0-4.66-1.61-6.353-3.393A2.31 2.31 0 0 1 1 18c0-.6.232-1.178.64-1.6C3.34 14.61 5.948 13 8 13Zm0 2c-1.369 0-3.552 1.348-4.917 2.785A.31.31 0 0 0 3 18c0 .083.031.161.09.222C4.447 19.652 6.631 21 8 21c1.37 0 3.556-1.35 4.917-2.785A.31.31 0 0 0 13 18a.32.32 0 0 0-.048-.17l-.042-.052C11.553 16.348 9.369 15 8 15Zm0 1a2 2 0 1 1 0 4 2 2 0 0 1 0-4Z"/></symbol><symbol id="icon-eds-i-altmetric-medium" viewBox="0 0 24 24"><path d="M12 1c5.978 0 10.843 4.77 10.996 10.712l.004.306-.002.022-.002.248C22.843 18.23 17.978 23 12 23 5.925 23 1 18.075 1 12S5.925 1 12 1Zm-1.726 9.246L8.848 12.53a1 1 0 0 1-.718.461L8.003 13l-4.947.014a9.001 9.001 0 0 0 17.887-.001L16.553 13l-2.205 3.53a1 1 0 0 1-1.735-.068l-.05-.11-2.289-6.106ZM12 3a9.001 9.001 0 0 0-8.947 8.013l4.391-.012L9.652 7.47a1 1 0 0 1 1.784.179l2.288 6.104 1.428-2.283a1 1 0 0 1 .722-.462l.129-.008 4.943.012A9.001 9.001 0 0 0 12 3Z"/></symbol><symbol id="icon-eds-i-arrow-bend-down-medium" viewBox="0 0 24 24"><path d="m11.852 20.989.058.007L12 21l.075-.003.126-.017.111-.03.111-.044.098-.052.104-.074.082-.073 6-6a1 1 0 0 0-1.414-1.414L13 17.585v-12.2C13 4.075 11.964 3 10.667 3H4a1 1 0 1 0 0 2h6.667c.175 0 .333.164.333.385v12.2l-4.293-4.292a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414l6 6c.035.036.073.068.112.097l.11.071.114.054.105.035.118.025Z"/></symbol><symbol id="icon-eds-i-arrow-bend-down-small" viewBox="0 0 16 16"><path d="M1 2a1 1 0 0 0 1 1h5v8.585L3.707 8.293a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414l5 5 .063.059.093.069.081.048.105.048.104.035.105.022.096.01h.136l.122-.018.113-.03.103-.04.1-.053.102-.07.052-.043 5.04-5.037a1 1 0 1 0-1.415-1.414L9 11.583V3a2 2 0 0 0-2-2H2a1 1 0 0 0-1 1Z"/></symbol><symbol id="icon-eds-i-arrow-bend-up-medium" viewBox="0 0 24 24"><path d="m11.852 3.011.058-.007L12 3l.075.003.126.017.111.03.111.044.098.052.104.074.082.073 6 6a1 1 0 1 1-1.414 1.414L13 6.415v12.2C13 19.925 11.964 21 10.667 21H4a1 1 0 0 1 0-2h6.667c.175 0 .333-.164.333-.385v-12.2l-4.293 4.292a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l6-6c.035-.036.073-.068.112-.097l.11-.071.114-.054.105-.035.118-.025Z"/></symbol><symbol id="icon-eds-i-arrow-bend-up-small" viewBox="0 0 16 16"><path d="M1 13.998a1 1 0 0 1 1-1h5V4.413L3.707 7.705a1 1 0 0 1-1.32.084l-.094-.084a1 1 0 0 1 0-1.414l5-5 .063-.059.093-.068.081-.05.105-.047.104-.035.105-.022L7.94 1l.136.001.122.017.113.03.103.04.1.053.102.07.052.043 5.04 5.037a1 1 0 1 1-1.415 1.414L9 4.415v8.583a2 2 0 0 1-2 2H2a1 1 0 0 1-1-1Z"/></symbol><symbol id="icon-eds-i-arrow-diagonal-medium" viewBox="0 0 24 24"><path d="M14 3h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L21 4v6a1 1 0 0 1-2 0V6.414l-4.293 4.293a1 1 0 0 1-1.414-1.414L17.584 5H14a1 1 0 0 1-.993-.883L13 4a1 1 0 0 1 1-1ZM4 13a1 1 0 0 1 1 1v3.584l4.293-4.291a1 1 0 1 1 1.414 1.414L6.414 19H10a1 1 0 0 1 .993.883L11 20a1 1 0 0 1-1 1l-6.075-.003-.126-.017-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08a1.01 1.01 0 0 1-.097-.112l-.071-.11-.054-.114-.035-.105-.025-.118-.007-.058L3 20v-6a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-arrow-diagonal-small" viewBox="0 0 16 16"><path d="m2 15-.082-.004-.119-.016-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08a1.008 1.008 0 0 1-.097-.112l-.071-.11-.031-.062-.034-.081-.024-.076-.025-.118-.007-.058L1 14.02V9a1 1 0 1 1 2 0v2.584l2.793-2.791a1 1 0 1 1 1.414 1.414L4.414 13H7a1 1 0 0 1 .993.883L8 14a1 1 0 0 1-1 1H2ZM14 1l.081.003.12.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.031.062.034.081.024.076.03.148L15 2v5a1 1 0 0 1-2 0V4.414l-2.96 2.96A1 1 0 1 1 8.626 5.96L11.584 3H9a1 1 0 0 1-.993-.883L8 2a1 1 0 0 1 1-1h5Z"/></symbol><symbol id="icon-eds-i-arrow-down-medium" viewBox="0 0 24 24"><path d="m20.707 12.728-7.99 7.98a.996.996 0 0 1-.561.281l-.157.011a.998.998 0 0 1-.788-.384l-7.918-7.908a1 1 0 0 1 1.414-1.416L11 17.576V4a1 1 0 0 1 2 0v13.598l6.293-6.285a1 1 0 0 1 1.32-.082l.095.083a1 1 0 0 1-.001 1.414Z"/></symbol><symbol id="icon-eds-i-arrow-down-small" viewBox="0 0 16 16"><path d="m1.293 8.707 6 6 .063.059.093.069.081.048.105.049.104.034.056.013.118.017L8 15l.076-.003.122-.017.113-.03.085-.032.063-.03.098-.058.06-.043.05-.043 6.04-6.037a1 1 0 0 0-1.414-1.414L9 11.583V2a1 1 0 1 0-2 0v9.585L2.707 7.293a1 1 0 0 0-1.32-.083l-.094.083a1 1 0 0 0 0 1.414Z"/></symbol><symbol id="icon-eds-i-arrow-left-medium" viewBox="0 0 24 24"><path d="m11.272 3.293-7.98 7.99a.996.996 0 0 0-.281.561L3 12.001c0 .32.15.605.384.788l7.908 7.918a1 1 0 0 0 1.416-1.414L6.424 13H20a1 1 0 0 0 0-2H6.402l6.285-6.293a1 1 0 0 0 .082-1.32l-.083-.095a1 1 0 0 0-1.414.001Z"/></symbol><symbol id="icon-eds-i-arrow-left-small" viewBox="0 0 16 16"><path d="m7.293 1.293-6 6-.059.063-.069.093-.048.081-.049.105-.034.104-.013.056-.017.118L1 8l.003.076.017.122.03.113.032.085.03.063.058.098.043.06.043.05 6.037 6.04a1 1 0 0 0 1.414-1.414L4.417 9H14a1 1 0 0 0 0-2H4.415l4.292-4.293a1 1 0 0 0 .083-1.32l-.083-.094a1 1 0 0 0-1.414 0Z"/></symbol><symbol id="icon-eds-i-arrow-right-medium" viewBox="0 0 24 24"><path d="m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z"/></symbol><symbol id="icon-eds-i-arrow-right-small" viewBox="0 0 16 16"><path d="m8.707 1.293 6 6 .059.063.069.093.048.081.049.105.034.104.013.056.017.118L15 8l-.003.076-.017.122-.03.113-.032.085-.03.063-.058.098-.043.06-.043.05-6.037 6.04a1 1 0 0 1-1.414-1.414L11.583 9H2a1 1 0 1 1 0-2h9.585L7.293 2.707a1 1 0 0 1-.083-1.32l.083-.094a1 1 0 0 1 1.414 0Z"/></symbol><symbol id="icon-eds-i-arrow-up-medium" viewBox="0 0 24 24"><path d="m3.293 11.272 7.99-7.98a.996.996 0 0 1 .561-.281L12.001 3c.32 0 .605.15.788.384l7.918 7.908a1 1 0 0 1-1.414 1.416L13 6.424V20a1 1 0 0 1-2 0V6.402l-6.293 6.285a1 1 0 0 1-1.32.082l-.095-.083a1 1 0 0 1 .001-1.414Z"/></symbol><symbol id="icon-eds-i-arrow-up-small" viewBox="0 0 16 16"><path d="m1.293 7.293 6-6 .063-.059.093-.069.081-.048.105-.049.104-.034.056-.013.118-.017L8 1l.076.003.122.017.113.03.085.032.063.03.098.058.06.043.05.043 6.04 6.037a1 1 0 0 1-1.414 1.414L9 4.417V14a1 1 0 0 1-2 0V4.415L2.707 8.707a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414Z"/></symbol><symbol id="icon-eds-i-article-medium" viewBox="0 0 24 24"><path d="M8 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H8ZM8 11a1 1 0 1 0 0 2h8a1 1 0 1 0 0-2H8ZM7 16a1 1 0 0 1 1-1h8a1 1 0 1 1 0 2H8a1 1 0 0 1-1-1Z"/><path d="M5.545 1A2.542 2.542 0 0 0 3 3.538v16.924A2.542 2.542 0 0 0 5.545 23h12.91A2.542 2.542 0 0 0 21 20.462V3.5A2.5 2.5 0 0 0 18.5 1H5.545ZM5 3.538C5 3.245 5.24 3 5.545 3H18.5a.5.5 0 0 1 .5.5v16.962c0 .293-.24.538-.546.538H5.545A.542.542 0 0 1 5 20.462V3.538Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-book-medium" viewBox="0 0 24 24"><path d="M18.5 1A2.5 2.5 0 0 1 21 3.5v12c0 1.16-.79 2.135-1.86 2.418l-.14.031V21h1a1 1 0 0 1 .993.883L21 22a1 1 0 0 1-1 1H6.5A3.5 3.5 0 0 1 3 19.5v-15A3.5 3.5 0 0 1 6.5 1h12ZM17 18H6.5a1.5 1.5 0 0 0-1.493 1.356L5 19.5A1.5 1.5 0 0 0 6.5 21H17v-3Zm1.5-15h-12A1.5 1.5 0 0 0 5 4.5v11.837l.054-.025a3.481 3.481 0 0 1 1.254-.307L6.5 16h12a.5.5 0 0 0 .492-.41L19 15.5v-12a.5.5 0 0 0-.5-.5ZM15 6a1 1 0 0 1 0 2H9a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-book-series-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M1 3.786C1 2.759 1.857 2 2.82 2H6.18c.964 0 1.82.759 1.82 1.786V4h3.168c.668 0 1.298.364 1.616.938.158-.109.333-.195.523-.252l3.216-.965c.923-.277 1.962.204 2.257 1.187l4.146 13.82c.296.984-.307 1.957-1.23 2.234l-3.217.965c-.923.277-1.962-.203-2.257-1.187L13 10.005v10.21c0 1.04-.878 1.785-1.834 1.785H7.833c-.291 0-.575-.07-.83-.195A1.849 1.849 0 0 1 6.18 22H2.821C1.857 22 1 21.241 1 20.214V3.786ZM3 4v11h3V4H3Zm0 16v-3h3v3H3Zm15.075-.04-.814-2.712 2.874-.862.813 2.712-2.873.862Zm1.485-5.49-2.874.862-2.634-8.782 2.873-.862 2.635 8.782ZM8 20V6h3v14H8Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-calendar-acceptance-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-.534 7.747a1 1 0 0 1 .094 1.412l-4.846 5.538a1 1 0 0 1-1.352.141l-2.77-2.076a1 1 0 0 1 1.2-1.6l2.027 1.519 4.236-4.84a1 1 0 0 1 1.411-.094ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-date-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1ZM8 15a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm-4-4a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2Zm4 0a1 1 0 1 1 0 2 1 1 0 0 1 0-2ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-decision-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-2.935 8.246 2.686 2.645c.34.335.34.883 0 1.218l-2.686 2.645a.858.858 0 0 1-1.213-.009.854.854 0 0 1 .009-1.21l1.05-1.035H7.984a.992.992 0 0 1-.984-1c0-.552.44-1 .984-1h5.928l-1.051-1.036a.854.854 0 0 1-.085-1.121l.076-.088a.858.858 0 0 1 1.213-.009ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-calendar-impact-factor-medium" viewBox="0 0 24 24"><path d="M17 2a1 1 0 0 1 1 1v1h1.5C20.817 4 22 5.183 22 6.5v13c0 1.317-1.183 2.5-2.5 2.5h-15C3.183 22 2 20.817 2 19.5v-13C2 5.183 3.183 4 4.5 4a1 1 0 1 1 0 2c-.212 0-.5.288-.5.5v13c0 .212.288.5.5.5h15c.212 0 .5-.288.5-.5v-13c0-.212-.288-.5-.5-.5H18v1a1 1 0 0 1-2 0V3a1 1 0 0 1 1-1Zm-3.2 6.924a.48.48 0 0 1 .125.544l-1.52 3.283h2.304c.27 0 .491.215.491.483a.477.477 0 0 1-.13.327l-4.18 4.484a.498.498 0 0 1-.69.031.48.48 0 0 1-.125-.544l1.52-3.284H9.291a.487.487 0 0 1-.491-.482c0-.121.047-.238.13-.327l4.18-4.484a.498.498 0 0 1 .69-.031ZM7.5 2a1 1 0 0 1 1 1v1H14a1 1 0 0 1 0 2H8.5v1a1 1 0 1 1-2 0V3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-call-papers-medium" viewBox="0 0 24 24"><g><path d="m20.707 2.883-1.414 1.414a1 1 0 0 0 1.414 1.414l1.414-1.414a1 1 0 0 0-1.414-1.414Z"/><path d="M6 16.054c0 2.026 1.052 2.943 3 2.943a1 1 0 1 1 0 2c-2.996 0-5-1.746-5-4.943v-1.227a4.068 4.068 0 0 1-1.83-1.189 4.553 4.553 0 0 1-.87-1.455 4.868 4.868 0 0 1-.3-1.686c0-1.17.417-2.298 1.17-3.14.38-.426.834-.767 1.338-1 .51-.237 1.06-.36 1.617-.36L6.632 6H7l7.932-2.895A2.363 2.363 0 0 1 18 5.36v9.28a2.36 2.36 0 0 1-3.069 2.25l.084.03L7 14.997H6v1.057Zm9.637-11.057a.415.415 0 0 0-.083.008L8 7.638v5.536l7.424 1.786.104.02c.035.01.072.02.109.02.2 0 .363-.16.363-.36V5.36c0-.2-.163-.363-.363-.363Zm-9.638 3h-.874a1.82 1.82 0 0 0-.625.111l-.15.063a2.128 2.128 0 0 0-.689.517c-.42.47-.661 1.123-.661 1.81 0 .34.06.678.176.992.114.308.28.585.485.816.4.447.925.691 1.464.691h.874v-5Z" clip-rule="evenodd"/><path d="M20 8.997h2a1 1 0 1 1 0 2h-2a1 1 0 1 1 0-2ZM20.707 14.293l1.414 1.414a1 1 0 0 1-1.414 1.414l-1.414-1.414a1 1 0 0 1 1.414-1.414Z"/></g></symbol><symbol id="icon-eds-i-card-medium" viewBox="0 0 24 24"><path d="M19.615 2c.315 0 .716.067 1.14.279.76.38 1.245 1.107 1.245 2.106v15.23c0 .315-.067.716-.279 1.14-.38.76-1.107 1.245-2.106 1.245H4.385a2.56 2.56 0 0 1-1.14-.279C2.485 21.341 2 20.614 2 19.615V4.385c0-.315.067-.716.279-1.14C2.659 2.485 3.386 2 4.385 2h15.23Zm0 2H4.385c-.213 0-.265.034-.317.14A.71.71 0 0 0 4 4.385v15.23c0 .213.034.265.14.317a.71.71 0 0 0 .245.068h15.23c.213 0 .265-.034.317-.14a.71.71 0 0 0 .068-.245V4.385c0-.213-.034-.265-.14-.317A.71.71 0 0 0 19.615 4ZM17 16a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h10Zm0-3a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h10Zm-.5-7A1.5 1.5 0 0 1 18 7.5v3a1.5 1.5 0 0 1-1.5 1.5h-9A1.5 1.5 0 0 1 6 10.5v-3A1.5 1.5 0 0 1 7.5 6h9ZM16 8H8v2h8V8Z"/></symbol><symbol id="icon-eds-i-cart-medium" viewBox="0 0 24 24"><path d="M5.76 1a1 1 0 0 1 .994.902L7.155 6h13.34c.18 0 .358.02.532.057l.174.045a2.5 2.5 0 0 1 1.693 3.103l-2.069 7.03c-.36 1.099-1.398 1.823-2.49 1.763H8.65c-1.272.015-2.352-.927-2.546-2.244L4.852 3H2a1 1 0 0 1-.993-.883L1 2a1 1 0 0 1 1-1h3.76Zm2.328 14.51a.555.555 0 0 0 .55.488l9.751.001a.533.533 0 0 0 .527-.357l2.059-7a.5.5 0 0 0-.48-.642H7.351l.737 7.51ZM18 19a2 2 0 1 1 0 4 2 2 0 0 1 0-4ZM8 19a2 2 0 1 1 0 4 2 2 0 0 1 0-4Z"/></symbol><symbol id="icon-eds-i-check-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm5.125 4.72a1 1 0 0 1 .156 1.405l-6 7.5a1 1 0 0 1-1.421.143l-3-2.5a1 1 0 0 1 1.28-1.536l2.217 1.846 5.362-6.703a1 1 0 0 1 1.406-.156Z"/></symbol><symbol id="icon-eds-i-check-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm5.125 6.72a1 1 0 0 0-1.406.155l-5.362 6.703-2.217-1.846a1 1 0 1 0-1.28 1.536l3 2.5a1 1 0 0 0 1.42-.143l6-7.5a1 1 0 0 0-.155-1.406Z"/></symbol><symbol id="icon-eds-i-chevron-down-medium" viewBox="0 0 24 24"><path d="M3.305 8.28a1 1 0 0 0-.024 1.415l7.495 7.762c.314.345.757.543 1.224.543.467 0 .91-.198 1.204-.522l7.515-7.783a1 1 0 1 0-1.438-1.39L12 15.845l-7.28-7.54A1 1 0 0 0 3.4 8.2l-.096.082Z"/></symbol><symbol id="icon-eds-i-chevron-down-small" viewBox="0 0 16 16"><path d="M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z"/></symbol><symbol id="icon-eds-i-chevron-left-medium" viewBox="0 0 24 24"><path d="M15.72 3.305a1 1 0 0 0-1.415-.024l-7.762 7.495A1.655 1.655 0 0 0 6 12c0 .467.198.91.522 1.204l7.783 7.515a1 1 0 1 0 1.39-1.438L8.155 12l7.54-7.28A1 1 0 0 0 15.8 3.4l-.082-.096Z"/></symbol><symbol id="icon-eds-i-chevron-left-small" viewBox="0 0 16 16"><path d="M10.722 2.308a1 1 0 0 0-1.414-.03L4.49 6.897a1.491 1.491 0 0 0-.019 2.188l4.838 4.637a1 1 0 1 0 1.384-1.444L6.229 8l4.463-4.278a1 1 0 0 0 .111-1.318l-.081-.096Z"/></symbol><symbol id="icon-eds-i-chevron-right-medium" viewBox="0 0 24 24"><path d="M8.28 3.305a1 1 0 0 1 1.415-.024l7.762 7.495c.345.314.543.757.543 1.224 0 .467-.198.91-.522 1.204l-7.783 7.515a1 1 0 1 1-1.39-1.438L15.845 12l-7.54-7.28A1 1 0 0 1 8.2 3.4l.082-.096Z"/></symbol><symbol id="icon-eds-i-chevron-right-small" viewBox="0 0 16 16"><path d="M5.278 2.308a1 1 0 0 1 1.414-.03l4.819 4.619a1.491 1.491 0 0 1 .019 2.188l-4.838 4.637a1 1 0 1 1-1.384-1.444L9.771 8 5.308 3.722a1 1 0 0 1-.111-1.318l.081-.096Z"/></symbol><symbol id="icon-eds-i-chevron-up-medium" viewBox="0 0 24 24"><path d="M20.695 15.72a1 1 0 0 0 .024-1.415l-7.495-7.762A1.655 1.655 0 0 0 12 6c-.467 0-.91.198-1.204.522l-7.515 7.783a1 1 0 1 0 1.438 1.39L12 8.155l7.28 7.54a1 1 0 0 0 1.319.106l.096-.082Z"/></symbol><symbol id="icon-eds-i-chevron-up-small" viewBox="0 0 16 16"><path d="M13.692 10.722a1 1 0 0 0 .03-1.414L9.103 4.49a1.491 1.491 0 0 0-2.188-.019L2.278 9.308a1 1 0 0 0 1.444 1.384L8 6.229l4.278 4.463a1 1 0 0 0 1.318.111l.096-.081Z"/></symbol><symbol id="icon-eds-i-citations-medium" viewBox="0 0 24 24"><path d="M15.59 1a1 1 0 0 1 .706.291l5.41 5.385a1 1 0 0 1 .294.709v13.077c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742h-5.843a1 1 0 1 1 0-2h5.843a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.8L15.178 3H5.545a.543.543 0 0 0-.538.451L5 3.538v8.607a1 1 0 0 1-2 0V3.538A2.542 2.542 0 0 1 5.545 1h10.046ZM5.483 14.35c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Zm5 0c.197.26.17.62-.049.848l-.095.083-.016.011c-.36.24-.628.45-.804.634-.393.409-.59.93-.59 1.562.077-.019.192-.028.345-.028.442 0 .84.158 1.195.474.355.316.532.716.532 1.2 0 .501-.173.9-.518 1.198-.345.298-.767.446-1.266.446-.672 0-1.209-.195-1.612-.585-.403-.39-.604-.976-.604-1.757 0-.744.11-1.39.33-1.938.222-.549.49-1.009.807-1.38a4.28 4.28 0 0 1 .992-.88c.07-.043.148-.087.232-.133a.881.881 0 0 1 1.121.245Z"/></symbol><symbol id="icon-eds-i-clipboard-check-medium" viewBox="0 0 24 24"><path d="M14.4 1c1.238 0 2.274.865 2.536 2.024L18.5 3C19.886 3 21 4.14 21 5.535v14.93C21 21.86 19.886 23 18.5 23h-13C4.114 23 3 21.86 3 20.465V5.535C3 4.14 4.114 3 5.5 3h1.57c.27-1.147 1.3-2 2.53-2h4.8Zm4.115 4-1.59.024A2.601 2.601 0 0 1 14.4 7H9.6c-1.23 0-2.26-.853-2.53-2H5.5c-.27 0-.5.234-.5.535v14.93c0 .3.23.535.5.535h13c.27 0 .5-.234.5-.535V5.535c0-.3-.23-.535-.485-.535Zm-1.909 4.205a1 1 0 0 1 .19 1.401l-5.334 7a1 1 0 0 1-1.344.23l-2.667-1.75a1 1 0 1 1 1.098-1.672l1.887 1.238 4.769-6.258a1 1 0 0 1 1.401-.19ZM14.4 3H9.6a.6.6 0 0 0-.6.6v.8a.6.6 0 0 0 .6.6h4.8a.6.6 0 0 0 .6-.6v-.8a.6.6 0 0 0-.6-.6Z"/></symbol><symbol id="icon-eds-i-clipboard-report-medium" viewBox="0 0 24 24"><path d="M14.4 1c1.238 0 2.274.865 2.536 2.024L18.5 3C19.886 3 21 4.14 21 5.535v14.93C21 21.86 19.886 23 18.5 23h-13C4.114 23 3 21.86 3 20.465V5.535C3 4.14 4.114 3 5.5 3h1.57c.27-1.147 1.3-2 2.53-2h4.8Zm4.115 4-1.59.024A2.601 2.601 0 0 1 14.4 7H9.6c-1.23 0-2.26-.853-2.53-2H5.5c-.27 0-.5.234-.5.535v14.93c0 .3.23.535.5.535h13c.27 0 .5-.234.5-.535V5.535c0-.3-.23-.535-.485-.535Zm-2.658 10.929a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h7.857Zm0-3.929a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h7.857ZM14.4 3H9.6a.6.6 0 0 0-.6.6v.8a.6.6 0 0 0 .6.6h4.8a.6.6 0 0 0 .6-.6v-.8a.6.6 0 0 0-.6-.6Z"/></symbol><symbol id="icon-eds-i-close-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM8.707 7.293 12 10.585l3.293-3.292a1 1 0 0 1 1.414 1.414L13.415 12l3.292 3.293a1 1 0 0 1-1.414 1.414L12 13.415l-3.293 3.292a1 1 0 1 1-1.414-1.414L10.585 12 7.293 8.707a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-cloud-upload-medium" viewBox="0 0 24 24"><path d="m12.852 10.011.028-.004L13 10l.075.003.126.017.086.022.136.052.098.052.104.074.082.073 3 3a1 1 0 0 1 0 1.414l-.094.083a1 1 0 0 1-1.32-.083L14 13.416V20a1 1 0 0 1-2 0v-6.586l-1.293 1.293a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l3-3 .112-.097.11-.071.114-.054.105-.035.118-.025Zm.587-7.962c3.065.362 5.497 2.662 5.992 5.562l.013.085.207.073c2.117.782 3.496 2.845 3.337 5.097l-.022.226c-.297 2.561-2.503 4.491-5.124 4.502a1 1 0 1 1-.009-2c1.619-.007 2.967-1.186 3.147-2.733.179-1.542-.86-2.979-2.487-3.353-.512-.149-.894-.579-.981-1.165-.21-2.237-2-4.035-4.308-4.308-2.31-.273-4.497 1.06-5.25 3.19l-.049.113c-.234.468-.718.756-1.176.743-1.418.057-2.689.857-3.32 2.084a3.668 3.668 0 0 0 .262 3.798c.796 1.136 2.169 1.764 3.583 1.635a1 1 0 1 1 .182 1.992c-2.125.194-4.193-.753-5.403-2.48a5.668 5.668 0 0 1-.403-5.86c.85-1.652 2.449-2.79 4.323-3.092l.287-.039.013-.028c1.207-2.741 4.125-4.404 7.186-4.042Z"/></symbol><symbol id="icon-eds-i-collection-medium" viewBox="0 0 24 24"><path d="M21 7a1 1 0 0 1 1 1v12.5a2.5 2.5 0 0 1-2.5 2.5H8a1 1 0 0 1 0-2h11.5a.5.5 0 0 0 .5-.5V8a1 1 0 0 1 1-1Zm-5.5-5A2.5 2.5 0 0 1 18 4.5v12a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 2 16.5v-12A2.5 2.5 0 0 1 4.5 2h11Zm0 2h-11a.5.5 0 0 0-.5.5v12a.5.5 0 0 0 .5.5h11a.5.5 0 0 0 .5-.5v-12a.5.5 0 0 0-.5-.5ZM13 13a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h6Zm0-3.5a1 1 0 0 1 0 2H7a1 1 0 0 1 0-2h6ZM13 6a1 1 0 0 1 0 2H7a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-conference-series-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M4.5 2A2.5 2.5 0 0 0 2 4.5v11A2.5 2.5 0 0 0 4.5 18h2.37l-2.534 2.253a1 1 0 0 0 1.328 1.494L9.88 18H11v3a1 1 0 1 0 2 0v-3h1.12l4.216 3.747a1 1 0 0 0 1.328-1.494L17.13 18h2.37a2.5 2.5 0 0 0 2.5-2.5v-11A2.5 2.5 0 0 0 19.5 2h-15ZM20 6V4.5a.5.5 0 0 0-.5-.5h-15a.5.5 0 0 0-.5.5V6h16ZM4 8v7.5a.5.5 0 0 0 .5.5h15a.5.5 0 0 0 .5-.5V8H4Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-delivery-medium" viewBox="0 0 24 24"><path d="M8.51 20.598a3.037 3.037 0 0 1-3.02 0A2.968 2.968 0 0 1 4.161 19L3.5 19A2.5 2.5 0 0 1 1 16.5v-11A2.5 2.5 0 0 1 3.5 3h10a2.5 2.5 0 0 1 2.45 2.004L16 5h2.527c.976 0 1.855.585 2.27 1.49l2.112 4.62a1 1 0 0 1 .091.416v4.856C23 17.814 21.889 19 20.484 19h-.523a1.01 1.01 0 0 1-.121-.007 2.96 2.96 0 0 1-1.33 1.605 3.037 3.037 0 0 1-3.02 0A2.968 2.968 0 0 1 14.161 19H9.838a2.968 2.968 0 0 1-1.327 1.597Zm-2.024-3.462a.955.955 0 0 0-.481.73L5.999 18l.001.022a.944.944 0 0 0 .388.777l.098.065c.316.181.712.181 1.028 0A.97.97 0 0 0 8 17.978a.95.95 0 0 0-.486-.842 1.037 1.037 0 0 0-1.028 0Zm10 0a.955.955 0 0 0-.481.73l-.005.156a.944.944 0 0 0 .388.777l.098.065c.316.181.712.181 1.028 0a.97.97 0 0 0 .486-.886.95.95 0 0 0-.486-.842 1.037 1.037 0 0 0-1.028 0ZM21 12h-5v3.17a3.038 3.038 0 0 1 2.51.232 2.993 2.993 0 0 1 1.277 1.45l.058.155.058-.005.581-.002c.27 0 .516-.263.516-.618V12Zm-7.5-7h-10a.5.5 0 0 0-.5.5v11a.5.5 0 0 0 .5.5h.662a2.964 2.964 0 0 1 1.155-1.491l.172-.107a3.037 3.037 0 0 1 3.022 0A2.987 2.987 0 0 1 9.843 17H13.5a.5.5 0 0 0 .5-.5v-11a.5.5 0 0 0-.5-.5Zm5.027 2H16v3h4.203l-1.224-2.677a.532.532 0 0 0-.375-.316L18.527 7Z"/></symbol><symbol id="icon-eds-i-download-medium" viewBox="0 0 24 24"><path d="M22 18.5a3.5 3.5 0 0 1-3.5 3.5h-13A3.5 3.5 0 0 1 2 18.5V18a1 1 0 0 1 2 0v.5A1.5 1.5 0 0 0 5.5 20h13a1.5 1.5 0 0 0 1.5-1.5V18a1 1 0 0 1 2 0v.5Zm-3.293-7.793-6 6-.063.059-.093.069-.081.048-.105.049-.104.034-.056.013-.118.017L12 17l-.076-.003-.122-.017-.113-.03-.085-.032-.063-.03-.098-.058-.06-.043-.05-.043-6.04-6.037a1 1 0 0 1 1.414-1.414l4.294 4.29L11 3a1 1 0 0 1 2 0l.001 10.585 4.292-4.292a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414Z"/></symbol><symbol id="icon-eds-i-edit-medium" viewBox="0 0 24 24"><path d="M17.149 2a2.38 2.38 0 0 1 1.699.711l2.446 2.46a2.384 2.384 0 0 1 .005 3.38L10.01 19.906a1 1 0 0 1-.434.257l-6.3 1.8a1 1 0 0 1-1.237-1.237l1.8-6.3a1 1 0 0 1 .257-.434L15.443 2.718A2.385 2.385 0 0 1 17.15 2Zm-3.874 5.689-7.586 7.536-1.234 4.319 4.318-1.234 7.54-7.582-3.038-3.039ZM17.149 4a.395.395 0 0 0-.286.126L14.695 6.28l3.029 3.029 2.162-2.173a.384.384 0 0 0 .106-.197L20 6.864c0-.103-.04-.2-.119-.278l-2.457-2.47A.385.385 0 0 0 17.149 4Z"/></symbol><symbol id="icon-eds-i-education-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M12.41 2.088a1 1 0 0 0-.82 0l-10 4.5a1 1 0 0 0 0 1.824L3 9.047v7.124A3.001 3.001 0 0 0 4 22a3 3 0 0 0 1-5.83V9.948l1 .45V14.5a1 1 0 0 0 .087.408L7 14.5c-.913.408-.912.41-.912.41l.001.003.003.006.007.015a1.988 1.988 0 0 0 .083.16c.054.097.131.225.236.373.21.297.53.68.993 1.057C8.351 17.292 9.824 18 12 18c2.176 0 3.65-.707 4.589-1.476.463-.378.783-.76.993-1.057a4.162 4.162 0 0 0 .319-.533l.007-.015.003-.006v-.003h.002s0-.002-.913-.41l.913.408A1 1 0 0 0 18 14.5v-4.103l4.41-1.985a1 1 0 0 0 0-1.824l-10-4.5ZM16 11.297l-3.59 1.615a1 1 0 0 1-.82 0L8 11.297v2.94a3.388 3.388 0 0 0 .677.739C9.267 15.457 10.294 16 12 16s2.734-.543 3.323-1.024a3.388 3.388 0 0 0 .677-.739v-2.94ZM4.437 7.5 12 4.097 19.563 7.5 12 10.903 4.437 7.5ZM3 19a1 1 0 1 1 2 0 1 1 0 0 1-2 0Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-error-diamond-medium" viewBox="0 0 24 24"><path d="M12.002 1c.702 0 1.375.279 1.871.775l8.35 8.353a2.646 2.646 0 0 1 .001 3.744l-8.353 8.353a2.646 2.646 0 0 1-3.742 0l-8.353-8.353a2.646 2.646 0 0 1 0-3.744l8.353-8.353.156-.142c.424-.362.952-.58 1.507-.625l.21-.008Zm0 2a.646.646 0 0 0-.38.123l-.093.08-8.34 8.34a.646.646 0 0 0-.18.355L3 12c0 .171.068.336.19.457l8.353 8.354a.646.646 0 0 0 .914 0l8.354-8.354a.646.646 0 0 0-.001-.914l-8.351-8.354A.646.646 0 0 0 12.002 3ZM12 14.5a1.5 1.5 0 0 1 .144 2.993L12 17.5a1.5 1.5 0 0 1 0-3ZM12 6a1 1 0 0 1 1 1v5a1 1 0 0 1-2 0V7a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-error-filled-medium" viewBox="0 0 24 24"><path d="M12.002 1c.702 0 1.375.279 1.871.775l8.35 8.353a2.646 2.646 0 0 1 .001 3.744l-8.353 8.353a2.646 2.646 0 0 1-3.742 0l-8.353-8.353a2.646 2.646 0 0 1 0-3.744l8.353-8.353.156-.142c.424-.362.952-.58 1.507-.625l.21-.008ZM12 14.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 14.5ZM12 6a1 1 0 0 0-1 1v5a1 1 0 0 0 2 0V7a1 1 0 0 0-1-1Z"/></symbol><symbol id="icon-eds-i-external-link-medium" viewBox="0 0 24 24"><path d="M9 2a1 1 0 1 1 0 2H4.6c-.371 0-.6.209-.6.5v15c0 .291.229.5.6.5h14.8c.371 0 .6-.209.6-.5V15a1 1 0 0 1 2 0v4.5c0 1.438-1.162 2.5-2.6 2.5H4.6C3.162 22 2 20.938 2 19.5v-15C2 3.062 3.162 2 4.6 2H9Zm6 0h6l.075.003.126.017.111.03.111.044.098.052.096.067.09.08c.036.035.068.073.097.112l.071.11.054.114.035.105.03.148L22 3v6a1 1 0 0 1-2 0V5.414l-6.693 6.693a1 1 0 0 1-1.414-1.414L18.584 4H15a1 1 0 0 1-.993-.883L14 3a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-external-link-small" viewBox="0 0 16 16"><path d="M5 1a1 1 0 1 1 0 2l-2-.001V13L13 13v-2a1 1 0 0 1 2 0v2c0 1.15-.93 2-2.067 2H3.067C1.93 15 1 14.15 1 13V3c0-1.15.93-2 2.067-2H5Zm4 0h5l.075.003.126.017.111.03.111.044.098.052.096.067.09.08.044.047.073.093.051.083.054.113.035.105.03.148L15 2v5a1 1 0 0 1-2 0V4.414L9.107 8.307a1 1 0 0 1-1.414-1.414L11.584 3H9a1 1 0 0 1-.993-.883L8 2a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-file-download-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3ZM12 7a1 1 0 0 1 1 1v6.585l2.293-2.292a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414l-4 4a1.008 1.008 0 0 1-.112.097l-.11.071-.114.054-.105.035-.149.03L12 18l-.075-.003-.126-.017-.111-.03-.111-.044-.098-.052-.096-.067-.09-.08-4-4a1 1 0 0 1 1.414-1.414L11 14.585V8a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-file-report-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962c0 .674-.269 1.32-.747 1.796a2.549 2.549 0 0 1-1.798.742H5.545c-.674 0-1.32-.267-1.798-.742A2.535 2.535 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .142.057.278.158.379.102.102.242.159.387.159h12.91a.549.549 0 0 0 .387-.16.535.535 0 0 0 .158-.378V7.915L14.085 3ZM16 17a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm0-3a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm-4.793-6.207L13 9.585l1.793-1.792a1 1 0 0 1 1.32-.083l.094.083a1 1 0 0 1 0 1.414l-2.5 2.5a1 1 0 0 1-1.414 0L10.5 9.915l-1.793 1.792a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l2.5-2.5a1 1 0 0 1 1.414 0Z"/></symbol><symbol id="icon-eds-i-file-text-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3ZM16 15a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm0-4a1 1 0 0 1 0 2H8a1 1 0 0 1 0-2h8Zm-5-4a1 1 0 0 1 0 2H8a1 1 0 1 1 0-2h3Z"/></symbol><symbol id="icon-eds-i-file-upload-medium" viewBox="0 0 24 24"><path d="M14.5 1a1 1 0 0 1 .707.293l5.5 5.5A1 1 0 0 1 21 7.5v12.962A2.542 2.542 0 0 1 18.455 23H5.545A2.542 2.542 0 0 1 3 20.462V3.538A2.542 2.542 0 0 1 5.545 1H14.5Zm-.415 2h-8.54A.542.542 0 0 0 5 3.538v16.924c0 .296.243.538.545.538h12.91a.542.542 0 0 0 .545-.538V7.915L14.085 3Zm-2.233 4.011.058-.007L12 7l.075.003.126.017.111.03.111.044.098.052.104.074.082.073 4 4a1 1 0 0 1 0 1.414l-.094.083a1 1 0 0 1-1.32-.083L13 10.415V17a1 1 0 0 1-2 0v-6.585l-2.293 2.292a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l4-4 .112-.097.11-.071.114-.054.105-.035.118-.025Z"/></symbol><symbol id="icon-eds-i-filter-medium" viewBox="0 0 24 24"><path d="M21 2a1 1 0 0 1 .82 1.573L15 13.314V18a1 1 0 0 1-.31.724l-.09.076-4 3A1 1 0 0 1 9 21v-7.684L2.18 3.573a1 1 0 0 1 .707-1.567L3 2h18Zm-1.921 2H4.92l5.9 8.427a1 1 0 0 1 .172.45L11 13v6l2-1.5V13a1 1 0 0 1 .117-.469l.064-.104L19.079 4Z"/></symbol><symbol id="icon-eds-i-funding-medium" viewBox="0 0 24 24"><path fill-rule="evenodd" d="M23 8A7 7 0 1 0 9 8a7 7 0 0 0 14 0ZM9.006 12.225A4.07 4.07 0 0 0 6.12 11.02H2a.979.979 0 1 0 0 1.958h4.12c.558 0 1.094.222 1.489.617l2.207 2.288c.27.27.27.687.012.944a.656.656 0 0 1-.928 0L7.744 15.67a.98.98 0 0 0-1.386 1.384l1.157 1.158c.535.536 1.244.791 1.946.765l.041.002h6.922c.874 0 1.597.748 1.597 1.688 0 .203-.146.354-.309.354H7.755c-.487 0-.96-.178-1.339-.504L2.64 17.259a.979.979 0 0 0-1.28 1.482L5.137 22c.733.631 1.66.979 2.618.979h9.957c1.26 0 2.267-1.043 2.267-2.312 0-2.006-1.584-3.646-3.555-3.646h-4.529a2.617 2.617 0 0 0-.681-2.509l-2.208-2.287ZM16 3a5 5 0 1 0 0 10 5 5 0 0 0 0-10Zm.979 3.5a.979.979 0 1 0-1.958 0v3a.979.979 0 1 0 1.958 0v-3Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-hashtag-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18ZM9.52 18.189a1 1 0 1 1-1.964-.378l.437-2.274H6a1 1 0 1 1 0-2h2.378l.592-3.076H6a1 1 0 0 1 0-2h3.354l.51-2.65a1 1 0 1 1 1.964.378l-.437 2.272h3.04l.51-2.65a1 1 0 1 1 1.964.378l-.438 2.272H18a1 1 0 0 1 0 2h-1.917l-.592 3.076H18a1 1 0 0 1 0 2h-2.893l-.51 2.652a1 1 0 1 1-1.964-.378l.437-2.274h-3.04l-.51 2.652Zm.895-4.652h3.04l.591-3.076h-3.04l-.591 3.076Z"/></symbol><symbol id="icon-eds-i-home-medium" viewBox="0 0 24 24"><path d="M5 22a1 1 0 0 1-1-1v-8.586l-1.293 1.293a1 1 0 0 1-1.32.083l-.094-.083a1 1 0 0 1 0-1.414l10-10a1 1 0 0 1 1.414 0l10 10a1 1 0 0 1-1.414 1.414L20 12.415V21a1 1 0 0 1-1 1H5Zm7-17.585-6 5.999V20h5v-4a1 1 0 0 1 2 0v4h5v-9.585l-6-6Z"/></symbol><symbol id="icon-eds-i-image-medium" viewBox="0 0 24 24"><path d="M19.615 2A2.385 2.385 0 0 1 22 4.385v15.23A2.385 2.385 0 0 1 19.615 22H4.385A2.385 2.385 0 0 1 2 19.615V4.385A2.385 2.385 0 0 1 4.385 2h15.23Zm0 2H4.385A.385.385 0 0 0 4 4.385v15.23c0 .213.172.385.385.385h1.244l10.228-8.76a1 1 0 0 1 1.254-.037L20 13.392V4.385A.385.385 0 0 0 19.615 4Zm-3.07 9.283L8.703 20h10.912a.385.385 0 0 0 .385-.385v-3.713l-3.455-2.619ZM9.5 6a3.5 3.5 0 1 1 0 7 3.5 3.5 0 0 1 0-7Zm0 2a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3Z"/></symbol><symbol id="icon-eds-i-impact-factor-medium" viewBox="0 0 24 24"><path d="M16.49 2.672c.74.694.986 1.765.632 2.712l-.04.1-1.549 3.54h1.477a2.496 2.496 0 0 1 2.485 2.34l.005.163c0 .618-.23 1.21-.642 1.675l-7.147 7.961a2.48 2.48 0 0 1-3.554.165 2.512 2.512 0 0 1-.633-2.712l.042-.103L9.108 15H7.46c-1.393 0-2.379-1.11-2.455-2.369L5 12.473c0-.593.142-1.145.628-1.692l7.307-7.944a2.48 2.48 0 0 1 3.555-.165ZM14.43 4.164l-7.33 7.97c-.083.093-.101.214-.101.34 0 .277.19.526.46.526h4.163l.097-.009c.015 0 .03.003.046.009.181.078.264.32.186.5l-2.554 5.817a.512.512 0 0 0 .127.552.48.48 0 0 0 .69-.033l7.155-7.97a.513.513 0 0 0 .13-.34.497.497 0 0 0-.49-.502h-3.988a.355.355 0 0 1-.328-.497l2.555-5.844a.512.512 0 0 0-.127-.552.48.48 0 0 0-.69.033Z"/></symbol><symbol id="icon-eds-i-info-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm0 7a1 1 0 0 1 1 1v5h1.5a1 1 0 0 1 0 2h-5a1 1 0 0 1 0-2H11v-4h-.5a1 1 0 0 1-.993-.883L9.5 11a1 1 0 0 1 1-1H12Zm0-4.5a1.5 1.5 0 0 1 .144 2.993L12 8.5a1.5 1.5 0 0 1 0-3Z"/></symbol><symbol id="icon-eds-i-info-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 9h-1.5a1 1 0 0 0-1 1l.007.117A1 1 0 0 0 10.5 12h.5v4H9.5a1 1 0 0 0 0 2h5a1 1 0 0 0 0-2H13v-5a1 1 0 0 0-1-1Zm0-4.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 5.5Z"/></symbol><symbol id="icon-eds-i-journal-medium" viewBox="0 0 24 24"><path d="M18.5 1A2.5 2.5 0 0 1 21 3.5v14a2.5 2.5 0 0 1-2.5 2.5h-13a.5.5 0 1 0 0 1H20a1 1 0 0 1 0 2H5.5A2.5 2.5 0 0 1 3 20.5v-17A2.5 2.5 0 0 1 5.5 1h13ZM7 3H5.5a.5.5 0 0 0-.5.5v14.549l.016-.002c.104-.02.211-.035.32-.042L5.5 18H7V3Zm11.5 0H9v15h9.5a.5.5 0 0 0 .5-.5v-14a.5.5 0 0 0-.5-.5ZM16 5a1 1 0 0 1 1 1v4a1 1 0 0 1-1 1h-5a1 1 0 0 1-1-1V6a1 1 0 0 1 1-1h5Zm-1 2h-3v2h3V7Z"/></symbol><symbol id="icon-eds-i-mail-medium" viewBox="0 0 24 24"><path d="M20.462 3C21.875 3 23 4.184 23 5.619v12.762C23 19.816 21.875 21 20.462 21H3.538C2.125 21 1 19.816 1 18.381V5.619C1 4.184 2.125 3 3.538 3h16.924ZM21 8.158l-7.378 6.258a2.549 2.549 0 0 1-3.253-.008L3 8.16v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619V8.158ZM20.462 5H3.538c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516Z"/></symbol><symbol id="icon-eds-i-mail-send-medium" viewBox="0 0 24 24"><path d="M20.444 5a2.562 2.562 0 0 1 2.548 2.37l.007.078.001.123v7.858A2.564 2.564 0 0 1 20.444 18H9.556A2.564 2.564 0 0 1 7 15.429l.001-7.977.007-.082A2.561 2.561 0 0 1 9.556 5h10.888ZM21 9.331l-5.46 3.51a1 1 0 0 1-1.08 0L9 9.332v6.097c0 .317.251.571.556.571h10.888a.564.564 0 0 0 .556-.571V9.33ZM20.444 7H9.556a.543.543 0 0 0-.32.105l5.763 3.706 5.766-3.706a.543.543 0 0 0-.32-.105ZM4.308 5a1 1 0 1 1 0 2H2a1 1 0 1 1 0-2h2.308Zm0 5.5a1 1 0 0 1 0 2H2a1 1 0 0 1 0-2h2.308Zm0 5.5a1 1 0 0 1 0 2H2a1 1 0 0 1 0-2h2.308Z"/></symbol><symbol id="icon-eds-i-mentions-medium" viewBox="0 0 24 24"><path d="m9.452 1.293 5.92 5.92 2.92-2.92a1 1 0 0 1 1.415 1.414l-2.92 2.92 5.92 5.92a1 1 0 0 1 0 1.415 10.371 10.371 0 0 1-10.378 2.584l.652 3.258A1 1 0 0 1 12 23H2a1 1 0 0 1-.874-1.486l4.789-8.62C4.194 9.074 4.9 4.43 8.038 1.292a1 1 0 0 1 1.414 0Zm-2.355 13.59L3.699 21h7.081l-.689-3.442a10.392 10.392 0 0 1-2.775-2.396l-.22-.28Zm1.69-11.427-.07.09a8.374 8.374 0 0 0 11.737 11.737l.089-.071L8.787 3.456Z"/></symbol><symbol id="icon-eds-i-menu-medium" viewBox="0 0 24 24"><path d="M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z"/></symbol><symbol id="icon-eds-i-metrics-medium" viewBox="0 0 24 24"><path d="M3 22a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v7h4V8a1 1 0 0 1 1-1h6a1 1 0 0 1 1 1v13a1 1 0 0 1-.883.993L21 22H3Zm17-2V9h-4v11h4Zm-6-8h-4v8h4v-8ZM8 4H4v16h4V4Z"/></symbol><symbol id="icon-eds-i-news-medium" viewBox="0 0 24 24"><path d="M17.384 3c.975 0 1.77.787 1.77 1.762v13.333c0 .462.354.846.815.899l.107.006.109-.006a.915.915 0 0 0 .809-.794l.006-.105V8.19a1 1 0 0 1 2 0v9.905A2.914 2.914 0 0 1 20.077 21H3.538a2.547 2.547 0 0 1-1.644-.601l-.147-.135A2.516 2.516 0 0 1 1 18.476V4.762C1 3.787 1.794 3 2.77 3h14.614Zm-.231 2H3v13.476c0 .11.035.216.1.304l.054.063c.101.1.24.157.384.157l13.761-.001-.026-.078a2.88 2.88 0 0 1-.115-.655l-.004-.17L17.153 5ZM14 15.021a.979.979 0 1 1 0 1.958H6a.979.979 0 1 1 0-1.958h8Zm0-8c.54 0 .979.438.979.979v4c0 .54-.438.979-.979.979H6A.979.979 0 0 1 5.021 12V8c0-.54.438-.979.979-.979h8Zm-.98 1.958H6.979v2.041h6.041V8.979Z"/></symbol><symbol id="icon-eds-i-newsletter-medium" viewBox="0 0 24 24"><path d="M21 10a1 1 0 0 1 1 1v9.5a2.5 2.5 0 0 1-2.5 2.5h-15A2.5 2.5 0 0 1 2 20.5V11a1 1 0 0 1 2 0v.439l8 4.888 8-4.889V11a1 1 0 0 1 1-1Zm-1 3.783-7.479 4.57a1 1 0 0 1-1.042 0l-7.48-4.57V20.5a.5.5 0 0 0 .501.5h15a.5.5 0 0 0 .5-.5v-6.717ZM15 9a1 1 0 0 1 0 2H9a1 1 0 0 1 0-2h6Zm2.5-8A2.5 2.5 0 0 1 20 3.5V9a1 1 0 0 1-2 0V3.5a.5.5 0 0 0-.5-.5h-11a.5.5 0 0 0-.5.5V9a1 1 0 1 1-2 0V3.5A2.5 2.5 0 0 1 6.5 1h11ZM15 5a1 1 0 0 1 0 2H9a1 1 0 1 1 0-2h6Z"/></symbol><symbol id="icon-eds-i-notifcation-medium" viewBox="0 0 24 24"><path d="M14 20a1 1 0 0 1 0 2h-4a1 1 0 0 1 0-2h4ZM3 18l-.133-.007c-1.156-.124-1.156-1.862 0-1.986l.3-.012C4.32 15.923 5 15.107 5 14V9.5C5 5.368 8.014 2 12 2s7 3.368 7 7.5V14c0 1.107.68 1.923 1.832 1.995l.301.012c1.156.124 1.156 1.862 0 1.986L21 18H3Zm9-14C9.17 4 7 6.426 7 9.5V14c0 .671-.146 1.303-.416 1.858L6.51 16h10.979l-.073-.142a4.192 4.192 0 0 1-.412-1.658L17 14V9.5C17 6.426 14.83 4 12 4Z"/></symbol><symbol id="icon-eds-i-publish-medium" viewBox="0 0 24 24"><g><path d="M16.296 1.291A1 1 0 0 0 15.591 1H5.545A2.542 2.542 0 0 0 3 3.538V13a1 1 0 1 0 2 0V3.538l.007-.087A.543.543 0 0 1 5.545 3h9.633L20 7.8v12.662a.534.534 0 0 1-.158.379.548.548 0 0 1-.387.159H11a1 1 0 1 0 0 2h8.455c.674 0 1.32-.267 1.798-.742A2.534 2.534 0 0 0 22 20.462V7.385a1 1 0 0 0-.294-.709l-5.41-5.385Z"/><path d="M10.762 16.647a1 1 0 0 0-1.525-1.294l-4.472 5.271-2.153-1.665a1 1 0 1 0-1.224 1.582l2.91 2.25a1 1 0 0 0 1.374-.144l5.09-6ZM16 10a1 1 0 1 1 0 2H8a1 1 0 1 1 0-2h8ZM12 7a1 1 0 0 0-1-1H8a1 1 0 1 0 0 2h3a1 1 0 0 0 1-1Z"/></g></symbol><symbol id="icon-eds-i-refresh-medium" viewBox="0 0 24 24"><g><path d="M7.831 5.636H6.032A8.76 8.76 0 0 1 9 3.631 8.549 8.549 0 0 1 12.232 3c.603 0 1.192.063 1.76.182C17.979 4.017 21 7.632 21 12a1 1 0 1 0 2 0c0-5.296-3.674-9.746-8.591-10.776A10.61 10.61 0 0 0 5 3.851V2.805a1 1 0 0 0-.987-1H4a1 1 0 0 0-1 1v3.831a1 1 0 0 0 1 1h3.831a1 1 0 0 0 .013-2h-.013ZM17.968 18.364c-1.59 1.632-3.784 2.636-6.2 2.636C6.948 21 3 16.993 3 12a1 1 0 1 0-2 0c0 6.053 4.799 11 10.768 11 2.788 0 5.324-1.082 7.232-2.85v1.045a1 1 0 1 0 2 0v-3.831a1 1 0 0 0-1-1h-3.831a1 1 0 0 0 0 2h1.799Z"/></g></symbol><symbol id="icon-eds-i-search-medium" viewBox="0 0 24 24"><path d="M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z"/></symbol><symbol id="icon-eds-i-settings-medium" viewBox="0 0 24 24"><path d="M11.382 1h1.24a2.508 2.508 0 0 1 2.334 1.63l.523 1.378 1.59.933 1.444-.224c.954-.132 1.89.3 2.422 1.101l.095.155.598 1.066a2.56 2.56 0 0 1-.195 2.848l-.894 1.161v1.896l.92 1.163c.6.768.707 1.812.295 2.674l-.09.17-.606 1.08a2.504 2.504 0 0 1-2.531 1.25l-1.428-.223-1.589.932-.523 1.378a2.512 2.512 0 0 1-2.155 1.625L12.65 23h-1.27a2.508 2.508 0 0 1-2.334-1.63l-.524-1.379-1.59-.933-1.443.225c-.954.132-1.89-.3-2.422-1.101l-.095-.155-.598-1.066a2.56 2.56 0 0 1 .195-2.847l.891-1.161v-1.898l-.919-1.162a2.562 2.562 0 0 1-.295-2.674l.09-.17.606-1.08a2.504 2.504 0 0 1 2.531-1.25l1.43.223 1.618-.938.524-1.375.07-.167A2.507 2.507 0 0 1 11.382 1Zm.003 2a.509.509 0 0 0-.47.338l-.65 1.71a1 1 0 0 1-.434.51L7.6 6.85a1 1 0 0 1-.655.123l-1.762-.275a.497.497 0 0 0-.498.252l-.61 1.088a.562.562 0 0 0 .04.619l1.13 1.43a1 1 0 0 1 .216.62v2.585a1 1 0 0 1-.207.61L4.15 15.339a.568.568 0 0 0-.036.634l.601 1.072a.494.494 0 0 0 .484.26l1.78-.278a1 1 0 0 1 .66.126l2.2 1.292a1 1 0 0 1 .43.507l.648 1.71a.508.508 0 0 0 .467.338h1.263a.51.51 0 0 0 .47-.34l.65-1.708a1 1 0 0 1 .428-.507l2.201-1.292a1 1 0 0 1 .66-.126l1.763.275a.497.497 0 0 0 .498-.252l.61-1.088a.562.562 0 0 0-.04-.619l-1.13-1.43a1 1 0 0 1-.216-.62v-2.585a1 1 0 0 1 .207-.61l1.105-1.437a.568.568 0 0 0 .037-.634l-.601-1.072a.494.494 0 0 0-.484-.26l-1.78.278a1 1 0 0 1-.66-.126l-2.2-1.292a1 1 0 0 1-.43-.507l-.649-1.71A.508.508 0 0 0 12.62 3h-1.234ZM12 8a4 4 0 1 1 0 8 4 4 0 0 1 0-8Zm0 2a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"/></symbol><symbol id="icon-eds-i-shipping-medium" viewBox="0 0 24 24"><path d="M16.515 2c1.406 0 2.706.728 3.352 1.902l2.02 3.635.02.042.036.089.031.105.012.058.01.073.004.075v11.577c0 .64-.244 1.255-.683 1.713a2.356 2.356 0 0 1-1.701.731H4.386a2.356 2.356 0 0 1-1.702-.731 2.476 2.476 0 0 1-.683-1.713V7.948c.01-.217.083-.43.22-.6L4.2 3.905C4.833 2.755 6.089 2.032 7.486 2h9.029ZM20 9H4v10.556a.49.49 0 0 0 .075.26l.053.07a.356.356 0 0 0 .257.114h15.23c.094 0 .186-.04.258-.115a.477.477 0 0 0 .127-.33V9Zm-2 7.5a1 1 0 0 1 0 2h-4a1 1 0 0 1 0-2h4ZM16.514 4H13v3h6.3l-1.183-2.13c-.288-.522-.908-.87-1.603-.87ZM11 3.999H7.51c-.679.017-1.277.36-1.566.887L4.728 7H11V3.999Z"/></symbol><symbol id="icon-eds-i-step-guide-medium" viewBox="0 0 24 24"><path d="M11.394 9.447a1 1 0 1 0-1.788-.894l-.88 1.759-.019-.02a1 1 0 1 0-1.414 1.415l1 1a1 1 0 0 0 1.601-.26l1.5-3ZM12 11a1 1 0 0 1 1-1h3a1 1 0 1 1 0 2h-3a1 1 0 0 1-1-1ZM12 17a1 1 0 0 1 1-1h3a1 1 0 1 1 0 2h-3a1 1 0 0 1-1-1ZM10.947 14.105a1 1 0 0 1 .447 1.342l-1.5 3a1 1 0 0 1-1.601.26l-1-1a1 1 0 1 1 1.414-1.414l.02.019.879-1.76a1 1 0 0 1 1.341-.447Z"/><path d="M5.545 1A2.542 2.542 0 0 0 3 3.538v16.924A2.542 2.542 0 0 0 5.545 23h12.91A2.542 2.542 0 0 0 21 20.462V7.5a1 1 0 0 0-.293-.707l-5.5-5.5A1 1 0 0 0 14.5 1H5.545ZM5 3.538C5 3.245 5.24 3 5.545 3h8.54L19 7.914v12.547c0 .294-.24.539-.546.539H5.545A.542.542 0 0 1 5 20.462V3.538Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-submission-medium" viewBox="0 0 24 24"><g><path d="M5 3.538C5 3.245 5.24 3 5.545 3h9.633L20 7.8v12.662a.535.535 0 0 1-.158.379.549.549 0 0 1-.387.159H6a1 1 0 0 1-1-1v-2.5a1 1 0 1 0-2 0V20a3 3 0 0 0 3 3h13.455c.673 0 1.32-.266 1.798-.742A2.535 2.535 0 0 0 22 20.462V7.385a1 1 0 0 0-.294-.709l-5.41-5.385A1 1 0 0 0 15.591 1H5.545A2.542 2.542 0 0 0 3 3.538V7a1 1 0 0 0 2 0V3.538Z"/><path d="m13.707 13.707-4 4a1 1 0 0 1-1.414 0l-.083-.094a1 1 0 0 1 .083-1.32L10.585 14 2 14a1 1 0 1 1 0-2l8.583.001-2.29-2.294a1 1 0 0 1 1.414-1.414l4.037 4.04.043.05.043.06.059.098.03.063.031.085.03.113.017.122L14 13l-.004.087-.017.118-.013.056-.034.104-.049.105-.048.081-.07.093-.058.063Z"/></g></symbol><symbol id="icon-eds-i-table-1-medium" viewBox="0 0 24 24"><path d="M4.385 22a2.56 2.56 0 0 1-1.14-.279C2.485 21.341 2 20.614 2 19.615V4.385c0-.315.067-.716.279-1.14C2.659 2.485 3.386 2 4.385 2h15.23c.315 0 .716.067 1.14.279.76.38 1.245 1.107 1.245 2.106v15.23c0 .315-.067.716-.279 1.14-.38.76-1.107 1.245-2.106 1.245H4.385ZM4 19.615c0 .213.034.265.14.317a.71.71 0 0 0 .245.068H8v-4H4v3.615ZM20 16H10v4h9.615c.213 0 .265-.034.317-.14a.71.71 0 0 0 .068-.245V16Zm0-2v-4H10v4h10ZM4 14h4v-4H4v4ZM19.615 4H10v4h10V4.385c0-.213-.034-.265-.14-.317A.71.71 0 0 0 19.615 4ZM8 4H4.385l-.082.002c-.146.01-.19.047-.235.138A.71.71 0 0 0 4 4.385V8h4V4Z"/></symbol><symbol id="icon-eds-i-table-2-medium" viewBox="0 0 24 24"><path d="M4.384 22A2.384 2.384 0 0 1 2 19.616V4.384A2.384 2.384 0 0 1 4.384 2h15.232A2.384 2.384 0 0 1 22 4.384v15.232A2.384 2.384 0 0 1 19.616 22H4.384ZM10 15H4v4.616c0 .212.172.384.384.384H10v-5Zm5 0h-3v5h3v-5Zm5 0h-3v5h2.616a.384.384 0 0 0 .384-.384V15ZM10 9H4v4h6V9Zm5 0h-3v4h3V9Zm5 0h-3v4h3V9Zm-.384-5H4.384A.384.384 0 0 0 4 4.384V7h16V4.384A.384.384 0 0 0 19.616 4Z"/></symbol><symbol id="icon-eds-i-tag-medium" viewBox="0 0 24 24"><path d="m12.621 1.998.127.004L20.496 2a1.5 1.5 0 0 1 1.497 1.355L22 3.5l-.005 7.669c.038.456-.133.905-.447 1.206l-9.02 9.018a2.075 2.075 0 0 1-2.932 0l-6.99-6.99a2.075 2.075 0 0 1 .001-2.933L11.61 2.47c.246-.258.573-.418.881-.46l.131-.011Zm.286 2-8.885 8.886a.075.075 0 0 0 0 .106l6.987 6.988c.03.03.077.03.106 0l8.883-8.883L19.999 4l-7.092-.002ZM16 6.5a1.5 1.5 0 0 1 .144 2.993L16 9.5a1.5 1.5 0 0 1 0-3Z"/></symbol><symbol id="icon-eds-i-trash-medium" viewBox="0 0 24 24"><path d="M12 1c2.717 0 4.913 2.232 4.997 5H21a1 1 0 0 1 0 2h-1v12.5c0 1.389-1.152 2.5-2.556 2.5H6.556C5.152 23 4 21.889 4 20.5V8H3a1 1 0 1 1 0-2h4.003l.001-.051C7.114 3.205 9.3 1 12 1Zm6 7H6v12.5c0 .238.19.448.454.492l.102.008h10.888c.315 0 .556-.232.556-.5V8Zm-4 3a1 1 0 0 1 1 1v6.005a1 1 0 0 1-2 0V12a1 1 0 0 1 1-1Zm-4 0a1 1 0 0 1 1 1v6a1 1 0 0 1-2 0v-6a1 1 0 0 1 1-1Zm2-8c-1.595 0-2.914 1.32-2.996 3h5.991v-.02C14.903 4.31 13.589 3 12 3Z"/></symbol><symbol id="icon-eds-i-user-account-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 16c-1.806 0-3.52.994-4.664 2.698A8.947 8.947 0 0 0 12 21a8.958 8.958 0 0 0 4.664-1.301C15.52 17.994 13.806 17 12 17Zm0-14a9 9 0 0 0-6.25 15.476C7.253 16.304 9.54 15 12 15s4.747 1.304 6.25 3.475A9 9 0 0 0 12 3Zm0 3a4 4 0 1 1 0 8 4 4 0 0 1 0-8Zm0 2a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"/></symbol><symbol id="icon-eds-i-user-add-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm9 10a1 1 0 0 1 1 1v3h3a1 1 0 0 1 0 2h-3v3a1 1 0 0 1-2 0v-3h-3a1 1 0 0 1 0-2h3v-3a1 1 0 0 1 1-1Zm-5.545-.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378Z"/></symbol><symbol id="icon-eds-i-user-assign-medium" viewBox="0 0 24 24"><path d="M16.226 13.298a1 1 0 0 1 1.414-.01l.084.093a1 1 0 0 1-.073 1.32L15.39 17H22a1 1 0 0 1 0 2h-6.611l2.262 2.298a1 1 0 0 1-1.425 1.404l-3.939-4a1 1 0 0 1 0-1.404l3.94-4Zm-3.771-.449a1 1 0 1 1-.91 1.781 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 10.5 20a1 1 0 0 1 .993.883L11.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Z"/></symbol><symbol id="icon-eds-i-user-block-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm9 10a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm-5.545-.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM15 18a3 3 0 0 0 4.294 2.707l-4.001-4c-.188.391-.293.83-.293 1.293Zm3-3c-.463 0-.902.105-1.294.293l4.001 4A3 3 0 0 0 18 15Z"/></symbol><symbol id="icon-eds-i-user-check-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm13.647 12.237a1 1 0 0 1 .116 1.41l-5.091 6a1 1 0 0 1-1.375.144l-2.909-2.25a1 1 0 1 1 1.224-1.582l2.153 1.665 4.472-5.271a1 1 0 0 1 1.41-.116Zm-8.139-.977c.22.214.428.44.622.678a1 1 0 1 1-1.548 1.266 6.025 6.025 0 0 0-1.795-1.49.86.86 0 0 1-.163-.048l-.079-.036a5.721 5.721 0 0 0-2.62-.63l-.194.006c-2.76.134-5.022 2.177-5.592 4.864l-.035.175-.035.213c-.03.201-.05.405-.06.61L3.003 20 10 20a1 1 0 0 1 .993.883L11 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876l.005-.223.02-.356.02-.222.03-.248.022-.15c.02-.133.044-.265.071-.397.44-2.178 1.725-4.105 3.595-5.301a7.75 7.75 0 0 1 3.755-1.215l.12-.004a7.908 7.908 0 0 1 5.87 2.252Z"/></symbol><symbol id="icon-eds-i-user-delete-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6ZM4.763 13.227a7.713 7.713 0 0 1 7.692-.378 1 1 0 1 1-.91 1.781 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20H11.5a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897Zm11.421 1.543 2.554 2.553 2.555-2.553a1 1 0 0 1 1.414 1.414l-2.554 2.554 2.554 2.555a1 1 0 0 1-1.414 1.414l-2.555-2.554-2.554 2.554a1 1 0 0 1-1.414-1.414l2.553-2.555-2.553-2.554a1 1 0 0 1 1.414-1.414Z"/></symbol><symbol id="icon-eds-i-user-edit-medium" viewBox="0 0 24 24"><path d="m19.876 10.77 2.831 2.83a1 1 0 0 1 0 1.415l-7.246 7.246a1 1 0 0 1-.572.284l-3.277.446a1 1 0 0 1-1.125-1.13l.461-3.277a1 1 0 0 1 .283-.567l7.23-7.246a1 1 0 0 1 1.415-.001Zm-7.421 2.08a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 7.5 20a1 1 0 0 1 .993.883L8.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378Zm6.715.042-6.29 6.3-.23 1.639 1.633-.222 6.302-6.302-1.415-1.415ZM9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Z"/></symbol><symbol id="icon-eds-i-user-linked-medium" viewBox="0 0 24 24"><path d="M15.65 6c.31 0 .706.066 1.122.274C17.522 6.65 18 7.366 18 8.35v12.3c0 .31-.066.706-.274 1.122-.375.75-1.092 1.228-2.076 1.228H3.35a2.52 2.52 0 0 1-1.122-.274C1.478 22.35 1 21.634 1 20.65V8.35c0-.31.066-.706.274-1.122C1.65 6.478 2.366 6 3.35 6h12.3Zm0 2-12.376.002c-.134.007-.17.04-.21.12A.672.672 0 0 0 3 8.35v12.3c0 .198.028.24.122.287.09.044.2.063.228.063h.887c.788-2.269 2.814-3.5 5.263-3.5 2.45 0 4.475 1.231 5.263 3.5h.887c.198 0 .24-.028.287-.122.044-.09.063-.2.063-.228V8.35c0-.198-.028-.24-.122-.287A.672.672 0 0 0 15.65 8ZM9.5 19.5c-1.36 0-2.447.51-3.06 1.5h6.12c-.613-.99-1.7-1.5-3.06-1.5ZM20.65 1A2.35 2.35 0 0 1 23 3.348V15.65A2.35 2.35 0 0 1 20.65 18H20a1 1 0 0 1 0-2h.65a.35.35 0 0 0 .35-.35V3.348A.35.35 0 0 0 20.65 3H8.35a.35.35 0 0 0-.35.348V4a1 1 0 1 1-2 0v-.652A2.35 2.35 0 0 1 8.35 1h12.3ZM9.5 10a3.5 3.5 0 1 1 0 7 3.5 3.5 0 0 1 0-7Zm0 2a1.5 1.5 0 1 0 0 3 1.5 1.5 0 0 0 0-3Z"/></symbol><symbol id="icon-eds-i-user-multiple-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm6 0a5 5 0 0 1 0 10 1 1 0 0 1-.117-1.993L15 9a3 3 0 0 0 0-6 1 1 0 0 1 0-2ZM9 3a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm8.857 9.545a7.99 7.99 0 0 1 2.651 1.715A8.31 8.31 0 0 1 23 20.134V21a1 1 0 0 1-1 1h-3a1 1 0 0 1 0-2h1.995l-.005-.153a6.307 6.307 0 0 0-1.673-3.945l-.204-.209a5.99 5.99 0 0 0-1.988-1.287 1 1 0 1 1 .732-1.861Zm-3.349 1.715A8.31 8.31 0 0 1 17 20.134V21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.877c.044-4.343 3.387-7.908 7.638-8.115a7.908 7.908 0 0 1 5.87 2.252ZM9.016 14l-.285.006c-3.104.15-5.58 2.718-5.725 5.9L3.004 20h11.991l-.005-.153a6.307 6.307 0 0 0-1.673-3.945l-.204-.209A5.924 5.924 0 0 0 9.3 14.008L9.016 14Z"/></symbol><symbol id="icon-eds-i-user-notify-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm10 18v1a1 1 0 0 1-2 0v-1h-3a1 1 0 0 1 0-2v-2.818C14 13.885 15.777 12 18 12s4 1.885 4 4.182V19a1 1 0 0 1 0 2h-3Zm-6.545-8.15a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM18 14c-1.091 0-2 .964-2 2.182V19h4v-2.818c0-1.165-.832-2.098-1.859-2.177L18 14Z"/></symbol><symbol id="icon-eds-i-user-remove-medium" viewBox="0 0 24 24"><path d="M9 1a5 5 0 1 1 0 10A5 5 0 0 1 9 1Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm3.455 9.85a1 1 0 1 1-.91 1.78 5.713 5.713 0 0 0-5.705.282c-1.67 1.068-2.728 2.927-2.832 4.956L3.004 20 11.5 20a1 1 0 0 1 .993.883L12.5 21a1 1 0 0 1-1 1H2a1 1 0 0 1-1-1v-.876c.028-2.812 1.446-5.416 3.763-6.897a7.713 7.713 0 0 1 7.692-.378ZM22 17a1 1 0 0 1 0 2h-8a1 1 0 0 1 0-2h8Z"/></symbol><symbol id="icon-eds-i-user-single-medium" viewBox="0 0 24 24"><path d="M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z"/></symbol><symbol id="icon-eds-i-warning-circle-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 2a9 9 0 1 0 0 18 9 9 0 0 0 0-18Zm0 11.5a1.5 1.5 0 0 1 .144 2.993L12 17.5a1.5 1.5 0 0 1 0-3ZM12 6a1 1 0 0 1 1 1v5a1 1 0 0 1-2 0V7a1 1 0 0 1 1-1Z"/></symbol><symbol id="icon-eds-i-warning-filled-medium" viewBox="0 0 24 24"><path d="M12 1c6.075 0 11 4.925 11 11s-4.925 11-11 11S1 18.075 1 12 5.925 1 12 1Zm0 13.5a1.5 1.5 0 0 0 0 3l.144-.007A1.5 1.5 0 0 0 12 14.5ZM12 6a1 1 0 0 0-1 1v5a1 1 0 0 0 2 0V7a1 1 0 0 0-1-1Z"/></symbol><symbol id="icon-eds-i-work-medium" viewBox="0 0 24 24"><path d="M4 3.53808C4 3.24519 4.23975 3 4.5451 3H14.1778L19 7.80031V8C19 8.55228 19.4477 9 20 9C20.5523 9 21 8.55228 21 8V7.38477C21 7.11876 20.894 6.86372 20.7055 6.67605L15.2962 1.29129C15.1088 1.10473 14.8551 1 14.5907 1H4.5451C3.14377 1 2 2.13206 2 3.53808V20.5007C2 21.882 3.11988 23 4.5 23H8C8.55228 23 9 22.5523 9 22C9 21.4477 8.55228 21 8 21H4.5C4.22327 21 4 20.7762 4 20.5007V3.53808Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M19.8764 10.7698C19.6887 10.5822 19.4341 10.4768 19.1687 10.4769C18.9033 10.4771 18.6489 10.5827 18.4614 10.7706L11.2306 18.0167C11.0776 18.1701 10.9785 18.3691 10.9483 18.5836L10.4867 21.8605C10.443 22.1707 10.5472 22.4835 10.7682 22.7055C10.9892 22.9275 11.3015 23.0331 11.6118 22.9909L14.8888 22.5447C15.1054 22.5152 15.3064 22.4155 15.461 22.261L22.7071 15.0148C22.8947 14.8273 23 14.5729 23 14.3077C23 14.0425 22.8947 13.7881 22.7071 13.6006L19.8764 10.7698ZM12.8821 19.1931L19.17 12.8919L20.5858 14.3077L14.285 20.6085L12.6515 20.8309L12.8821 19.1931Z"/><path d="M11.0812 4.68628C11.5307 5.00729 11.6347 5.63184 11.3137 6.08125L8.81373 9.58125C8.64288 9.82045 8.37543 9.97236 8.08248 9.99661C7.78953 10.0209 7.50075 9.91498 7.29289 9.70712L5.79289 8.20712C5.40237 7.8166 5.40237 7.18343 5.79289 6.79291C6.18342 6.40239 6.81658 6.40239 7.20711 6.79291L7.8724 7.4582L9.68627 4.91878C10.0073 4.46937 10.6318 4.36527 11.0812 4.68628Z"/><path d="M11.3137 12.0813C11.6347 11.6318 11.5307 11.0073 11.0812 10.6863C10.6318 10.3653 10.0073 10.4694 9.68627 10.9188L7.8724 13.4582L7.20711 12.7929C6.81658 12.4024 6.18342 12.4024 5.79289 12.7929C5.40237 13.1834 5.40237 13.8166 5.79289 14.2071L7.29289 15.7071C7.50075 15.915 7.78953 16.0209 8.08248 15.9966C8.37543 15.9724 8.64288 15.8205 8.81373 15.5813L11.3137 12.0813Z"/></symbol><symbol id="icon-ai-stars"><path d="M22.294 13.39c.941.536.941 1.945 0 2.482l-3.613 2.061c-.228.13-.415.325-.54.563l-1.976 3.768a1.33 1.33 0 0 1-2.38 0l-1.977-3.768a1.4 1.4 0 0 0-.539-.563l-3.614-2.061c-.94-.537-.94-1.946 0-2.482l3.614-2.061c.228-.13.415-.325.54-.563l1.976-3.768a1.33 1.33 0 0 1 2.38 0l1.977 3.768c.124.238.311.433.539.563zM10.08 4.861c1.044.508 1.044 2.056 0 2.564l-1.543.751c-.29.14-.521.383-.656.684l-.72 1.61a1.334 1.334 0 0 1-2.459 0l-.72-1.61a1.4 1.4 0 0 0-.656-.684l-1.543-.751c-1.044-.508-1.044-2.056 0-2.564l1.543-.751c.29-.14.521-.383.656-.684l.72-1.61a1.334 1.334 0 0 1 2.459 0l.72 1.61c.135.301.367.543.656.684z"/></symbol><symbol id="icon-chevron-left-medium" viewBox="0 0 24 24"><path d="M15.7194 3.3054C15.3358 2.90809 14.7027 2.89699 14.3054 3.28061L6.54342 10.7757C6.19804 11.09 6 11.5335 6 12C6 12.4665 6.19804 12.91 6.5218 13.204L14.3054 20.7194C14.7027 21.103 15.3358 21.0919 15.7194 20.6946C16.103 20.2973 16.0919 19.6642 15.6946 19.2806L8.155 12L15.6946 4.71939C16.0614 4.36528 16.099 3.79863 15.8009 3.40105L15.7194 3.3054Z"/></symbol><symbol id="icon-chevron-right-medium" viewBox="0 0 24 24"><path d="M8.28061 3.3054C8.66423 2.90809 9.29729 2.89699 9.6946 3.28061L17.4566 10.7757C17.802 11.09 18 11.5335 18 12C18 12.4665 17.802 12.91 17.4782 13.204L9.6946 20.7194C9.29729 21.103 8.66423 21.0919 8.28061 20.6946C7.89699 20.2973 7.90809 19.6642 8.3054 19.2806L15.845 12L8.3054 4.71939C7.93865 4.36528 7.90098 3.79863 8.19908 3.40105L8.28061 3.3054Z"/></symbol><symbol id="icon-eds-alerts" viewBox="0 0 32 32"><path d="M28 12.667c.736 0 1.333.597 1.333 1.333v13.333A3.333 3.333 0 0 1 26 30.667H6a3.333 3.333 0 0 1-3.333-3.334V14a1.333 1.333 0 1 1 2.666 0v1.252L16 21.769l10.667-6.518V14c0-.736.597-1.333 1.333-1.333Zm-1.333 5.71-9.972 6.094c-.427.26-.963.26-1.39 0l-9.972-6.094v8.956c0 .368.299.667.667.667h20a.667.667 0 0 0 .667-.667v-8.956ZM19.333 12a1.333 1.333 0 1 1 0 2.667h-6.666a1.333 1.333 0 1 1 0-2.667h6.666Zm4-10.667a3.333 3.333 0 0 1 3.334 3.334v6.666a1.333 1.333 0 1 1-2.667 0V4.667A.667.667 0 0 0 23.333 4H8.667A.667.667 0 0 0 8 4.667v6.666a1.333 1.333 0 1 1-2.667 0V4.667a3.333 3.333 0 0 1 3.334-3.334h14.666Zm-4 5.334a1.333 1.333 0 0 1 0 2.666h-6.666a1.333 1.333 0 1 1 0-2.666h6.666Z"/></symbol><symbol id="icon-eds-arrow-up" viewBox="0 0 24 24"><path fill-rule="evenodd" d="m13.002 7.408 4.88 4.88a.99.99 0 0 0 1.32.08l.09-.08c.39-.39.39-1.03 0-1.42l-6.58-6.58a1.01 1.01 0 0 0-1.42 0l-6.58 6.58a1 1 0 0 0-.09 1.32l.08.1a1 1 0 0 0 1.42-.01l4.88-4.87v11.59a.99.99 0 0 0 .88.99l.12.01c.55 0 1-.45 1-1V7.408z" class="layer"/></symbol><symbol id="icon-eds-checklist" viewBox="0 0 32 32"><path d="M19.2 1.333a3.468 3.468 0 0 1 3.381 2.699L24.667 4C26.515 4 28 5.52 28 7.38v19.906c0 1.86-1.485 3.38-3.333 3.38H7.333c-1.848 0-3.333-1.52-3.333-3.38V7.38C4 5.52 5.485 4 7.333 4h2.093A3.468 3.468 0 0 1 12.8 1.333h6.4ZM9.426 6.667H7.333c-.36 0-.666.312-.666.713v19.906c0 .401.305.714.666.714h17.334c.36 0 .666-.313.666-.714V7.38c0-.4-.305-.713-.646-.714l-2.121.033A3.468 3.468 0 0 1 19.2 9.333h-6.4a3.468 3.468 0 0 1-3.374-2.666Zm12.715 5.606c.586.446.7 1.283.253 1.868l-7.111 9.334a1.333 1.333 0 0 1-1.792.306l-3.556-2.333a1.333 1.333 0 1 1 1.463-2.23l2.517 1.651 6.358-8.344a1.333 1.333 0 0 1 1.868-.252ZM19.2 4h-6.4a.8.8 0 0 0-.8.8v1.067a.8.8 0 0 0 .8.8h6.4a.8.8 0 0 0 .8-.8V4.8a.8.8 0 0 0-.8-.8Z"/></symbol><symbol id="icon-eds-citation" viewBox="0 0 36 36"><path d="M23.25 1.5a1.5 1.5 0 0 1 1.06.44l8.25 8.25a1.5 1.5 0 0 1 .44 1.06v19.5c0 2.105-1.645 3.75-3.75 3.75H18a1.5 1.5 0 0 1 0-3h11.25c.448 0 .75-.302.75-.75V11.873L22.628 4.5H8.31a.811.811 0 0 0-.8.68l-.011.13V16.5a1.5 1.5 0 0 1-3 0V5.31A3.81 3.81 0 0 1 8.31 1.5h14.94ZM8.223 20.358a.984.984 0 0 1-.192 1.378l-.048.034c-.54.36-.942.676-1.206.951-.59.614-.885 1.395-.885 2.343.115-.028.288-.042.518-.042.662 0 1.26.237 1.791.711.533.474.799 1.074.799 1.799 0 .753-.259 1.352-.777 1.799-.518.446-1.151.669-1.9.669-1.006 0-1.812-.293-2.417-.878C3.302 28.536 3 27.657 3 26.486c0-1.115.165-2.085.496-2.907.331-.823.734-1.513 1.209-2.071.475-.558.971-.997 1.49-1.318a6.01 6.01 0 0 1 .347-.2 1.321 1.321 0 0 1 1.681.368Zm7.5 0a.984.984 0 0 1-.192 1.378l-.048.034c-.54.36-.942.676-1.206.951-.59.614-.885 1.395-.885 2.343.115-.028.288-.042.518-.042.662 0 1.26.237 1.791.711.533.474.799 1.074.799 1.799 0 .753-.259 1.352-.777 1.799-.518.446-1.151.669-1.9.669-1.006 0-1.812-.293-2.417-.878-.604-.586-.906-1.465-.906-2.636 0-1.115.165-2.085.496-2.907.331-.823.734-1.513 1.209-2.071.475-.558.971-.997 1.49-1.318a6.01 6.01 0 0 1 .347-.2 1.321 1.321 0 0 1 1.681.368Z"/></symbol><symbol id="icon-eds-i-access-indicator" viewBox="0 0 16 16"><circle cx="4.5" cy="11.5" r="3.5" style="fill:currentColor"/><path fill-rule="evenodd" d="M4 3v3a1 1 0 0 1-2 0V2.923C2 1.875 2.84 1 3.909 1h5.909a1 1 0 0 1 .713.298l3.181 3.231a1 1 0 0 1 .288.702v7.846c0 .505-.197.993-.554 1.354a1.902 1.902 0 0 1-1.355.569H10a1 1 0 1 1 0-2h2V5.64L9.4 3H4Z" clip-rule="evenodd" style="fill:#222"/></symbol><symbol id="icon-eds-i-accessibility-medium" viewBox="0 0 24 24"><path d="M17 10.5C17.5523 10.5 18 10.9477 18 11.5C18 12.0523 17.5523 12.5 17 12.5H13V13C13 13.4952 13.2735 14.3106 13.7695 15.3027C14.1249 16.0135 14.551 16.7321 14.9483 17.3564L15.332 17.9453L15.3848 18.0332C15.6218 18.4812 15.4855 19.0448 15.0547 19.332C14.6238 19.6193 14.0508 19.5282 13.7285 19.1367L13.668 19.0547L13.2627 18.4326C12.8412 17.7703 12.3781 16.9924 11.9844 16.2061C11.4619 17.2978 10.8292 18.309 10.332 19.0547C10.0257 19.5142 9.40486 19.6384 8.94533 19.332C8.4858 19.0257 8.36163 18.4048 8.66798 17.9453C9.15666 17.2123 9.75032 16.2592 10.2197 15.2617C10.6385 14.372 10.9221 13.5218 10.9863 12.8008L11 12.5H7.00002C6.44774 12.5 6.00002 12.0523 6.00002 11.5C6.00002 10.9477 6.44774 10.5 7.00002 10.5H17Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M12 4C12.7957 4 13.5585 4.3163 14.1211 4.87891C14.6837 5.44152 15 6.20435 15 7C15 7.79565 14.6837 8.55848 14.1211 9.12109C13.5585 9.6837 12.7957 10 12 10C11.2044 10 10.4415 9.6837 9.87892 9.12109C9.31631 8.55848 9.00002 7.79565 9.00002 7C9.00002 6.20435 9.31631 5.44152 9.87892 4.87891C10.4415 4.3163 11.2044 4 12 4ZM12 6C11.7348 6 11.4805 6.10543 11.293 6.29297C11.1054 6.4805 11 6.73478 11 7C11 7.26522 11.1054 7.5195 11.293 7.70703C11.4805 7.89457 11.7348 8 12 8C12.2652 8 12.5195 7.89457 12.707 7.70703C12.8946 7.5195 13 7.26522 13 7C13 6.73478 12.8946 6.48051 12.707 6.29297C12.5195 6.10543 12.2652 6 12 6Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M12 1C18.0751 1 23 5.92487 23 12C23 18.0751 18.0751 23 12 23C5.92488 23 1.00002 18.0751 1.00002 12C1.00002 5.92487 5.92488 1 12 1ZM12 3C7.02945 3 3.00002 7.02944 3.00002 12C3.00002 16.9706 7.02945 21 12 21C16.9706 21 21 16.9706 21 12C21 7.02944 16.9706 3 12 3Z"/></symbol><symbol id="icon-eds-i-book-research-medium"><path fill-rule="evenodd" d="M9.99.952c.922 0 1.822.273 2.589.784l2.42 1.614 2.421-1.614a4.667 4.667 0 0 1 2.283-.774l.306-.01h6.324a3.333 3.333 0 0 1 3.333 3.334v8.666a1.333 1.333 0 0 1-2.666 0V4.286a.667.667 0 0 0-.667-.667h-6.324a2 2 0 0 0-1.11.336l-2.566 1.71v5.954a1.333 1.333 0 1 1-2.667 0V5.666L11.1 3.955a2 2 0 0 0-1.11-.336H3.666A.667.667 0 0 0 3 4.286v17.333c0 .368.298.667.666.667h10a1.333 1.333 0 1 1 0 2.666h-10A3.333 3.333 0 0 1 .333 21.62V4.286A3.333 3.333 0 0 1 3.666.952H9.99Zm12.343 13.334a6 6 0 0 1 5.08 9.193l1.863 1.864a1.333 1.333 0 1 1-1.886 1.886l-1.864-1.863a6 6 0 1 1-3.193-11.08Zm-3.333 6a3.333 3.333 0 1 1 6.666 0 3.333 3.333 0 0 1-6.666 0Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-circle-bluesky" viewBox="0 0 25 24"><path d="M12.5 0c6.627 0 12 5.373 12 12s-5.373 12-12 12-12-5.373-12-12 5.373-12 12-12m7 7.44c0-2.158-1.877-1.48-3.035-.604-1.605 1.214-3.331 3.676-3.965 4.997-.634-1.321-2.36-3.783-3.965-4.997C7.377 5.96 5.5 5.282 5.5 7.439c0 .432.245 3.62.389 4.137.5 1.8 2.32 2.258 3.94 1.98-2.831.486-3.551 2.095-1.996 3.703 2.954 3.054 4.246-.766 4.577-1.745.061-.181.09-.265.09-.19 0-.075.029.009.09.19.33.98 1.623 4.8 4.577 1.745 1.555-1.608.835-3.217-1.996-3.702 1.62.277 3.44-.182 3.94-1.98.144-.518.389-3.706.389-4.138"/></symbol><symbol id="icon-eds-i-circle-facebook" viewBox="0 0 25 24"><path d="M12.5 0C5.872 0 .5 5.372.5 12s5.372 12 12 12 12-5.372 12-12-5.372-12-12-12m3.356 7.417h-1.62s-.858-.023-.93 1v1.836h2.186l-.017 2.454h-2.168l-.003 6.409-2.571-.004v-6.405H8.612V10.23h2.12V8.012s.096-2.574 2.598-2.884h2.526z"/></symbol><symbol id="icon-eds-i-circle-instagram" viewBox="0 0 25 24"><g clip-path="url(#a)"><path d="M12.5 0C5.872 0 .5 5.372.5 12s5.372 12 12 12 12-5.372 12-12-5.372-12-12-12m6.687 15.313a3.377 3.377 0 0 1-3.374 3.373H9.188a3.377 3.377 0 0 1-3.373-3.373V8.687a3.377 3.377 0 0 1 3.373-3.374h6.627a3.377 3.377 0 0 1 3.373 3.374zm-3.374-8.544H9.188A1.92 1.92 0 0 0 7.27 8.687v6.627a1.92 1.92 0 0 0 1.918 1.918h6.627a1.92 1.92 0 0 0 1.918-1.918V8.686a1.92 1.92 0 0 0-1.918-1.918M12.5 15.444A3.45 3.45 0 0 1 9.056 12c0-1.9 1.545-3.444 3.444-3.444S15.944 10.1 15.944 12 14.4 15.444 12.5 15.444m3.444-6.073a.816.816 0 1 1 .002-1.632.816.816 0 0 1-.002 1.632m-3.444.64c-1.096 0-1.99.893-1.99 1.989s.894 1.99 1.99 1.99A1.99 1.99 0 0 0 14.489 12a1.99 1.99 0 0 0-1.989-1.989"/></g></symbol><symbol id="icon-eds-i-circle-linkedin" viewBox="0 0 25 24"><path d="M12.5 0C5.872 0 .5 5.373.5 12s5.372 12 12 12 12-5.373 12-12-5.373-12-12-12m-2.288 16.662h-2.24V9.765h2.24zM9.056 8.844a1.253 1.253 0 1 1 0-2.507 1.253 1.253 0 0 1 0 2.507m9.03 7.81h-2.119v-3.998s-.034-1.321-1.22-1.17c0 0-1.016-.05-1.135 1.237v3.914h-2.151v-6.86h2.032v.914s.576-1.135 2.067-1.101c0 0 2.405-.254 2.525 2.49z"/></symbol><symbol id="icon-eds-i-circle-x" viewBox="0 0 25 24"><path d="m12.59 11.233-2.397-3.427H8.915l2.97 4.247.373.534 2.542 3.636h1.278l-3.115-4.455zM12.5 0C5.872 0 .5 5.372.5 12s5.372 12 12 12 12-5.372 12-12-5.372-12-12-12m1.908 16.82-2.572-3.743-3.221 3.744h-.832l3.683-4.281-3.683-5.36h2.809l2.435 3.544 3.05-3.545h.833l-3.513 4.083 3.82 5.56z"/></symbol><symbol id="icon-eds-i-circle-youtube" viewBox="0 0 24 24"><g clip-path="url(#youtube-icon)"><path d="M10.568 9.79053V13.9189L12.0275 13.1403L14.4376 11.855L12.0275 10.5686L10.568 9.79053Z"/><path d="M12 0C5.37302 0 0 5.37247 0 12C0 18.6275 5.37302 24 12 24C18.627 24 24 18.6275 24 12C24 5.37247 18.6275 0 12 0ZM18.2984 14.5486C18.2539 14.9382 18.1418 15.286 17.9637 15.5855C17.7483 15.9471 17.4071 16.1702 16.9768 16.2323C16.6015 16.2856 12.0275 16.4301 12.0275 16.4301H12.0258C12.0258 16.4301 9.15523 16.363 8.22658 16.3317C7.84222 16.3197 7.45882 16.2865 7.07812 16.2323C6.8686 16.2052 6.66815 16.1302 6.49235 16.013L6.48961 16.0114C6.34964 15.9169 6.22913 15.7963 6.13463 15.6564L6.13298 15.6536C6.11833 15.6317 6.10386 15.6088 6.08957 15.5849C5.90594 15.267 5.79223 14.9135 5.75602 14.548C5.66366 13.7017 5.62054 12.8508 5.62689 11.9995C5.62054 11.1481 5.66366 10.2972 5.75602 9.45087C5.79943 9.06127 5.91208 8.71289 6.08957 8.41451C6.30497 8.05348 6.64731 7.82984 7.07757 7.76774C7.45123 7.71499 7.83863 7.68147 8.22603 7.66828C9.13106 7.63861 12.0269 7.57047 12.0269 7.57047C12.0269 7.57047 14.9228 7.63861 15.8273 7.66828C16.2152 7.68092 16.6015 7.71499 16.9763 7.76774C17.2554 7.80786 17.4972 7.91611 17.6906 8.08645C17.734 8.12382 17.9181 8.34032 17.9632 8.41506C18.1418 8.71399 18.2539 9.06182 18.2978 9.45142C18.3874 10.2614 18.4292 11.0944 18.4264 12.0011C18.4317 12.852 18.3893 13.7025 18.2984 14.5486Z"/></g></symbol><symbol id="icon-eds-i-copy-link" viewBox="0 0 24 24"><path fill-rule="evenodd" clip-rule="evenodd" d="M19.4594 8.57015C19.0689 8.17963 19.0689 7.54646 19.4594 7.15594L20.2927 6.32261C20.2927 6.32261 20.2927 6.32261 20.2927 6.32261C21.0528 5.56252 21.0528 4.33019 20.2928 3.57014C19.5327 2.81007 18.3004 2.81007 17.5404 3.57014L16.7071 4.40347C16.3165 4.794 15.6834 4.794 15.2928 4.40348C14.9023 4.01296 14.9023 3.3798 15.2928 2.98927L16.1262 2.15594C17.6673 0.614803 20.1659 0.614803 21.707 2.15593C23.2481 3.69705 23.248 6.19569 21.707 7.7368L20.8737 8.57014C20.4831 8.96067 19.85 8.96067 19.4594 8.57015Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M18.0944 5.90592C18.4849 6.29643 18.4849 6.9296 18.0944 7.32013L16.4278 8.9868C16.0373 9.37733 15.4041 9.37734 15.0136 8.98682C14.6231 8.59631 14.6231 7.96314 15.0136 7.57261L16.6802 5.90594C17.0707 5.51541 17.7039 5.5154 18.0944 5.90592Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M13.5113 6.32243C13.9018 6.71295 13.9018 7.34611 13.5113 7.73664L12.678 8.56997C12.678 8.56997 12.678 8.56997 12.678 8.56997C11.9179 9.33006 11.9179 10.5624 12.6779 11.3224C13.438 12.0825 14.6703 12.0825 15.4303 11.3224L16.2636 10.4891C16.6542 10.0986 17.2873 10.0986 17.6779 10.4891C18.0684 10.8796 18.0684 11.5128 17.6779 11.9033L16.8445 12.7366C15.3034 14.2778 12.8048 14.2778 11.2637 12.7366C9.72262 11.1955 9.72266 8.69689 11.2637 7.15578L12.097 6.32244C12.4876 5.93191 13.1207 5.93191 13.5113 6.32243Z"/><path d="M8 20V22H19.4619C20.136 22 20.7822 21.7311 21.2582 21.2529C21.7333 20.7757 22 20.1289 22 19.4549V15C22 14.4477 21.5523 14 21 14C20.4477 14 20 14.4477 20 15V19.4549C20 19.6004 19.9426 19.7397 19.8408 19.842C19.7399 19.9433 19.6037 20 19.4619 20H8Z"/><path d="M4 13H2V19.4619C2 20.136 2.26889 20.7822 2.74705 21.2582C3.22434 21.7333 3.87105 22 4.5451 22H9C9.55228 22 10 21.5523 10 21C10 20.4477 9.55228 20 9 20H4.5451C4.39957 20 4.26028 19.9426 4.15804 19.8408C4.05668 19.7399 4 19.6037 4 19.4619V13Z"/><path d="M4 13H2V4.53808C2 3.86398 2.26889 3.21777 2.74705 2.74178C3.22434 2.26666 3.87105 2 4.5451 2H9C9.55228 2 10 2.44772 10 3C10 3.55228 9.55228 4 9 4H4.5451C4.39957 4 4.26028 4.05743 4.15804 4.15921C4.05668 4.26011 4 4.39633 4 4.53808V13Z"/></symbol><symbol id="icon-eds-i-funding-dollar" viewBox="0 0 32 32"><path d="M17.333 7.79549V9.21808C18.3681 9.32469 19.2889 9.82002 19.9444 10.5523C20.2938 10.9427 20.5697 11.4022 20.7488 11.9089C20.9942 12.6031 20.6303 13.3649 19.936 13.6103C19.2418 13.8558 18.48 13.4919 18.2346 12.7976C18.1735 12.6249 18.0788 12.4665 17.9574 12.3308C17.6988 12.0419 17.3272 11.8632 16.9122 11.8632H16.042C16.028 11.8636 16.0139 11.8639 15.9997 11.8639C15.9907 11.8639 15.9817 11.8638 15.9727 11.8636C15.9676 11.8635 15.9624 11.8634 15.9573 11.8632H14.7952C14.1833 11.8632 13.6872 12.3593 13.6872 12.9713C13.6872 13.492 14.0498 13.9424 14.5584 14.0537L17.7816 14.7588C19.6498 15.1675 20.9806 16.8226 20.9806 18.734C20.9806 20.8383 19.3827 22.5712 17.333 22.7819V24.2051C17.333 24.9415 16.7361 25.5384 15.9997 25.5384C15.2633 25.5384 14.6663 24.9415 14.6663 24.2051V22.7817C13.0793 22.618 11.7653 21.5424 11.2524 20.091C11.007 19.3967 11.3709 18.635 12.0651 18.3896C12.7594 18.1442 13.5212 18.5081 13.7666 19.2024C13.9597 19.7486 14.4807 20.1367 15.0889 20.1367H15.9849C15.9898 20.1367 15.9947 20.1366 15.9997 20.1366C16.0046 20.1366 16.0095 20.1367 16.0144 20.1367H16.9122C17.6857 20.1367 18.3139 19.5088 18.3139 18.734C18.3139 18.0748 17.8548 17.5045 17.2118 17.3639L13.9886 16.6588C12.2557 16.2797 11.0205 14.7451 11.0205 12.9713C11.0205 10.9297 12.6413 9.26664 14.6663 9.19869V7.79549C14.6663 7.05911 15.2633 6.46216 15.9997 6.46216C16.7361 6.46216 17.333 7.05911 17.333 7.79549Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M15.9997 1.33325C7.8995 1.33325 1.33301 7.89974 1.33301 15.9999C1.33301 24.1002 7.89951 30.6666 15.9997 30.6666C24.1 30.6666 30.6663 24.1002 30.6663 15.9999C30.6663 7.89975 24.1 1.33325 15.9997 1.33325ZM3.99967 15.9999C3.99967 9.3725 9.37226 3.99992 15.9997 3.99992C22.6272 3.99992 27.9997 9.3725 27.9997 15.9999C27.9997 22.6274 22.6272 27.9999 15.9997 27.9999C9.37225 27.9999 3.99967 22.6274 3.99967 15.9999Z"/></symbol><symbol id="icon-eds-i-github-medium" viewBox="0 0 24 24"><path d="M 11.964844 0 C 5.347656 0 0 5.269531 0 11.792969 C 0 17.003906 3.425781 21.417969 8.179688 22.976562 C 8.773438 23.09375 8.992188 22.722656 8.992188 22.410156 C 8.992188 22.136719 8.972656 21.203125 8.972656 20.226562 C 5.644531 20.929688 4.953125 18.820312 4.953125 18.820312 C 4.417969 17.453125 3.625 17.101562 3.625 17.101562 C 2.535156 16.378906 3.703125 16.378906 3.703125 16.378906 C 4.914062 16.457031 5.546875 17.589844 5.546875 17.589844 C 6.617188 19.386719 8.339844 18.878906 9.03125 18.566406 C 9.132812 17.804688 9.449219 17.277344 9.785156 16.984375 C 7.132812 16.710938 4.339844 15.695312 4.339844 11.167969 C 4.339844 9.878906 4.8125 8.824219 5.566406 8.003906 C 5.445312 7.710938 5.03125 6.5 5.683594 4.878906 C 5.683594 4.878906 6.695312 4.566406 8.972656 6.089844 C 9.949219 5.832031 10.953125 5.703125 11.964844 5.699219 C 12.972656 5.699219 14.003906 5.835938 14.957031 6.089844 C 17.234375 4.566406 18.242188 4.878906 18.242188 4.878906 C 18.898438 6.5 18.480469 7.710938 18.363281 8.003906 C 19.136719 8.824219 19.589844 9.878906 19.589844 11.167969 C 19.589844 15.695312 16.796875 16.691406 14.125 16.984375 C 14.558594 17.355469 14.933594 18.058594 14.933594 19.171875 C 14.933594 20.753906 14.914062 22.019531 14.914062 22.410156 C 14.914062 22.722656 15.132812 23.09375 15.726562 22.976562 C 20.480469 21.414062 23.910156 17.003906 23.910156 11.792969 C 23.929688 5.269531 18.558594 0 11.964844 0 Z M 11.964844 0 "/></symbol><symbol id="icon-eds-i-institution-medium" viewBox="0 0 24 24"><g><path fill-rule="evenodd" clip-rule="evenodd" d="M11.9967 1C11.6364 1 11.279 1.0898 10.961 1.2646C10.9318 1.28061 10.9035 1.29806 10.8761 1.31689L2.79765 6.87C2.46776 7.08001 2.20618 7.38466 2.07836 7.76668C1.94823 8.15561 1.98027 8.55648 2.12665 8.90067C2.42086 9.59246 3.12798 10 3.90107 10H4.99994V16H4.49994C3.11923 16 1.99994 17.1193 1.99994 18.5V19.5C1.99994 20.8807 3.11923 22 4.49994 22H19.4999C20.8807 22 21.9999 20.8807 21.9999 19.5V18.5C21.9999 17.1193 20.8807 16 19.4999 16H18.9999V10H20.0922C20.8653 10 21.5725 9.59252 21.8667 8.90065C22.0131 8.55642 22.0451 8.15553 21.9149 7.7666C21.7871 7.38459 21.5255 7.07997 21.1956 6.86998L13.1172 1.31689C13.0898 1.29806 13.0615 1.28061 13.0324 1.2646C12.7143 1.0898 12.357 1 11.9967 1ZM4.6844 8L11.9472 3.00755C11.9616 3.00295 11.9783 3 11.9967 3C12.015 3 12.0318 3.00295 12.0461 3.00755L19.3089 8H4.6844ZM16.9999 16V10H14.9999V16H16.9999ZM12.9999 16V10H10.9999V16H12.9999ZM8.99994 16V10H6.99994V16H8.99994ZM3.99994 18.5C3.99994 18.2239 4.2238 18 4.49994 18H19.4999C19.7761 18 19.9999 18.2239 19.9999 18.5V19.5C19.9999 19.7761 19.7761 20 19.4999 20H4.49994C4.2238 20 3.99994 19.7761 3.99994 19.5V18.5Z"/></g></symbol><symbol id="icon-eds-i-limited-access" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 3v3a1 1 0 0 1-2 0V2.923C2 1.875 2.84 1 3.909 1h5.909a1 1 0 0 1 .713.298l3.181 3.231a1 1 0 0 1 .288.702V6a1 1 0 1 1-2 0v-.36L9.4 3H4ZM3 8a1 1 0 0 1 1 1v1a1 1 0 1 1-2 0V9a1 1 0 0 1 1-1Zm10 0a1 1 0 0 1 1 1v1a1 1 0 1 1-2 0V9a1 1 0 0 1 1-1Zm-3.5 6a1 1 0 0 1-1 1h-1a1 1 0 1 1 0-2h1a1 1 0 0 1 1 1Zm2.441-1a1 1 0 0 1 2 0c0 .73-.246 1.306-.706 1.664a1.61 1.61 0 0 1-.876.334l-.032.002H11.5a1 1 0 1 1 0-2h.441ZM4 13a1 1 0 0 0-2 0c0 .73.247 1.306.706 1.664a1.609 1.609 0 0 0 .876.334l.032.002H4.5a1 1 0 1 0 0-2H4Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-marker-filled"><path d="M19.7998 21.1049C19.7998 21.7661 19.4529 22.3363 18.9053 22.6263C18.3697 22.9099 17.7222 22.8847 17.1855 22.5629C17.1651 22.5506 17.1445 22.5375 17.125 22.5238L11.999 18.9261L6.87402 22.5238C6.85458 22.5374 6.83481 22.5506 6.81445 22.5629C6.25918 22.896 5.60347 22.8929 5.08398 22.6469C4.54665 22.3923 4.09961 21.8431 4.09961 21.1049V3.57751C4.09961 2.22526 5.14769 1.17712 6.5 1.17712H17.3994C18.7517 1.17712 19.7998 2.22526 19.7998 3.57751V21.1049Z"/></symbol><symbol id="icon-eds-i-marker-unfilled"><path d="M17.7998 3.57751C17.7998 3.32977 17.6471 3.17712 17.3994 3.17712H6.5C6.25231 3.17712 6.09961 3.32977 6.09961 3.57751V20.6244L11.4248 16.8871L11.5596 16.807C11.8831 16.6484 12.2726 16.6755 12.5742 16.8871L17.7998 20.5531V3.57751ZM19.7998 21.1049C19.7998 21.7661 19.4529 22.3363 18.9053 22.6263C18.3697 22.9099 17.7222 22.8847 17.1855 22.5629C17.1651 22.5506 17.1445 22.5375 17.125 22.5238L11.999 18.9261L6.87402 22.5238C6.85458 22.5374 6.83481 22.5506 6.81445 22.5629C6.25918 22.896 5.60347 22.8929 5.08398 22.6469C4.54665 22.3923 4.09961 21.8431 4.09961 21.1049V3.57751C4.09961 2.22526 5.14769 1.17712 6.5 1.17712H17.3994C18.7517 1.17712 19.7998 2.22526 19.7998 3.57751V21.1049Z"/></symbol><symbol id="icon-eds-i-rss" viewBox="0 0 22 22"><path d="M1.96094 1C1.96094 0.447715 2.40865 0 2.96094 0C5.46109 0 7.93678 0.492038 10.2467 1.44806C12.5565 2.40407 14.6554 3.80534 16.4234 5.57189C18.1913 7.33843 19.5939 9.4357 20.5508 11.744C21.5077 14.0522 22.0001 16.5263 22.0001 19.0247C22.0001 19.577 21.5524 20.0247 21.0001 20.0247C20.4478 20.0247 20.0001 19.577 20.0001 19.0247C20.0001 16.7891 19.5595 14.5753 18.7033 12.5098C17.8471 10.4444 16.5919 8.56762 15.0097 6.98666C13.4275 5.40575 11.5492 4.15167 9.48182 3.29604C7.41447 2.4404 5.19868 2 2.96094 2C2.40865 2 1.96094 1.55228 1.96094 1Z"/><path fill-rule="evenodd" clip-rule="evenodd" d="M0 18.649C0 16.7974 1.50196 15.298 3.35294 15.298C5.20392 15.298 6.70588 16.7974 6.70588 18.649C6.70588 20.5003 5.20397 22 3.35294 22C1.50191 22 0 20.5003 0 18.649ZM3.35294 17.298C2.60493 17.298 2 17.9036 2 18.649C2 19.3943 2.60498 20 3.35294 20C4.1009 20 4.70588 19.3943 4.70588 18.649C4.70588 17.9036 4.10095 17.298 3.35294 17.298Z"/><path d="M3.3374 7.46115C2.78512 7.46115 2.3374 7.90887 2.3374 8.46115C2.3374 9.01344 2.78512 9.46115 3.3374 9.46115C4.54515 9.46115 5.74107 9.69885 6.85684 10.1606C7.97262 10.6224 8.98639 11.2993 9.84028 12.1525C10.6942 13.0057 11.3715 14.0185 11.8336 15.1332C12.2956 16.2478 12.5335 17.4424 12.5335 18.649C12.5335 19.2013 12.9812 19.649 13.5335 19.649C14.0858 19.649 14.5335 19.2013 14.5335 18.649C14.5335 17.1796 14.2438 15.7247 13.6811 14.3673C13.1184 13.0099 12.2936 11.7765 11.2539 10.7377C10.2142 9.69885 8.97999 8.87484 7.62168 8.31266C6.26337 7.75049 4.80757 7.46115 3.3374 7.46115Z"/></symbol><symbol id="icon-eds-i-search-category-medium" viewBox="0 0 32 32"><path fill-rule="evenodd" d="M2 5.306A3.306 3.306 0 0 1 5.306 2h5.833a3.306 3.306 0 0 1 3.306 3.306v5.833a3.306 3.306 0 0 1-3.306 3.305H5.306A3.306 3.306 0 0 1 2 11.14V5.306Zm3.306-.584a.583.583 0 0 0-.584.584v5.833c0 .322.261.583.584.583h5.833a.583.583 0 0 0 .583-.583V5.306a.583.583 0 0 0-.583-.584H5.306Zm15.555 8.945a7.194 7.194 0 1 0 4.034 13.153l2.781 2.781a1.361 1.361 0 1 0 1.925-1.925l-2.781-2.781a7.194 7.194 0 0 0-5.958-11.228Zm3.173 10.346a4.472 4.472 0 1 0-.021.021l.01-.01.011-.011Zm-5.117-19.29a.583.583 0 0 0-.584.583v5.833a1.361 1.361 0 0 1-2.722 0V5.306A3.306 3.306 0 0 1 18.917 2h5.833a3.306 3.306 0 0 1 3.306 3.306v5.833c0 .6-.161 1.166-.443 1.654a1.361 1.361 0 1 1-2.357-1.363.575.575 0 0 0 .078-.291V5.306a.583.583 0 0 0-.584-.584h-5.833ZM2 18.916a3.306 3.306 0 0 1 3.306-3.306h5.833a1.361 1.361 0 1 1 0 2.722H5.306a.583.583 0 0 0-.584.584v5.833c0 .322.261.583.584.583h5.833a.574.574 0 0 0 .29-.077 1.361 1.361 0 1 1 1.364 2.356 3.296 3.296 0 0 1-1.654.444H5.306A3.306 3.306 0 0 1 2 24.75v-5.833Z" clip-rule="evenodd"/></symbol><symbol id="icon-eds-i-search-magic" viewBox="0 0 20 20"><path d="M8.695 1.667a9.1 9.1 0 0 1 1.756.17A3.098 3.098 0 0 0 9.436 3.37a7.333 7.333 0 0 0-.738-.038c-3.841 0-6.956 2.986-6.956 6.668 0 3.681 3.115 6.665 6.956 6.665 3.642 0 6.627-2.681 6.928-6.096a3.19 3.19 0 0 0 1.763-.548 8.091 8.091 0 0 1-1.961 5.25l3.446 3.306a.81.81 0 0 1 0 1.178.897.897 0 0 1-1.23 0l-3.447-3.303a8.892 8.892 0 0 1-5.502 1.88C3.893 18.334 0 14.603 0 10c0-4.603 3.893-8.333 8.695-8.334Z"/><path d="M20 4.166a.663.663 0 0 1-.128.395.709.709 0 0 1-.342.251l-2.341.827-.863 2.244a.693.693 0 0 1-.263.326.74.74 0 0 1-.821 0 .693.693 0 0 1-.264-.326l-.862-2.244-2.341-.827a.715.715 0 0 1-.341-.252.669.669 0 0 1 0-.787.715.715 0 0 1 .34-.252l2.342-.827.862-2.244a.693.693 0 0 1 .264-.327.74.74 0 0 1 .821 0 .7.7 0 0 1 .263.327l.863 2.244 2.34.827a.709.709 0 0 1 .343.251.663.663 0 0 1 .128.394Z"/></symbol><symbol id="icon-eds-i-subjects-medium" viewBox="0 0 24 24"><g id="icon-subjects-copy" stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M13.3846154,2 C14.7015971,2 15.7692308,3.06762994 15.7692308,4.38461538 L15.7692308,7.15384615 C15.7692308,8.47082629 14.7015955,9.53846154 13.3846154,9.53846154 L13.1038388,9.53925278 C13.2061091,9.85347965 13.3815528,10.1423885 13.6195822,10.3804178 C13.9722182,10.7330539 14.436524,10.9483278 14.9293854,10.9918129 L15.1153846,11 C16.2068332,11 17.2535347,11.433562 18.0254647,12.2054189 C18.6411944,12.8212361 19.0416785,13.6120766 19.1784166,14.4609738 L19.6153846,14.4615385 C20.932386,14.4615385 22,15.5291672 22,16.8461538 L22,19.6153846 C22,20.9323924 20.9323924,22 19.6153846,22 L16.8461538,22 C15.5291672,22 14.4615385,20.932386 14.4615385,19.6153846 L14.4615385,16.8461538 C14.4615385,15.5291737 15.5291737,14.4615385 16.8461538,14.4615385 L17.126925,14.460779 C17.0246537,14.1465537 16.8492179,13.857633 16.6112344,13.6196157 C16.2144418,13.2228606 15.6764136,13 15.1153846,13 C14.0239122,13 12.9771569,12.5664197 12.2053686,11.7946314 C12.1335167,11.7227795 12.0645962,11.6485444 11.9986839,11.5721119 C11.9354038,11.6485444 11.8664833,11.7227795 11.7946314,11.7946314 C11.0228431,12.5664197 9.97608778,13 8.88461538,13 C8.323576,13 7.78552852,13.2228666 7.38881294,13.6195822 C7.15078359,13.8576115 6.97533988,14.1465203 6.8730696,14.4607472 L7.15384615,14.4615385 C8.47082629,14.4615385 9.53846154,15.5291737 9.53846154,16.8461538 L9.53846154,19.6153846 C9.53846154,20.932386 8.47083276,22 7.15384615,22 L4.38461538,22 C3.06762347,22 2,20.9323876 2,19.6153846 L2,16.8461538 C2,15.5291721 3.06762994,14.4615385 4.38461538,14.4615385 L4.8215823,14.4609378 C4.95831893,13.6120029 5.3588057,12.8211623 5.97459937,12.2053686 C6.69125996,11.488708 7.64500941,11.0636656 8.6514968,11.0066017 L8.88461538,11 C9.44565477,11 9.98370225,10.7771334 10.3804178,10.3804178 C10.6184472,10.1423885 10.7938909,9.85347965 10.8961612,9.53925278 L10.6153846,9.53846154 C9.29840448,9.53846154 8.23076923,8.47082629 8.23076923,7.15384615 L8.23076923,4.38461538 C8.23076923,3.06762994 9.29840286,2 10.6153846,2 L13.3846154,2 Z M7.15384615,16.4615385 L4.38461538,16.4615385 C4.17220099,16.4615385 4,16.63374 4,16.8461538 L4,19.6153846 C4,19.8278134 4.17218833,20 4.38461538,20 L7.15384615,20 C7.36626945,20 7.53846154,19.8278103 7.53846154,19.6153846 L7.53846154,16.8461538 C7.53846154,16.6337432 7.36625679,16.4615385 7.15384615,16.4615385 Z M19.6153846,16.4615385 L16.8461538,16.4615385 C16.6337432,16.4615385 16.4615385,16.6337432 16.4615385,16.8461538 L16.4615385,19.6153846 C16.4615385,19.8278103 16.6337306,20 16.8461538,20 L19.6153846,20 C19.8278229,20 20,19.8278229 20,19.6153846 L20,16.8461538 C20,16.6337306 19.8278103,16.4615385 19.6153846,16.4615385 Z M13.3846154,4 L10.6153846,4 C10.4029708,4 10.2307692,4.17220099 10.2307692,4.38461538 L10.2307692,7.15384615 C10.2307692,7.36625679 10.402974,7.53846154 10.6153846,7.53846154 L13.3846154,7.53846154 C13.597026,7.53846154 13.7692308,7.36625679 13.7692308,7.15384615 L13.7692308,4.38461538 C13.7692308,4.17220099 13.5970292,4 13.3846154,4 Z" id="Shape" fill-rule="nonzero"/></g></symbol><symbol id="icon-eds-small-arrow-left" viewBox="0 0 16 17"><path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14 8.092H2m0 0L8 2M2 8.092l6 6.035"/></symbol><symbol id="icon-eds-small-arrow-right" viewBox="0 0 16 16"><g fill-rule="evenodd" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M2 8.092h12M8 2l6 6.092M8 14.127l6-6.035"/></g></symbol><symbol id="icon-globe-with-star" viewBox="0 0 32 32"><path style="fill:none;stroke:#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M27.282 17.026c0 6.797-5.51 12.307-12.307 12.307-6.798 0-12.308-5.51-12.308-12.307 0-6.798 5.51-12.308 12.308-12.308M2.667 17.026h14.201"/><path style="fill:none;stroke:#fff" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14.975 4.718a21.244 21.244 0 0 0-4.734 12.308c.233 4.5 1.89 8.81 4.734 12.307a21.245 21.245 0 0 0 4.394-9.467M17.045 9.72c-.709-.126-.709-1.16 0-1.286 2.568-.454 4.61-2.443 5.168-5.032l.043-.199c.153-.712 1.15-.716 1.31-.006l.052.232c.578 2.577 2.621 4.549 5.182 5.002.712.126.712 1.166 0 1.292-2.561.453-4.604 2.425-5.182 5.002l-.052.231c-.16.711-1.157.707-1.31-.005l-.043-.199c-.557-2.59-2.6-4.578-5.168-5.032Z"/></symbol><symbol id="icon-orcid-logo" viewBox="0 0 40 40"><path fill-rule="evenodd" d="M12.281 10.453c.875 0 1.578-.719 1.578-1.578 0-.86-.703-1.578-1.578-1.578-.875 0-1.578.703-1.578 1.578 0 .86.703 1.578 1.578 1.578Zm-1.203 18.641h2.406V12.359h-2.406v16.735Z"/><path fill-rule="evenodd" d="M17.016 12.36h6.5c6.187 0 8.906 4.421 8.906 8.374 0 4.297-3.36 8.375-8.875 8.375h-6.531V12.36Zm6.234 14.578h-3.828V14.53h3.703c4.688 0 6.828 2.844 6.828 6.203 0 2.063-1.25 6.203-6.703 6.203Z" clip-rule="evenodd"/></symbol><symbol id="icon-thumbs-down" viewBox="41 0 33 33"><path stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M61 17.611h-1l-2.085 4.436a1 1 0 0 1-.366.332 1.04 1.04 0 0 1-1.197-.159.95.95 0 0 1-.298-.678v-3.32h-3.93c-.61 0-.674-1.066-.599-1.55l.726-4.301a.98.98 0 0 1 .341-.622 1.06 1.06 0 0 1 .685-.249H61M63.5 11.5v6"/></symbol><symbol id="icon-thumbs-up-medium" viewBox="0 0 24 24"><path d="M6.75 9.33333H8.25L11.3778 2.67913C11.5138 2.47128 11.7025 2.29994 11.9263 2.18116C12.1502 2.06239 12.4018 2.00005 12.6576 2C13.056 1.99999 13.4384 2.15092 13.7214 2.41998C14.0044 2.68903 14.1652 3.05442 14.1688 3.43663V8.41667C16.1342 8.41667 18.1116 8.41667 20.0648 8.41667C20.9795 8.41667 21.0744 10.0164 20.9625 10.7422L19.8733 17.194C19.8269 17.5542 19.6449 17.8856 19.3616 18.1261C19.0783 18.3667 18.7132 18.4996 18.3349 18.5H6.75" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/><path d="M3 18.5V9.5" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/></symbol><symbol id="icon-thumbs-up"><path stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 15.389h1l2.085-4.436a1 1 0 0 1 .366-.332 1.04 1.04 0 0 1 1.197.159.95.95 0 0 1 .298.678v3.32h3.93c.61 0 .674 1.066.599 1.55l-.726 4.301a.98.98 0 0 1-.341.622 1.06 1.06 0 0 1-.685.249H13m-2.5 0v-6"/></symbol><symbol id="icon-tick-with-curly-circle" viewBox="0 0 40 40"><path d="M17.923.757a3.227 3.227 0 0 1 4.401.231l2.168 2.25 3.001-.866.33-.076a3.23 3.23 0 0 1 3.598 2.076l.099.325.75 3.03 3.033.753a3.229 3.229 0 0 1 2.4 3.697l-.075.33-.865 3.001 2.249 2.168.231.247a3.227 3.227 0 0 1-.231 4.401l-2.25 2.166.866 3.003.076.33a3.228 3.228 0 0 1-2.401 3.697l-3.033.75-.75 3.033a3.229 3.229 0 0 1-4.027 2.325l-3.001-.867-2.168 2.25a3.227 3.227 0 0 1-4.648 0l-2.17-2.25-2.999.867a3.229 3.229 0 0 1-4.027-2.325l-.752-3.033-3.03-.75a3.229 3.229 0 0 1-2.326-4.027l.865-3.001-2.249-2.168a3.227 3.227 0 0 1 0-4.648l2.25-2.17-.866-2.999A3.229 3.229 0 0 1 4.697 8.48l3.031-.752.752-3.03a3.229 3.229 0 0 1 4.027-2.326l3 .865L17.675.988l.247-.231Zm.027 5.156a3.23 3.23 0 0 1-3.219.864l-2.838-.82-.712 2.87a3.227 3.227 0 0 1-2.355 2.354l-2.868.712.819 2.838a3.23 3.23 0 0 1-.864 3.219L3.786 20l2.127 2.05a3.23 3.23 0 0 1 .864 3.219l-.82 2.837 2.87.713.215.062a3.228 3.228 0 0 1 2.14 2.293l.71 2.867 2.84-.818a3.229 3.229 0 0 1 3.218.864L20 36.214l2.05-2.127.16-.156a3.228 3.228 0 0 1 2.841-.76l.218.052 2.837.818.713-2.867.062-.214a3.227 3.227 0 0 1 2.293-2.141l2.867-.713-.816-2.837c-.331-1.15 0-2.389.861-3.219L36.212 20l-2.126-2.05a3.229 3.229 0 0 1-.861-3.219l.816-2.838-2.867-.712a3.228 3.228 0 0 1-2.355-2.355l-.713-2.868-2.837.819a3.23 3.23 0 0 1-3.219-.864L20 3.786l-2.05 2.127Z" stroke="transparent" stroke-width=".9"/><path d="M25.723 13.406a1.807 1.807 0 0 1 2.699 2.397l-9.658 12.074a1.808 1.808 0 0 1-2.497.316L11.44 24.57a1.806 1.806 0 1 1 2.168-2.892l3.427 2.57 8.565-10.704.124-.138Z" stroke="transparent" stroke-width=".9"/></symbol></svg>
</div>


        

        
        
    <a class="c-skip-link" href="#main">Skip to main content</a>

    
        
    <aside class="u-lazy-ad-wrapper u-mbs-0" aria-label="Advertisement">
        <div class="c-ad c-ad--728x90 c-ad--conditional" data-test="springer-doubleclick-ad">
            <div class="c-ad c-ad__inner" >
                <p class="c-ad__label">Advertisement</p>
                <div id="div-gpt-ad-LB1"
                     class="div-gpt-ad grade-c-hide"
                     data-gpt
                     data-gpt-unitpath="/270604982/springerlink/40593/article"
                     data-gpt-sizes="728x90"
                     data-gpt-targeting="pos=top;articleid=s40593-025-00480-y;"
                     data-ad-type="top"
                     style="min-width:728px;min-height:90px">
                    
                    <script>
                        window.SN = window.SN || {};
                        window.SN.libs = window.SN.libs || {};
                        window.SN.libs.ads = window.SN.libs.ads || {};
                        window.SN.libs.ads.slotConfig = window.SN.libs.ads.slotConfig || {};
                        window.SN.libs.ads.slotConfig['LB1'] = {
                            'pos': 'top',
                            'type': 'top',
                        };
                        window.SN.libs.ads.slotConfig['unitPath'] = '/270604982/springerlink/40593/article';
                    </script>
                    <noscript>
                        <a href="//pubads.g.doubleclick.net/gampad/jump?iu=/270604982/springerlink/40593/article&amp;sz=728x90&amp;pos=top&amp;articleid=s40593-025-00480-y">
                            <img data-test="gpt-advert-fallback-img"
                                 src="//pubads.g.doubleclick.net/gampad/ad?iu=/270604982/springerlink/40593/article&amp;sz=728x90&amp;pos=top&amp;articleid=s40593-025-00480-y"
                                 alt="Advertisement"
                                 width="728"
                                 height="90">
                        </a>
                    </noscript>
                </div>
            </div>
        </div>
    </aside>

    

    <header class="eds-c-header" data-eds-c-header>
    <div class="eds-c-header__container" data-eds-c-header-expander-anchor>
        <div class="eds-c-header__brand">
            
                
                    <a href="https://link.springer.com"
                    	 data-test=springerlink-logo
                        
                            data-track="click_imprint_logo"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click logo link"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        <img src="/oscar-static/images/darwin/header/img/logo-springer-nature-link-3149409f62.svg" alt="Springer Nature Link">
                    </a>
                
            
        </div>

        
            
                
    
        <a class="c-header__link eds-c-header__link" id="identity-account-widget" data-track="click_login" data-track-context="header" href='https://idp.springer.com/auth/personal/springernature?redirect_uri=https://link.springer.com/article/10.1007/s40593-025-00480-y'><span class="eds-c-header__widget-fragment-title">Log in</span></a>
    


            
        
    </div>

    
        <nav class="eds-c-header__nav" aria-label="header navigation">
            <div class="eds-c-header__nav-container">
                <div class="eds-c-header__item eds-c-header__item--menu">
                   <a href="#eds-c-header-nav" class="eds-c-header__link" data-eds-c-header-expander>
                        <svg class="eds-c-header__icon" width="24" height="24" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-eds-i-menu-medium"></use>
                        </svg><span>Menu</span>
                    </a>
                </div>

                <div class="eds-c-header__item eds-c-header__item--inline-links">
                    
                        <a class="eds-c-header__link" href="https://link.springer.com/journals/"
                            
                                data-track="nav_find_a_journal"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click find a journal"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Find a journal
                        </a>
                    
                        <a class="eds-c-header__link" href="https://www.springernature.com/gp/authors"
                            
                                data-track="nav_how_to_publish"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click publish with us link"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Publish with us
                        </a>
                    
                        <a class="eds-c-header__link" href="https://link.springernature.com/home/"
                            
                                data-track="nav_track_your_research"
                            
                                data-track-context="unified header"
                            
                                data-track-action="click track your research"
                            
                                data-track-category="unified header"
                            
                                data-track-label="link"
                            
						>
                            Track your research
                        </a>
                    
                </div>

                <div class="eds-c-header__link-container">
                    
                        <div class="eds-c-header__item eds-c-header__item--divider">
                            <a href="#eds-c-header-popup-search" class="eds-c-header__link" data-eds-c-header-expander data-eds-c-header-test-search-btn>
                                <svg class="eds-c-header__icon" width="24" height="24" aria-hidden="true" focusable="false">
                                    <use xlink:href="#icon-eds-i-search-medium"></use>
                                </svg><span>Search</span>
                            </a>
                        </div>
                    
                    
                        
                            <div id="ecommerce-header-cart-icon-link" class="eds-c-header__item ecommerce-cart" style="display:inline-block">
 <a class="eds-c-header__link" href="https://order.springer.com/public/cart" style="appearance:none;border:none;background:none;color:inherit;position:relative">
  <svg id="eds-i-cart" class="eds-c-header__icon" xmlns="http://www.w3.org/2000/svg" height="24" width="24" viewBox="0 0 24 24" aria-hidden="true" focusable="false">
   <path fill="currentColor" fill-rule="nonzero" d="M2 1a1 1 0 0 0 0 2l1.659.001 2.257 12.808a2.599 2.599 0 0 0 2.435 2.185l.167.004 9.976-.001a2.613 2.613 0 0 0 2.61-1.748l.03-.106 1.755-7.82.032-.107a2.546 2.546 0 0 0-.311-1.986l-.108-.157a2.604 2.604 0 0 0-2.197-1.076L6.042 5l-.56-3.17a1 1 0 0 0-.864-.82l-.12-.007L2.001 1ZM20.35 6.996a.63.63 0 0 1 .54.26.55.55 0 0 1 .082.505l-.028.1L19.2 15.63l-.022.05c-.094.177-.282.299-.526.317l-10.145.002a.61.61 0 0 1-.618-.515L6.394 6.999l13.955-.003ZM18 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4ZM8 19a2 2 0 1 0 0 4 2 2 0 0 0 0-4Z"></path>
  </svg>
  <span>Cart</span><span class="cart-info" style="display:none;position:absolute;top:10px;right:45px;background-color:#C65301;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center"></span>
 </a>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    document.body.addEventListener("updatedCart", function () {
        updateCartIcon();
    }, false);
    return updateCartIcon();
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function (_) { });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
                        
                    
                </div>
            </div>
        </nav>
    
</header>



    <article lang="en" id="main" class="app-masthead__colour-12">
        <section class="app-masthead " aria-label="article masthead">
    <div class="app-masthead__container">
        
            <div class="app-article-masthead u-sans-serif js-context-bar-sticky-point-masthead" data-track-component="article" data-test="masthead-component">
                <div class="app-article-masthead__info">
                    
    
        <nav aria-label="breadcrumbs" data-test="breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--contrast" itemscope itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/" class="c-breadcrumbs__link" itemprop="item" data-track="click_breadcrumb" data-track-context="article page"  data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" width="10" height="10" viewBox="0 0 10 10">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/journal/40593" class="c-breadcrumbs__link" itemprop="item" data-track="click_breadcrumb" data-track-context="article page"  data-track-category="article" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">International Journal of Artificial Intelligence in Education</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" width="10" height="10" viewBox="0 0 10 10">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Article</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    

                    <h1 class="c-article-title" data-test="article-title" data-article-title="">Speech Enabled Reading Fluency Assessment: a Validation Study</h1>

                    <ul class="c-article-identifiers">
                        
        <li class="c-article-identifiers__item" data-test="article-category">ARTICLE</li>
    
        <li class="c-article-identifiers__item">
            <a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link" class="u-color-open-access" data-test="open-access">Open access</a>
        </li>
    
    

                        <li class="c-article-identifiers__item">
                            Published: <time datetime="2025-05-14">14 May 2025</time>
                        </li>
                    </ul>
                    <ul class="c-article-identifiers c-article-identifiers--cite-list">
                        <li class="c-article-identifiers__item">
                             (<span data-test="article-publication-year">2025</span>)
                        </li>
                        <li class="c-article-identifiers__item c-article-identifiers__item--cite">
                            <a href="#citeas" data-track="click" data-track-action="cite this article" data-track-category="article body" data-track-label="link">Cite this article</a>
                        </li>
                    </ul>

                    <div class="app-article-masthead__buttons" data-test="download-article-link-wrapper" data-track-context="masthead">
                        <p class="app-article-masthead__access">
                            <svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-check-filled-medium"></use></svg>
                            You have full access to this <a href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research" data-track="click" data-track-action="open access" data-track-label="link">open access</a> article</p>
                        
                        <div class="app-article-masthead__access-container">
                            
        <div class="c-pdf-container">
            <div class="c-pdf-download u-clear-both u-mb-16">
                <a href="/content/pdf/10.1007/s40593-025-00480-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="content_download" data-track-type="article pdf download" data-track-action="download pdf" data-track-label="button" data-track-external download>
                    
                        <span class="c-pdf-download__text">Download PDF</span>
                        <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-eds-i-download-medium"/></svg>
                    
                </a>
            </div>
        </div>
    

                            
                        </div>
                    </div>
                </div>
                <div class="app-article-masthead__brand">
                    
                        
                            <a href="/journal/40593"
                        
                           class="app-article-masthead__journal-link"
                           data-track="click_journal_home"
                           data-track-action="journal homepage"
                           data-track-context="article page"
                           data-track-label="link">
                            <picture>
                                <source type="image/webp" media="(min-width: 768px)" width="120" height="159"
                                        srcset="https://media.springernature.com/w120/springer-static/cover-hires/journal/40593?as=webp,
                                                    https://media.springernature.com/w316/springer-static/cover-hires/journal/40593?as=webp 2x">
                                <img width="72" height="95"
                                     src="https://media.springernature.com/w72/springer-static/cover-hires/journal/40593?as=webp"
                                     srcset="https://media.springernature.com/w144/springer-static/cover-hires/journal/40593?as=webp 2x" alt="">
                            </picture>
                            <span class="app-article-masthead__journal-title">International Journal of Artificial Intelligence in Education</span>
                        </a>
                        
                            <a href="/journal/40593/aims-and-scope" class="app-article-masthead__submission-link"
                               data-track="click_aims_and_scope"
                               data-track-action="aims and scope"
                               data-track-context="article page"
                               data-track-label="link">
                                Aims and scope
                                <svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-arrow-right-medium"></use></svg>
                            </a>
                        
                        
                            <a href="https://submission.springernature.com/new-submission/40593/3" class="app-article-masthead__submission-link"
                               data-track="click_submit_manuscript"
                               data-track-context="article masthead on springerlink article page"
                               data-track-action="submit manuscript"
                               data-track-label="link">
                                Submit manuscript
                                <svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-arrow-right-medium"></use></svg>
                            </a>
                        
                    
                </div>
            </div>
        
    </div>
</section>

        <div class="c-article-main u-container u-mt-24 u-mb-32 l-with-sidebar" id="main-content"
             data-component="article-container">
            <main class="u-serif js-main-column" data-track-component="article body">
                
                
                    <div class="c-context-bar u-hide"
                         data-test="context-bar"
                         data-context-bar
                         aria-hidden="true">
                        <div class="c-context-bar__container">
                            <div class="c-context-bar__title">
                                Speech Enabled Reading Fluency Assessment: a Validation Study
                            </div>
                            
                                <div class="c-context-bar__cta-container" data-test="inCoD" data-track-context="sticky banner">
                                    
        <div class="c-pdf-container">
            <div class="c-pdf-download u-clear-both u-mb-16">
                <a href="/content/pdf/10.1007/s40593-025-00480-y.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="content_download" data-track-type="article pdf download" data-track-action="download pdf" data-track-label="button" data-track-external download>
                    
                        <span class="c-pdf-download__text">Download PDF</span>
                        <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#icon-eds-i-download-medium"/></svg>
                    
                </a>
            </div>
        </div>
    


                                    
                                </div>
                            
                        </div>
                    </div>
                

                <div class="c-article-header">
                    <header>
                        <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="1_6" data-track-context="researcher popup with no profile" href="#auth-Max-Velde-Aff1-Aff2" data-author-popup="auth-Max-Velde-Aff1-Aff2" data-author-search="van der Velde, Max" data-corresp-id="c1">Max van der Velde<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-mail-medium"></use></svg></a><span class="u-js-hide">
            <a class="js-orcid" href="https://orcid.org/0000-0003-4940-2521"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0003-4940-2521</a></span><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="2_6" data-track-context="researcher popup with no profile" href="#auth-Wieke-Harmsen-Aff4" data-author-popup="auth-Wieke-Harmsen-Aff4" data-author-search="Harmsen, Wieke">Wieke Harmsen</a><sup class="u-js-hide"><a href="#Aff4">4</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="3_6" data-track-context="researcher popup with no profile" href="#auth-Bernard_P_-Veldkamp-Aff1" data-author-popup="auth-Bernard_P_-Veldkamp-Aff1" data-author-search="Veldkamp, Bernard P.">Bernard P. Veldkamp</a><sup class="u-js-hide"><a href="#Aff1">1</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="4_6" data-track-context="researcher popup with no profile" href="#auth-Remco-Feskens-Aff1-Aff2" data-author-popup="auth-Remco-Feskens-Aff1-Aff2" data-author-search="Feskens, Remco">Remco Feskens</a><sup class="u-js-hide"><a href="#Aff1">1</a>,<a href="#Aff2">2</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="5_6" data-track-context="researcher popup with no profile" href="#auth-Jos-Keuning-Aff2" data-author-popup="auth-Jos-Keuning-Aff2" data-author-search="Keuning, Jos">Jos Keuning</a><sup class="u-js-hide"><a href="#Aff2">2</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 6 authors for this article" title="Show all 6 authors for this article"></li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" data-track-index="6_6" data-track-context="researcher popup with no profile" href="#auth-Nicole-Swart-Aff3" data-author-popup="auth-Nicole-Swart-Aff3" data-author-search="Swart, Nicole">Nicole Swart</a><sup class="u-js-hide"><a href="#Aff3">3</a></sup></li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-down-medium"></use></svg><span>Show authors</span></button>
                        
    


                        <div data-test="article-metrics">
                            
        <ul class="app-article-metrics-bar u-list-reset">
            
                <li class="app-article-metrics-bar__item" data-test="access-count">
                    <p class="app-article-metrics-bar__count"><svg class="u-icon app-article-metrics-bar__icon" width="24" height="24" aria-hidden="true" focusable="false">
                        <use xlink:href="#icon-eds-i-accesses-medium"></use>
                    </svg>1477 <span class="app-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
            
            
            
                
                    <li class="app-article-metrics-bar__item app-article-metrics-bar__item--metrics">
                        <p class="app-article-metrics-bar__details"><a href="/article/10.1007/s40593-025-00480-y/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Explore all metrics <svg class="u-icon app-article-metrics-bar__arrow-icon" width="24" height="24" aria-hidden="true" focusable="false">
                            <use xlink:href="#icon-eds-i-arrow-right-medium"></use>
                        </svg></a></p>
                    </li>
                
            
        </ul>
    
                        </div>
                        
                        
    <div class="u-mt-32">
    

    
    </div>

                        
                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">

                    
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>Although the ability to comprehend what one is reading is one of the most fundamental necessities to function within society, the reading comprehension skills of students have recently been on the decline in many countries. An essential prerequisite to reading comprehension is the ability to read fluently, which is defined as the ability to read (aloud) with accuracy, speed, automaticity and prosody. Current oral reading fluency assessment instruments seldom provide detailed diagnostics however, and bestow a heavy testing burden on practitioners. Recent developments in Artificial Intelligence-based assessment methodology might provide a solution to current assessment issues, but thorough validations of such procedures have proven scarce. This study evaluates whether valid word decoding and passage reading measures (accuracy, speed and automaticity) can be generated for a semi-transparent language, using an automatic speech recognition (ASR) based oral reading fluency assessment instrument. A validation study was conducted, using the Argument-Based Approach to Validation. Data concerned 176 h of speech data, and the results of 569 and 622 oral word- and passage reading tests that are currently administered in primary schools, from 653 children attending the second- or third grade of Dutch primary education. The results of the validation indicate that it is possible to generate fluency metrics for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument. Future researchers are advised to further optimize the ASR, evaluate its errors, and realize a prosody component, completing the envisioned reading fluency assessment instrument, thereby improving reading fluency assessment throughout primary education.</p></div></div></section>

                    

                    
    


                    

                    <div data-test="cobranding-download">
                        
                    </div>

                    
                        
        
            <section aria-labelledby="inline-recommendations" data-title="Inline Recommendations" class="c-article-recommendations" data-track-component="inline-recommendations">
                <h3 class="c-article-recommendations-title" id="inline-recommendations">Similar content being viewed by others</h3>
                <div class="c-article-recommendations-list">
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w215h120/springer-static/image/art%3A10.1007%2Fs40012-018-0202-3/MediaObjects/40012_2018_202_Fig1_HTML.png" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/s40012-018-0202-3?fromPaywallRec=false"
                                           data-track="select_recommendations_1"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 1"
                                           data-track-label="10.1007/s40012-018-0202-3">Automatic assessment of childrens oral reading using speech recognition and prosody modeling
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Article</span>
                                        
                                         <span class="c-article-meta-recommendations__date">25 June 2018</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-981-33-4594-2?as&#x3D;webp" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/978-981-33-4594-2_7?fromPaywallRec=false"
                                           data-track="select_recommendations_2"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 2"
                                           data-track-label="10.1007/978-981-33-4594-2_7">An Empirical Study of the Effect of ASR-Supported English Reading Aloud Practices on Pronunciation Accuracy
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Chapter</span>
                                        
                                         <span class="c-article-meta-recommendations__date"> 2020</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                        <div class="c-article-recommendations-list__item">
                            <article class="c-article-recommendations-card" itemscope itemtype="http://schema.org/ScholarlyArticle">
                                
                                    <div class="c-article-recommendations-card__img"><img src="https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-981-99-3236-8?as&#x3D;webp" loading="lazy" alt=""></div>
                                
                                <div class="c-article-recommendations-card__main">
                                    <h3 class="c-article-recommendations-card__heading" itemprop="name headline">
                                        <a class="c-article-recommendations-card__link"
                                           itemprop="url"
                                           href="https://link.springer.com/10.1007/978-981-99-3236-8_25?fromPaywallRec=false"
                                           data-track="select_recommendations_3"
                                           data-track-context="inline recommendations"
                                           data-track-action="click recommendations inline - 3"
                                           data-track-label="10.1007/978-981-99-3236-8_25">Digital Reading Fluency Training for Primary School StudentsConcept and First Results
                                        </a>
                                    </h3>
                                    <div class="c-article-meta-recommendations" data-test="recommendation-info">
                                        <span class="c-article-meta-recommendations__item-type">Chapter</span>
                                        
                                         <span class="c-article-meta-recommendations__date"> 2024</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    
                </div>
            </section>
        
            <script>
                window.dataLayer = window.dataLayer || [];
                window.dataLayer.push({
                    recommendations: {
                        recommender: 'semantic',
                        model: 'specter',
                        policy_id: 'NA',
                        timestamp: 1764150523,
                        embedded_user: 'null'
                    }
                });
            </script>
        
    
                    

                    
                        
    <section class="app-explore-related-subjects" aria-labelledby="content-related-subjects" data-test="subject-content">
        <h3 id="content-related-subjects" class="app-explore-related-subjects__title">Explore related subjects</h3>
        <span class="u-sans-serif u-text-xs u-display-block u-mb-16">Discover the latest articles, books and news in related subjects, suggested using machine learning.</span>
        <ul class="app-explore-related-subjects__list app-explore-related-subjects__list--no-mb" role="list">
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/dental-patient-assessment"  data-track="select_related_subject_1" data-track-context="related subjects from content page" data-track-label="Dental patient assessment">Dental patient assessment</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/psychological-testing"  data-track="select_related_subject_2" data-track-context="related subjects from content page" data-track-label="Psychological Testing">Psychological Testing</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/speech-and-language-therapy"  data-track="select_related_subject_3" data-track-context="related subjects from content page" data-track-label="Speech and Language Therapy">Speech and Language Therapy</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/speech-and-audio-processing"  data-track="select_related_subject_4" data-track-context="related subjects from content page" data-track-label="Speech and Audio Processing">Speech and Audio Processing</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/speech-perception"  data-track="select_related_subject_5" data-track-context="related subjects from content page" data-track-label="Speech Perception">Speech Perception</a>
            </li>
        
            <li class="app-explore-related-subjects__items" data-test="related-subject-item">
                <a href="/subjects/assessment-and-testing"  data-track="select_related_subject_6" data-track-context="related subjects from content page" data-track-label="Assessment and Testing">Assessment and Testing</a>
            </li>
        
        </ul>
    </section>

                    

                    
                        
    <div class="app-card-service" data-test="article-checklist-banner">
        <div>
            <a class="app-card-service__link" data-track="click_presubmission_checklist" data-track-context="article page top of reading companion" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=40593"
            data-test="article-checklist-banner-link">
            <span class="app-card-service__link-text">Use our pre-submission checklist</span>
            <svg class="app-card-service__link-icon" aria-hidden="true" focusable="false"><use xlink:href="#icon-eds-i-arrow-right-small"></use></svg>
            </a>
            <p class="app-card-service__description">Avoid common mistakes on your manuscript.</p>
        </div>
        <div class="app-card-service__icon-container">
            <svg class="app-card-service__icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-clipboard-check-medium"></use>
            </svg>
        </div>
    </div>

                    

                    
                        
                                <div class="main-content">
                                    <section data-title="Speech Enabled Reading Fluency Assessment: a Validation Study"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Speech Enabled Reading Fluency Assessment: a Validation Study</h2><div class="c-article-section__content" id="Sec1-content"><p>Being able to comprehend what you are reading is one of the most fundamental necessities to function within society. Nevertheless, the reading comprehension skills of students have recently been on the decline in many countries (Meelissen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Meelissen, M. R. M., Maassen, N. A. M., Gubbels, J., van Langen, A. M. L., Valk, J., Dood, C., Derks, I., In t Zandt, M., &amp; Wolbers, M. (2023). Resultaten PISA-2022 in vogelvlucht [Results PISA-2022-An overview]. Enschede: Universiteit Twente. &#xA;                https://doi.org/10.3990/1.9789036559461&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR36" id="ref-link-section-d2615778e531">2023</a>; Mullis et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., &amp; Wry, E. (2023).PIRLS 2021 International Results in Reading.Boston College, TIMSS &amp; PIRLS International Study Center.&#xA;                https://doi.org/10.6017/lse.tpisc.tr2103.kb5342&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR41" id="ref-link-section-d2615778e534">2023</a>), increasing the risk of functional illiteracy among future generations. One of the most important prerequisites to reading comprehension is the ability to read fluently (Fuchs et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Fuchs, L., Fuchs, D., Hosp, M., &amp; Jenkins, J. (2001). Oral reading fluency as an indicator of reading competence: a theoretical, empirical, and historical analysis. Scient Stud Read., 5, 239256. &#xA;                https://doi.org/10.1207/S1532799XSSR0503_3&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR19" id="ref-link-section-d2615778e537">2001</a>; Hoover &amp; Gough, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Hoover, W. A., &amp; Gough, P. B. (1990). The simple view of reading. Reading and Writing, 2, 127160. &#xA;                https://doi.org/10.1007/BF00401799&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR23" id="ref-link-section-d2615778e540">1990</a>), which is often defined as the ability to read aloud with accuracy, speed and proper expression (Kuhn et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Kuhn, M., Schwanenflugel, P., &amp; Meisinger, E. (2010). Aligning theory and assessment of reading fluency: automaticity, prosody, and definitions of fluency. Reading Research Quarterly, 45(2), 232253. &#xA;                https://doi.org/10.1598/RRQ.45.2.4&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR30" id="ref-link-section-d2615778e543">2010</a>; Pikulski &amp; Chard, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2005" title="Pikulski, J. J., &amp; Chard, D. J. (2005). Fluency: bridge between decoding comprehension. The Reading Teacher, 58(6), 510519. &#xA;                https://doi.org/10.1598/RT.58.6.2&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR44" id="ref-link-section-d2615778e547">2005</a>). Indeed, the importance of fluency to comprehension is so well-established that some interventions aimed at improving comprehension have focused on improving fluency instead (Mastropieri &amp; Scruggs, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Mastropieri, M. A., &amp; Scruggs, T. E. (1997). Best practices in promoting reading comprehension in students with learning disabilities 1976 to 1996. Remedial and Special Education, 18, 197213. &#xA;                https://doi.org/10.1177/074193259701800402&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR35" id="ref-link-section-d2615778e550">1997</a>; Reutzel &amp; Hollingsworth, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1993" title="Reutzel, D. R., &amp; Hollingsworth, P. M. (1993). Effects of fluency training on second graders reading comprehension. Journal of Educational Research, 86, 325331. &#xA;                https://doi.org/10.1080/00220671.1993.9941225&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR49" id="ref-link-section-d2615778e553">1993</a>). While it is not suggested that reading fluency interventions should substitute for specialized reading comprehension training, such implementations do demonstrate the relevance of fluency to comprehension.</p><p>To elaborate, research has increasingly linked comprehension to the automaticity and prosody of reading (Groen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Groen, M. A., Veenendaal, N. J., &amp; Verhoeven, L. (2018). The role of prosody in reading comprehension: evidence from poor comprehenders. Journal of Research in Reading, 42(1), 3757. &#xA;                https://doi.org/10.1111/1467-9817.12133&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR21" id="ref-link-section-d2615778e559">2018</a>; Kuhn et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Kuhn, M., Schwanenflugel, P., &amp; Meisinger, E. (2010). Aligning theory and assessment of reading fluency: automaticity, prosody, and definitions of fluency. Reading Research Quarterly, 45(2), 232253. &#xA;                https://doi.org/10.1598/RRQ.45.2.4&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR30" id="ref-link-section-d2615778e562">2010</a>). Here, automaticity reflects the ability to decode written text with sufficient accuracy and speed (e.g. Kim et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Kim, Y. S. G., Quinn, J. M., &amp; Petscher, Y. (2021). What is text reading fluency and is it a predictor or an outcome of reading comprehension? A longitudinal investigation. Developmental Psychology, 57(5), 718732. &#xA;                https://doi.org/10.1037/2Fdev0001167&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR29" id="ref-link-section-d2615778e565">2021</a>), which a reader attains through instruction and practice (Logan, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1988" title="Logan, G. D. (1988). Toward an instance theory of automatization. Psychological Review, 95(4), 492527. &#xA;                https://doi.org/10.1037/0033-295X.95.4.492&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR32" id="ref-link-section-d2615778e568">1988</a>). Automatic reading reduces the mental effort required to read, allowing the reader to focus on more cognitively demanding tasks, like comprehension (Aldhanhani &amp; Abu-Ayyash, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Aldhanhani, Z. R., &amp; Abu-Ayyash, E. A. (2020). Theories and research on oral readingfluency: What is needed? Theory and Practice in Language Studies, 10(4), 379388. &#xA;                https://doi.org/10.17507/tpls.1004.05&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR1" id="ref-link-section-d2615778e571">2020</a>; Morris &amp; Perney, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Morris, D., &amp; Perney, J. (2018). Using a sight word measure to predict reading fluency problems in grades 1 to 3. Reading &amp; Writing Quarterly, 34(4), 338348. &#xA;                https://doi.org/10.1080/10573569.2018.1446857&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR38" id="ref-link-section-d2615778e575">2018</a>). To elaborate, Perfettis (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Perfetti, C. (1985). Reading ability. New York: Oxford University Press" href="/article/10.1007/s40593-025-00480-y#ref-CR43" id="ref-link-section-d2615778e578">1985</a>) verbal efficiency theory states that lower complexity tasks must be mastered to some degree, before more complex tasks can occur during reading. Correspondingly, automaticity can be related to comprehension through proficiency in decoding, word identification and the retention of limited cognitive resources (Perfetti &amp; Stafura, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2014" title="Perfetti, C., &amp; Stafura, J. (2014). Word knowledge in a theory of reading comprehension. Scientific Studies of Reading, 18(1), 2237. &#xA;                https://doi.org/10.1080/10888438.2013.827687&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR42" id="ref-link-section-d2615778e581">2014</a>).</p><p>Meanwhile, prosody reflects expressive components of reading, such as phrasing, expression, intonation, stress and pitch (Miller &amp; Schwanenflugel, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Miller, J., &amp; Schwanenflugel, P. J. (2008). A longitudinal study of the development of reading prosody as a dimension of oral reading fluency in early elementary school children. Reading Research Quarterly, 43(4), 336354. &#xA;                https://doi.org/10.1598/RRQ.43.4.2&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR37" id="ref-link-section-d2615778e587">2008</a>; Share, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Share, D. L. (2008). On the Anglocentricities of current reading research and practice: the perils of overreliance on an&#34; outlier&#34; orthography. Psychological Bulletin, 134(4), 584615. &#xA;                https://doi.org/10.1037/0033-2909.134.4.584&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR53" id="ref-link-section-d2615778e590">2008</a>), which facilitate or enhance the retention of meaning (Kuhn et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Kuhn, M., Schwanenflugel, P., &amp; Meisinger, E. (2010). Aligning theory and assessment of reading fluency: automaticity, prosody, and definitions of fluency. Reading Research Quarterly, 45(2), 232253. &#xA;                https://doi.org/10.1598/RRQ.45.2.4&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR30" id="ref-link-section-d2615778e593">2010</a>; Miller &amp; Schwanenflugel, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Miller, J., &amp; Schwanenflugel, P. J. (2008). A longitudinal study of the development of reading prosody as a dimension of oral reading fluency in early elementary school children. Reading Research Quarterly, 43(4), 336354. &#xA;                https://doi.org/10.1598/RRQ.43.4.2&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR37" id="ref-link-section-d2615778e596">2008</a>; Silva et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Silva, W. A., Carchedi, L. C., Junior, J. G., de Souza, J. V., Barrere, E., &amp; de Souza, J. F. (2021). A framework for large-scale automatic fluency assessment. International Journal of Distance Education Technologies, 19(3), 7088. &#xA;                https://doi.org/10.4018/IJDET.2021070105&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR54" id="ref-link-section-d2615778e599">2021</a>). Prosody and comprehension have been shown to affect one another throughout most of primary education (Veenendaal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Veenendaal, N. J., Groen, M. A., &amp; Verhoeven, L. (2016). Bidirectional relations between text reading prosody and reading comprehension in the upper primary school grades: a longitudinal perspective. Scientific Studies of Reading., 20(3), 189202. &#xA;                https://doi.org/10.1080/10888438.2015.1128939&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR65" id="ref-link-section-d2615778e603">2016</a>), even when controlling for automaticity (Groen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Groen, M. A., Veenendaal, N. J., &amp; Verhoeven, L. (2018). The role of prosody in reading comprehension: evidence from poor comprehenders. Journal of Research in Reading, 42(1), 3757. &#xA;                https://doi.org/10.1111/1467-9817.12133&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR21" id="ref-link-section-d2615778e606">2018</a>; Veenendaal et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Veenendaal, N. J., Groen, M. A., &amp; Verhoeven, L. (2015). What speech text reading fluency can reveal about reading comprehension. Journal of Research in Reading, 38(3), 213225. &#xA;                https://doi.org/10.1111/1467-9817.12024&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR64" id="ref-link-section-d2615778e609">2015</a>). In short, the relationship between fluency and comprehension has been well-documented and involves automaticity and prosody.</p><p>In contrast, standardized oral reading fluency assessment tools, such as Dynamic Indicators of Basic Early Literacy Skills Oral Reading Fluency (DORF; University of Oregon, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="University of Oregon (2020). 8th Edition of Dynamic Indicators of Basic Early Literacy Skills (DIBELS): Administration and Scoring Guide. Eugene, OR: University of Oregon. &#xA;                https://dibels.uoregon.edu&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR58" id="ref-link-section-d2615778e615">2020</a>), and the Test of Word Reading Efficiency Sight Word Efficiency (TOWRE-SWE; Torgesen et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1997" title="Torgesen, J. K., Wagner, R., &amp; Rashotte, C. (1997). Test of word reading efficiency. Austin, TX: PRO-ED" href="/article/10.1007/s40593-025-00480-y#ref-CR56" id="ref-link-section-d2615778e618">1997</a>), assess fluency using the number of words read correctly per minute (WCPM). This metric only integrates measures of accuracy (words read correctly) and speed (per minute), thereby solely reflecting automaticity. Meanwhile, prosody is separately measured through subjective rating scales (Kuhn et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Kuhn, M., Schwanenflugel, P., &amp; Meisinger, E. (2010). Aligning theory and assessment of reading fluency: automaticity, prosody, and definitions of fluency. Reading Research Quarterly, 45(2), 232253. &#xA;                https://doi.org/10.1598/RRQ.45.2.4&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR30" id="ref-link-section-d2615778e621">2010</a>; Morrison &amp; Wilcox, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Morrison, T. G., &amp; Wilcox, B. (2020). Assessing expressive oral reading fluency. Education Sciences, 10(3), 59. &#xA;                https://doi.org/10.3390/educsci10030059&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR39" id="ref-link-section-d2615778e624">2020</a>), that require multiple trained raters to obtain reliable results.</p><p>In practice, the time-consuming nature of oral reading fluency assessment, the requirement for training, and the resulting testing burden, has led teachers and other practitioners to relinquish the assessment of prosody. In addition, practitioners stray from obtaining detailed automaticity diagnostics, as their extraction further increases assessment duration. This lack of complete and detailed diagnostics is problematic, as it complicates the implementation of individualized reading instruction, which has increasingly been identified as crucial for the optimal development of individual readers (Bray &amp; McClaskey, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Bray, B., &amp; McClaskey, K. (2015). Make learning personal. SAGE Publications Ltd., USA." href="/article/10.1007/s40593-025-00480-y#ref-CR9" id="ref-link-section-d2615778e631">2015</a>; Connor &amp; Morrison, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2016" title="Connor, C. M., &amp; Morrison, F. J. (2016). Individualizing student instruction in reading: implications for policy and practice. Policy Insights from the Behavioral and Brain Sciences, 3(1), 5461. &#xA;                https://doi.org/10.1177/2372732215624931&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR14" id="ref-link-section-d2615778e634">2016</a>).</p><p>To summarize, although fluency is a crucial prerequisite for developing reading comprehension skills, its assessment seldom supplies practitioners with detailed diagnostics, and bestows a heavy testing burden upon them. Therefore, an assessment instrument that provides detailed individualized diagnostics, and that reduces the testing burden placed on practitioners, could improve the development of reading fluency and comprehension alike. To fulfill this ambition, a recent review on oral reading fluency assessment has suggested the use of artificial intelligence-based speech technology (van der Velde et al.,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024a" title="van der Velde, M. E., Molenaar, B., Veldkamp, B. P., Feskens, R. C. W., &amp; Keuning, J. (2024a). What do they say? Assessment of oral reading fluency in early primary school children: A scoping review.International Journal of Educational Research, 128, 102444. &#xA;                https://doi.org/10.1016/j.ijer.2024.102444&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR59" id="ref-link-section-d2615778e640">2024a</a>), an approach that has served a multitude of scientific fields.</p><p>Over the last two decades, major advances have been made regarding the availability and complexity of artificial intelligence-based technology, increasing their applicability and relevance for assessment (Clarke-Midura &amp; Dede, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Clarke-Midura, J., &amp; Dede, C. (2010). Assessment, technology, and change. Journal of Research on Technology in Education, 42(3), 309328. &#xA;                https://doi.org/10.1080/15391523.2010.10782553&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR13" id="ref-link-section-d2615778e646">2010</a>). For example, developments in text processing have allowed for the automatic evaluation of theoretical papers (Rokade, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Rokade, A. A. (2018).Automated Grading System Using Natural Language Processing.International Conference on Inventive Communication and Computational Technologies 2018: Coimbatore, India. &#xA;                https://doi.org/10.1109/ICICCT.2018.8473170&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR50" id="ref-link-section-d2615778e649">2018</a>). Likewise, the development of automatic speech recognition (ASR), which concerns the independent, machine-based process of decoding and transcribing oral speech (Levis &amp; Suvorov, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2012" title="Levis, J., &amp; Suvorov, R. (2012). Automatic speech recognition. InThe encyclopedia of applied linguistics.Chapelle, C. A. (2012). Hoboken : John Wiley &amp; Sons" href="/article/10.1007/s40593-025-00480-y#ref-CR31" id="ref-link-section-d2615778e652">2012</a>, p. 1), has made audio data a valuable source of information.</p><p>With regard to reading fluency, the effectiveness of ASR has been demonstrated in early work by Mostow et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., &amp; Tobin, B. (2003). Evaluation of an automated reading tutor that listens: comparison to human tutoring and classroom instruction. Journal of Educational Computing Research, 29, 61117. &#xA;                https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR40" id="ref-link-section-d2615778e658">2003</a>) and Reeder et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="Reeder, K., Shapiro, J., &amp; Wakefield, J. (2007). The effectiveness of speech recognition technology in promoting reading proficiency and attitudes for Canadian immigrant children. Proceedings of the 9th European Conference on Reading" href="/article/10.1007/s40593-025-00480-y#ref-CR48" id="ref-link-section-d2615778e661">2007</a>), while the current relevance of ASR is reflected through its central role within recent reading fluency assessment frameworks (Silva et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Silva, W. A., Carchedi, L. C., Junior, J. G., de Souza, J. V., Barrere, E., &amp; de Souza, J. F. (2021). A framework for large-scale automatic fluency assessment. International Journal of Distance Education Technologies, 19(3), 7088. &#xA;                https://doi.org/10.4018/IJDET.2021070105&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR54" id="ref-link-section-d2615778e664">2021</a>). Correspondingly, much work has been conducted to automate fluency assessment through ASR, especially for English readers (Cheng &amp; Shen, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Cheng, J., &amp; Shen, J. (2010). Towards accurate recognition for children's oral reading fluency. IEEE Spoken Language Technology Workshop: Berkeley, USA. &#xA;                https://doi.org/10.1109/SLT.2010.5700830&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR10" id="ref-link-section-d2615778e667">2010</a>; Loukina et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2019" title="Loukina, A., Klebanov, B. B., Lange, P. L., Qian, Y., Gyawali, B., Madnani, N., Misra, A., Zechner, K., Wang, Z., &amp; Sabatini, J. (2019). Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead. INTERSPEECH 2019: Graz, Austria. &#xA;                https://www.iscaarchive.org/interspeech_2019/loukina19_interspeech.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR33" id="ref-link-section-d2615778e670">2019</a>; Sabu &amp; Rao, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Sabu, K., &amp; Rao, P. (2018). Automatic assessment of childrens oral reading using speech recognition and prosody modeling. CSI Transactions on ICT, 6, 221225. &#xA;                https://doi.org/10.1007/s40012-018-0202-3&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR51" id="ref-link-section-d2615778e674">2018</a>). This, in turn, has led to the creation of automatic reading fluency tools such as the Fluent Oral Reading Assessment (FLORA; Bolaos et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Bolaos, D., Cole, R. A., Ward, W. H., Tindal, G. A., Hasbrouck, J., &amp; Schwanenflugel, P. J. (2013). Human and automated assessment of oral reading fluency. Journal of Educational Psychology, 105(4), 11421151. &#xA;                https://doi.org/10.1037/a0031479&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR7" id="ref-link-section-d2615778e677">2013</a>), and Moby.Read (Cheng, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Cheng, J. (2018). Real-time scoring of an oral reading assessment on mobile devices. INTERSPEECH 2018: Hyderabad. &#xA;                https://doi.org/10.21437/Interspeech.2018-34&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR11" id="ref-link-section-d2615778e680">2018</a>).</p><p>Even though the body of literature that implements ASR within the English language is substantial, this does not necessarily indicate that these results are generalizable to all languages. Namely, although most literary research focusses on English, English has long been established as an outlier orthography (Share, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Share, D. L. (2008). On the Anglocentricities of current reading research and practice: the perils of overreliance on an&#34; outlier&#34; orthography. Psychological Bulletin, 134(4), 584615. &#xA;                https://doi.org/10.1037/0033-2909.134.4.584&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR53" id="ref-link-section-d2615778e686">2008</a>). Specifically, English has relatively high irregularity, or low transparency, with regard to grapheme-phoneme correspondences when compared to other languages. As previous research has illustrated, the transparency of a language impacts the way in which children process, learn, and attempt to express a language (Smith et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Smith, A. C., Monaghan, P., &amp; Huettig, F. (2021). The effect of orthographic systems on the developing reading system: typological and computational analyses. Psychological Review, 128(1), 125159. &#xA;                https://doi.org/10.1037/rev0000257&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR55" id="ref-link-section-d2615778e689">2021</a>; Wimmer &amp; Goswami, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1994" title="Wimmer, H., &amp; Goswami, U. (1994). The influence of orthographic consistency on reading development: word recognition in English and German children. Cognition, 51, 91103. &#xA;                https://doi.org/10.1016/0010-0277(94)90010-8&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR68" id="ref-link-section-d2615778e692">1994</a>). For example, children learning less transparent orthographies favor the direct recognition of words or letter-strings over converting graphemes into phonemes.</p><p>Throughout the last decade, attempts have been made to implement ASR within non-English languages. For example, Proena et al., (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2015" title="Proena, J., Celorico, D., Candeias, S., Lopes, C., &amp; Perdigo, F. (2015). Children's Reading Aloud Performance: A Database and Automatic Detection of Disfluencies. INTERSPEECH 2015: Dresden, Germany. &#xA;                https://doi.org/10.21437/Interspeech.2015-382&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR47" id="ref-link-section-d2615778e698">2015</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2017" title="Proena, J., Lopes, C., Tjalve, M., Stolcke, A., Candeias, S., &amp; Perdigo, F. (2017). Automatic evaluation of reading aloud performance in children. Speech Communication, 94, 114. &#xA;                https://doi.org/10.1016/j.specom.2017.08.006&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR46" id="ref-link-section-d2615778e701">2017</a>) automatically evaluated disfluencies in the speech of Portuguese children. Another example concerns the Dutch language, where crucial steps have been made regarding the automation of assessment of first graders (Bai et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2020" title="Bai, Y., Hubers, F. C. W., Cucchiarini, C., &amp; Strik, H. (2020). ASR-Based Evaluation and Feedback for Individualized Reading Practice. INTERSPEECH 2020: Shanghai, China. &#xA;                https://www.isca-archive.org/interspeech_2020/bai20b_interspeech.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR2" id="ref-link-section-d2615778e704">2020</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Bai, Y., Hubers, F. C. W., Cucchiarini, C., &amp; Strik, H. (2021). An ASR-based Reading Tutor for Practicing Reading Skills in the First Grade: Improving Performance through Threshold Adjustment. IberSPEECH 2021: Valladolid, Spain. &#xA;                https://repository.ubn.ru.nl/bitstream/handle/2066/245151/245151.pdf&#xA;                &#xA;              ." href="/article/10.1007/s40593-025-00480-y#ref-CR3" id="ref-link-section-d2615778e707">2021</a>), and secondary language learners (Cucchiarini et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Cucchiarini, C., Neri, A., &amp; Strik, H. (2009). Oral proficiency training in Dutch L2: the contribution of ASR-based corrective feedback. Speech Communication, 51(10), 853863. &#xA;                https://doi.org/10.1016/j.specom.2009.03.003&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR15" id="ref-link-section-d2615778e710">2009</a>; Wei et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2022" title="Wei, X., Cucchiarini, C., van Hout, R. W. N. M., &amp; Strik, H. (2022). Automatic speech recognition and pronunciation error detection of Dutch non-native speech: cumulating speech resources in a pluricentric language. Speech Communication, 144, 19. &#xA;                https://doi.org/10.1016/j.specom.2022.08.004&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR67" id="ref-link-section-d2615778e714">2022</a>). However, less attention has been placed on children attending Grades 2 and 3, even though these prominently featured in the reading fluency assessment literature (van der Velde et al.,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024a" title="van der Velde, M. E., Molenaar, B., Veldkamp, B. P., Feskens, R. C. W., &amp; Keuning, J. (2024a). What do they say? Assessment of oral reading fluency in early primary school children: A scoping review.International Journal of Educational Research, 128, 102444. &#xA;                https://doi.org/10.1016/j.ijer.2024.102444&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR59" id="ref-link-section-d2615778e717">2024a</a>). In addition, current ASR implementations primarily focus on accuracy, ignoring speed and prosody.</p><p>To overcome current assessment shortcomings, and to investigate the full potential of ASR based fluency assessment, an assessment instrument that utilizes automatic speech recognition to provide detailed diagnostic information on all fluency components has been developed (van der Velde et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024b" title="Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ranelovi B., Karali E., Aleksi K., uki D. (Eds.), E-testing and computer-based assessment. CIDREE Yearbook 2024 (pp. 99123). CIDREE. &#xA;                https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR60" id="ref-link-section-d2615778e724">2024b</a>).</p><h3 class="c-article__sub-heading" id="Sec2">SERDA: Automatic Oral Reading Fluency Assessment for Dutch</h3><p>The Speech Enabled Reading Diagnostics App (SERDA) is a Dutch oral reading fluency assessment instrument, developed to improve reading education at the primary school level (van der Velde et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024b" title="Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ranelovi B., Karali E., Aleksi K., uki D. (Eds.), E-testing and computer-based assessment. CIDREE Yearbook 2024 (pp. 99123). CIDREE. &#xA;                https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR60" id="ref-link-section-d2615778e734">2024b</a>). Through the incorporation of speech recognition, speech-based diagnostics, and their conversion into didactic suggestions for practitioners, SERDA allows for the provision of individualized feedback on childrens oral word and passage reading performance, as well as detailed information on all fluency components. All the while, SERDAs short administration duration and automatic scoring should reduce the testing burden placed on teachers and other practitioners.</p><p>Although these findings are promising, the ASR-based accuracy, speed, automaticity and prosody metrics of any automatic fluency instrument should be thoroughly validated before statements can be made about their usability in practice. Given that reading fluency is currently assessed through the speed, accuracy and automaticity of reading in practice, we argue that it should first be proven that ASR-based metrics can validly substitute for their pen-and-paper contemporaries, before prosody is considered. Therefore, the current study will focus on validating SERDAs word decoding and passage reading tasks, excluding prosodic metrics, to determine whether an ASR-based reading fluency assessment instrument can provide valid word decoding and passage reading metrics.</p><h3 class="c-article__sub-heading" id="Sec3">Validating ASR-Based Decoding Scores</h3><p>To substitute for current instruments, an ASR-based decoding instrument should provide observable and reliable scores based on childrens oral reading performance. Moreover, the ASR-based scores, obtained over a limited sample of reading items and primary school children, should be generalizable to all potential samples of reading items and primary school children. Furthermore, the scores should be proven to reflect oral reading skills, allowing for claims to be made regarding childrens oral reading performance. Finally, the reading tasks should provide scores that allow practitioners to differentiate between good, average and less proficient oral readers, such that decisions with regard to development and proficiency can be made.</p><p>In order to evaluate whether these requirements are met, we will apply the Argument-Based Approach to validation (ABP; Kane, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Kane, M. T. (1992). An argument-based approach to validity. Psychological Bulletin, 112, 527535. &#xA;                https://doi.org/10.1037/0033-2909.112.3.527&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR25" id="ref-link-section-d2615778e751">1992</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kane, M. T. (2006). Validation. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 1764). Washington: American Council on Education/Praeger" href="/article/10.1007/s40593-025-00480-y#ref-CR27" id="ref-link-section-d2615778e754">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Kane, M. T. (2013). Validating the interpretations and uses of test scores. Journal of Educational Measurement, 50, 173. &#xA;                https://doi.org/10.1111/jedm.12000&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR26" id="ref-link-section-d2615778e757">2013</a>). Within the ABP, an Interpretation and Use Argument (IUA) is specified, which describes the inferences and assumptions underlying the proposed interpretation of assessment results. Then, a validity argument is defined, describing the process of evaluating the components of the IUA through gathered evidence. Lastly, the validation as a whole is evaluated. Specifically, it is evaluated whether the correct assumptions and inferences are addressed, whether the inferences can be justified, and whether the validity argument, as a whole, is plausible.</p><h3 class="c-article__sub-heading" id="Sec4">The Present Study</h3><p>The present study aims to evaluate whether it is possible to generate valid word decoding and passage reading measures for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument.</p><p>Based on the ABP framework, the main question answered with this study is:</p><ul class="u-list-style-dash">
                <li>
                  <p>Can an oral reading fluency assessment instrument that utilizes automatic speech recognition provide valid word decoding and passage reading scores?</p>
                </li>
              </ul><p>In order to answer this question, we will answer the following sub-questions:</p><ol class="u-list-style-none">
                <li>
                  <span class="u-custom-list-number">1.</span>
                  
                    <p>Can performances on the reading tasks be translated into observable and reliable ASR-based scores?</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">2.</span>
                  
                    <p>Is the sample of reading tasks and primary schools representative of the population of reading tasks and primary schools?</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">3.</span>
                  
                    <p>Do the ASR-based scores reflect oral reading skills, allowing for claims to be made regarding childrens oral reading performance?</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">4.</span>
                  
                    <p>Can the ASR-based oral reading scores differentiate between good, average and less proficient oral readers, such that they can be used to make decisions regarding their proficiency and development?</p>
                  
                </li>
              </ol></div></div></section><section data-title="Methods"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">Methods</h2><div class="c-article-section__content" id="Sec5-content"><p>To determine whether an ASR-based oral reading fluency assessment instrument could provide valid word decoding and passage reading scores, we administered SERDAs word- and passage reading tasks (van der Velde et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024b" title="Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ranelovi B., Karali E., Aleksi K., uki D. (Eds.), E-testing and computer-based assessment. CIDREE Yearbook 2024 (pp. 99123). CIDREE. &#xA;                https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR60" id="ref-link-section-d2615778e839">2024b</a>), as well as the most popular instruments to monitor oral word and passage reading skills in the Netherlands: the Three Minute Task [<i>Drie-minuten-toets</i>; DMT] (van Til et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018a" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., Vloedgraven, J. &amp; De Wijs, A. (2018a). Wetenschappelijke verantwoording DMT [Scientific Justification DMT]. Cito: Arnhem" href="/article/10.1007/s40593-025-00480-y#ref-CR61" id="ref-link-section-d2615778e845">2018a</a>) and AVI [<i>Analyse van Individualiseringsvormen</i>; AVI] (van Til et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018b" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., &amp; De Wijs, A. (2018b). Wetenschappelijke verantwoording AVI [Scientific Justification AVI]. Cito: Arnhem." href="/article/10.1007/s40593-025-00480-y#ref-CR62" id="ref-link-section-d2615778e851">2018b</a>).</p><h3 class="c-article__sub-heading" id="Sec6">Participants</h3><p>One hundred seventy-six h of speech data were obtained, as well as the results of 569 DMT and 622 AVI administrations, from 653 (52% girls) children attending the second and third grade of Dutch primary education. Children attended 19 different primary schools, selected to represent dialect regions (Cucchiarini et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2008" title="Cucchiarini, C., van Hamme, H., Driesen, J., Sanders, E. (2008). THE JASMIN-CGN: CORPUS Design, recording, transcription and structure of the corpus" href="/article/10.1007/s40593-025-00480-y#ref-CR16" id="ref-link-section-d2615778e861">2008</a>) and school-weights, an indicator of expected school performance and social economic status of childrens parents (Inspectorate of Education, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024" title="Inspectorate of Education. (2024). Schoolweging primair onderwijs [Schoolweightprimary education]. &#xA;                https://www.onderwijsinspectie.nl/trends-en-ontwikkelingen/onderwijsdata/schoolweging-po&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR24" id="ref-link-section-d2615778e864">2024</a>). The average age of the children was seven and a half (<i>SD</i>=<i>0.74)</i>, with children attending Grade 2 being one year younger, on average, than children attending Grade 3.</p><h3 class="c-article__sub-heading" id="Sec7">Materials</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec8">SERDA: Word and Passage Decoding</h4><p>SERDAs word and passage reading tasks were individually administered on a tablet, during which childrens speech was recorded through a microphone. The word decoding task contained 150 words, chosen based on the DMT (van Til et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018a" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., Vloedgraven, J. &amp; De Wijs, A. (2018a). Wetenschappelijke verantwoording DMT [Scientific Justification DMT]. Cito: Arnhem" href="/article/10.1007/s40593-025-00480-y#ref-CR61" id="ref-link-section-d2615778e885">2018a</a>) and expert opinion. Words were divided over three 50-word subtasks, which varied with regard to the number of syllables per word and the complexity of reading difficulties. The presentation of words followed a progressive demasking design (Grainger &amp; Segui, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1990" title="Grainger, J., &amp; Segui, J. (1990). Neighborhood frequency effects in visual word recognition: a comparison of lexical decision and masked identification latencies. Perception &amp; Psychophysics, 47, 191198. &#xA;                https://doi.org/10.3758/BF03205983&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR20" id="ref-link-section-d2615778e888">1990</a>) to allow for accurate reading speed estimation. During the progressive demasking task, a mask was placed over the words at an increasing interval, such that the to be read word became visible for longer over time, until the participant indicated that they were able to recognize the word. Before administration, children were instructed to tap the screen as quickly as possible once the presented word was recognized, after which they read the word out loud as accurately as possible.</p><p>The passage reading task contained three passages of about 175 words, which were constructed using the guidelines of the AVI (van Til et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018b" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., &amp; De Wijs, A. (2018b). Wetenschappelijke verantwoording AVI [Scientific Justification AVI]. Cito: Arnhem." href="/article/10.1007/s40593-025-00480-y#ref-CR62" id="ref-link-section-d2615778e894">2018b</a>). The passages were written by childrens authors, discussed topics of interest to children, and contained multi-syllable words with reading complexities that corresponded to those, respectively, expected at the end of second grade, the middle of third grade and the end of the third grade. Children were instructed to read the passages as quickly and accurately as possible, including the title. The task was finalized once the entire passage was read, or after 3min had passed.</p><p>Each word and passage reading subtask yielded audio- and log files, based on which item-, subtask- and person-level measures were extracted. An overview of the extracted measures can be found in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s40593-025-00480-y#Tab1">1</a>. To extract these measures, the same methodology was adopted as described in van der Velde et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024b" title="Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ranelovi B., Karali E., Aleksi K., uki D. (Eds.), E-testing and computer-based assessment. CIDREE Yearbook 2024 (pp. 99123). CIDREE. &#xA;                https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR60" id="ref-link-section-d2615778e903">2024b</a>), using an updated version of the ASR model. In addition, we utilized Item Response Theory (Hambleton &amp; Swaminathan, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1985" title="Hambleton, R. K., &amp; Swaminathan, H. (1985). Item response theory: Principles and applications. Springer. &#xA;                https://link.springer.com/book/10.1007/978-94-017-1988-9&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR22" id="ref-link-section-d2615778e906">1985</a>) to extract item- and person parameters. Specifically, we applied the Hierarchical Bayesian joint modeling approach (van der Linden, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2007" title="van der Linden, W. J. (2007). A hierarchical framework for modeling speed and accuracy on test items. Psychometrika, 72, 287308. &#xA;                https://doi.org/10.1007/s11336-006-1478-z&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR63" id="ref-link-section-d2615778e909">2007</a>), which allows for the joint modelling of accuracy and speed scores, integrating both accuracy and speed information during the estimation of childrens oral reading skills. Here, we used the LNIRT (Fox et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Fox, J. P., Klotzke, K., &amp; Simsek, A. S. (2021). LNIRT: An R package for joint modeling of response accuracy and times.arXiv preprint &#xA;                arXiv:2106.10144&#xA;                &#xA;              . &#xA;                https://arxiv.org/abs/2106.10144&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR18" id="ref-link-section-d2615778e912">2021</a>) R-package to obtain item difficulty and discrimination parameters for all items. Finally, we calculated LNIRT word decoding and passage reading ability and speed estimates for each person, using their item-level accuracy and speed scores.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Item, Subtask and Person Level Measures Extracted by SERDA</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s40593-025-00480-y/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Before model specification, words or items with little to no variability and persons with extremely unlikely scores or mostly missing data were removed. For the word decoding task, we retained observations of 633 children for 149 items. For the passage reading task, we retained observations of 631 children for 526 items.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec9">Word Decoding: Three Minute Task [Drie-minuten-toets; DMT]</h4><p>The DMT is an on-paper examination, aimed at monitoring the development of word decoding skills of children during Grades 1 to 6 of primary education (van Til et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018a" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., Vloedgraven, J. &amp; De Wijs, A. (2018a). Wetenschappelijke verantwoording DMT [Scientific Justification DMT]. Cito: Arnhem" href="/article/10.1007/s40593-025-00480-y#ref-CR61" id="ref-link-section-d2615778e1181">2018a</a>). DMT administrations were individually conducted and scored by teachers of the schools the children attended. Children read up to three word lists of increasing difficulty, as quickly and accurately as possible, for a duration of one minute per list. Then, based on their performance compared to grade-specific norms for the population of primary schoolers, children were classified into one of five categories, ranging from the 20% best to least developed readers. As these categories were provided by school after specification, no reliability or validity information was collected. However, the reliability and validity of the DMT has previously been thoroughly investigated (Van Til., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018a" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., Vloedgraven, J. &amp; De Wijs, A. (2018a). Wetenschappelijke verantwoording DMT [Scientific Justification DMT]. Cito: Arnhem" href="/article/10.1007/s40593-025-00480-y#ref-CR61" id="ref-link-section-d2615778e1184">2018a</a>).</p><p>Based on the DMT classifications, we specified three proficiency classes. To elaborate, children in the 20% least developed DMT group were classified as Less Proficient, while children classified into the top 20% were classified as Highly Proficient. Children classified into the middle 60% of readers were classified as Averagely Proficient.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec10">Passage Reading: AVI [Analyse van Individualiseringsvormen; AVI]</h4><p>The AVI is an on-paper examination, aimed at monitoring the development of passage reading skills of children during Grades 1 to 6 of primary education (van Til et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018b" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., &amp; De Wijs, A. (2018b). Wetenschappelijke verantwoording AVI [Scientific Justification AVI]. Cito: Arnhem." href="/article/10.1007/s40593-025-00480-y#ref-CR62" id="ref-link-section-d2615778e1198">2018b</a>). AVI administrations were individually conducted and scored by teachers at the schools the children attended. During the AVI, children read Grade-level passages of increasing difficulty. The reading of passages continued until the child was unable to meet national norms, either by making too many mistakes, by not reading quickly enough, or by a combination of these factors. Then, based on the highest Grade-level passage read successfully, an AVI classification was provided. Specifically, the AVI categorizes children into one of twelve levels, ranging from the start to the end of primary education, providing an indication of the childs progress throughout primary education. As these categories were provided by the school after specification, no reliability or validity information was collected. However, the reliability and validity of the AVI has previously been thoroughly investigated (Van Til., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018b" title="Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., &amp; De Wijs, A. (2018b). Wetenschappelijke verantwoording AVI [Scientific Justification AVI]. Cito: Arnhem." href="/article/10.1007/s40593-025-00480-y#ref-CR62" id="ref-link-section-d2615778e1201">2018b</a>).</p><p>Based on the AVI classification, we specified three proficiency classes. Specifically, children who obtained an AVI categorization below the level of second grade were classified as Less proficient, while children with an AVI class at the level of the second or third grade were classified as Averagely Proficient. Children with an AVI classification above the third grade were classified as Highly Proficient.</p><h3 class="c-article__sub-heading" id="Sec11">Argument-based Validation</h3><p>The validation was implemented through the extended ABP (Kane, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Kane, M. T. (1992). An argument-based approach to validity. Psychological Bulletin, 112, 527535. &#xA;                https://doi.org/10.1037/0033-2909.112.3.527&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR25" id="ref-link-section-d2615778e1216">1992</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kane, M. T. (2006). Validation. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 1764). Washington: American Council on Education/Praeger" href="/article/10.1007/s40593-025-00480-y#ref-CR27" id="ref-link-section-d2615778e1219">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Kane, M. T. (2013). Validating the interpretations and uses of test scores. Journal of Educational Measurement, 50, 173. &#xA;                https://doi.org/10.1111/jedm.12000&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR26" id="ref-link-section-d2615778e1222">2013</a>; Wools et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wools, S., Eggen, T. J. H. M., &amp; Sanders, P. F. (2010). Evaluation of validity and validation by means of the argument-based approach. Cadmo, 18(1), 6382. &#xA;                https://doi.org/10.3280/CAD2010-001007&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR69" id="ref-link-section-d2615778e1225">2010</a>). First, we specified the explicit inferences made about the decoding scores, by means of an IUA. Then, we described the validity arguments for each step of the IUA. Correspondingly, we specified the analyses conducted and evidence gathered for each validity argument. Finally, we evaluated the validity in its entirety, including the validation procedure.</p><p>Making the proposed interpretations and uses of test scores explicit was done through the specification of claims. For example, it could be claimed that the performance on a test provides a score that is observable. To evaluate this claim, warrants, rebuttals and backings were specified, which respectively concern statements that allow for the acceptance of the claim, evidence that refutes the claim or warrant, and evidence that supports the claim or warrant (Toulmin,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Toulmin, S. E. (2003). The uses of argument. Cambridge University Press. &#xA;                https://doi.org/10.1017/CBO9780511840005&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR57" id="ref-link-section-d2615778e1231">2003</a>). It follows that the presentation of sufficient and qualitatively sound backings and warrants, alongside the justified rejection of rebuttals, leads to the acceptance of a claim.</p><p>The IUA for the current study is presented in Fig.<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s40593-025-00480-y#Fig1">1</a>. Additionally, a detailed overview of the proposed inferences, assumptions, and sources of evidence is provided in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s40593-025-00480-y#Tab2">2</a>. Correspondingly, the exact claims, warrants, rebuttals and backings for each inference are shown in Appendix A.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="176"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Interpretation and Use Argument (IUA) for the Validation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Inferences, Assumptions, and Sources of Evidence Used to Validate the Reading Tasks</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s40593-025-00480-y/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec12">Data Analysis</h3><p>The analyses conducted throughout the present study were used to evaluate the validity arguments underlying the proposed inferences. All statistical analyses were conducted using RStudio (version 4.3.1; Posit Team, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Posit team (2023). RStudio: Integrated Development Environment for R, version 4.3.1. [Computer software] Posit Software, PBC, Boston, MA. &#xA;                http://www.posit.co/&#xA;                &#xA;              ." href="/article/10.1007/s40593-025-00480-y#ref-CR45" id="ref-link-section-d2615778e1406">2023</a>).</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec13">Scoring Inference</h4><p>To evaluate whether childrens performances on the reading tasks could be translated into observable and interpretable scores, we validated the ASR scoring-algorithm by comparing its item-level accuracy and speed scores to human annotations. In addition, we evaluated the reliability of the accuracy and speed scores.</p><p>To evaluate the validity of the item-level ASR-based accuracy and speed scores, we compared them with manual annotations. For the word decoding task, we only validated the accuracy scores, as the speed scores concerned logged data. Specifically, we obtained human annotations for 333 word decoding subtasks. These annotations were made by test leaders during task administration, using SERDAs build-in test-leader app. Test leaders could label words as read incorrectly, while leaving them unlabelled marked them as read correctly.</p><p>For the passage reading task, test leaders reported that children read too fast to accurately annotate. Therefore, we obtained orthographic transcriptions of 18 subtasks, made by two Linguistics graduates. Transcribers respectively transcribed 12 and 9 subtasks, three of which were transcribed by both, in two tiers, using PRAAT (Boersma &amp; Weenink, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024" title="Boersma, P., &amp; Weenink, D. (2024). Praat: doing phonetics by computer [Computer program]. Version 6.4.13, retrieved 10 June 2024 from &#xA;                http://www.praat.org/&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR6" id="ref-link-section-d2615778e1422">2024</a>). The first tier contains the prompts presented to the speaker. Each prompt is a word from the passage reading task, transcribed in an interval that contains all attempts a speaker made to read the prompt. The second tier contains the orthographic transcription of the audio, where each attempt to read a word was transcribed in a separate interval. If the last attempt in tier 2 was equal to the prompt word in tier 1, the prompt was labelled as read correctly. Meanwhile, the item-level speed scores were defined as the duration of the final reading attempt for a prompt.</p><p>Consistent with earlier studies on automatic accuracy assessment (Kheir et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Kheir, Y. E., Ali, A., &amp; Chowdhury, S. A. (2023). Automatic Pronunciation Assessment--A Review. arXiv preprint &#xA;                arXiv:2310.13974&#xA;                &#xA;              . &#xA;                https://doi.org/10.48550/arXiv.2310.13974&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR28" id="ref-link-section-d2615778e1428">2023</a>), accuracy measures were encoded in terms of reading errors. Thus, correctly read words were labeled as False (i.e., word reading does not contain an error) and incorrectly read words as True (i.e., word reading does contain an error). Subsequently, we compared the ASR-based accuracy scores of both tasks to human annotations, using Matthews Correlation Coefficient (MCC). MCC yields a score between 1 and 1, where a score of 0 indicates that the correspondence is no better than chance. The MCC was chosen since our dataset is unbalanced, containing more correctly- than incorrectly read words, making the MCC a trustworthy and complete performance indication (Chicco et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2021" title="Chicco, D., Warrens, M. J., &amp; Jurman, G. (2021). The Matthews correlation coefficient (MCC) is more informative than Cohens Kappa and Brier score in binary classification assessment. Ieee Access, 9, 7836878381. &#xA;                https://doi.org/10.1109/ACCESS.2021.3084050&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR12" id="ref-link-section-d2615778e1431">2021</a>). In addition, to enable a more thorough interpretation of these results, we computed the sensitivity (i.e., the proportion of decoding errors that are predicted to be incorrect), specificity (i.e. the proportion of actually correct readings that are predicted to be correct), and precision (i.e., the proportion of predicted incorrect readings that are actually incorrect).</p><p>Finally, to evaluate the passage reading speed scores, we computed correlations between human and ASR-based item-level speed scores. These are the correlations between the speed scores of transcriber 1 and the ASR, the speed scores of transcriber 2 and the ASR, and the speed scores of both raters and the ASR. However, the ASR is currently only able to produce speed scores for correctly read words. To elaborate, due to the large variation in possible reading errors that a child can make (e.g. repetitions at sub-word, word, phrase level or insertions of words that are not in the prompt), defining the desired output is very difficult. As a result, we only included speed scores for words that were read correctly.</p><p>To estimate the reliability of the ASR-based accuracy and speed scores we calculated Cronbachs Alpha, Goodmans Lambda 2 and the Greatest Lower Bound for the accuracy and speed measures of the word and passage reading tasks. In addition, we investigated the posterior standard deviations for childrens LNIRT ability and speed estimates. However, as the LNIRT models assumption of log-normal residuals was violated for most items, we replicated the generation of person- and item parameter estimates using a different IRT model, which only incorporates the item-level accuracy scores. The results, which can be found in Supplementary Appendix A, provided no indication that the violation of the log-normal residuals assumption substantially affected the results.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec14">Generalization Inference</h4><p>We assume that the sample of oral reading items can be used to make inferences about all samples of items if they reflect Dutch learning goals and methods for early primary education, if they match the difficulty level expected of oral reading tasks in Grades 2 and 3, and if the sample of primary schools represents the population.</p><p>To determine whether the reading tasks reflect Dutch learning goals and methods, the main argumentation of current guidelines was compared to the content of the reading tasks. The difficulty of the oral reading items was investigated by evaluating the distribution of the LNIRT item difficulty parameters and ability estimates. Finally, we evaluated the representativeness of the sample of primary schools by comparing the distribution of dialect region and school-weight to those found in the population.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec15">Extrapolation Inference</h4><p>The oral reading scores are assumed to provide information about oral reading performance if they measure the same underlying construct as their pen-and-paper predecessors, and if they provide information on oral reading accuracy, speed and automaticity.</p><p>To investigate whether the reading tasks measure the same construct as the DMT and AVI, we calculated correlations between the LNIRT ability and speed metrics, the person-level WCPM-scores, and the classifications of the DMT and AVI. The reading tasks authenticity was determined by discussing whether they reflect all relevant aspects of oral reading.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec16">Decision Making Inference</h4><p>It is assumed that childrens oral reading scores can be used to guide decisions regarding their performance if the reading tasks contain items that can discriminate between good and less proficient oral readers, and if misclassifications into highly, averagely and less proficient readers are minimized.</p><p>The discriminative ability of the reading tasks was determined by evaluating the LNIRT item discrimination parameters. To investigate the minimization of misclassification, we predicted the DMT and AVI proficiency classes through ordinal regression. Models included the LNIRT ability and speed estimates and the person-level WCPM scores of the word decoding and passage reading task. We also included childrens Grade, as the DMT and AVI are normed based on grade. Model performance was evaluated by calculating the weighted kappa with quadratic weights, and the average F1-score over all proficiency classes.</p></div></div></section><section data-title="Results"><div class="c-article-section" id="Sec17-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec17">Results</h2><div class="c-article-section__content" id="Sec17-content"><h3 class="c-article__sub-heading" id="Sec18">Scoring Inference</h3><p>To validate the ASR-based item level accuracy scores, we compared them to accuracy scores from human raters, using the MCC, sensitivity, specificity and precision. The results are presented in Table<a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s40593-025-00480-y#Tab3">3</a>.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Evaluation Metrics for the ASR-Based Item-level Accuracy Scores</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s40593-025-00480-y/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>We found moderate agreement between human and automatic accuracy measures for the word decoding (MCC =0.43) and passage (MCC =0.55) reading task, and for the inter-rater agreement of the passage reading accuracy scores (MCC =0.59). Additionally, the word (sensitivity =0.93, specificity =0.69) and passage (sensitivity =0.76, specificity =0.86) reading tasks showed moderate to high sensitivity and specificity. However, the word decoding task showed low precision (0.31), while the passage reading task showed moderate precision (0.54).</p><p>Then, we compared the ASR-based item-level speed scores of the passage reading task to their human equivalents. We found moderate to strong correlations between the ASR and transcriber 1 (<i>r</i>= 0.61), transcriber 2 (<i>r</i>= 0.57) and both transcribers (<i>r</i>= 0.59).</p><p>The reliability of the accuracy and speed scores was evaluated using Cronbachs Alpha, Goodmans Lambda 2 and the Greatest Lower Bound, and by evaluating the posterior standard deviation estimates from the LNIRT model for all LNIRT ability and speed estimates. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s40593-025-00480-y#Tab4">4</a> presents Cronbachs Alpha, Goodmans Lambda 2 and the Greatest Lower Bound for the word decoding and passage reading task. Reliability estimates ranged from 0.96 to 1, indicating that both tasks show excellent reliability.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 Cronbachs Alpha, Goodmans Lambda 2 and the Greatest Lower Bound for the Accuracy and Speed Measures of the Word Decoding and Passage Reading Tasks</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s40593-025-00480-y/tables/4" aria-label="Full size table 4"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Figure<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s40593-025-00480-y#Fig2">2</a> shows the posterior standard deviation estimates for the LNIRT ability and speed estimates. Posterior standard deviations were relatively low, especially for the LNIRT speed estimates. Higher uncertainty was observed for relatively low and high ability estimates, and for a handful of negative passage speed estimates.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/2" rel="nofollow"><picture><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="388"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>Posterior Standard Deviations for the LINIRT Word Decoding and Passage Reading Ability and Speed Estimates</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec19">Generalization Inference</h3><p>To evaluate the generalizability of the oral reading scores, we compared the content of the reading tasks to current Dutch learning goals and methods for early primary education, and compared the distributions of the LNIRT ability- and item-difficulty estimates. In addition, we compared the sample of primary schools to their population with regard to dialect region and school weight.</p><p>Dutch can be considered a semi-transparent language because of its relatively consistent grapheme-phoneme correspondences (Borgwaldt et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2004" title="Borgwaldt, S. R., Hellwig, F. M., &amp; de Groot, A. M. (2004). Word-initial entropy in five languages: letter to sound, and sound to letter. Written Language &amp; Literacy, 7(2), 165184. &#xA;                https://doi.org/10.1075/wll.7.2.03bor&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR8" id="ref-link-section-d2615778e1860">2004</a>; Seymour et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2003" title="Seymour, P. H. K., Aro, M., Erskine, J. M., COST Action A8 network. (2003). Foundation literacy acquisition in European orthographies. British Journal of Psychology, 94, 143174. &#xA;                https://doi.org/10.1348/000712603321661859&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR52" id="ref-link-section-d2615778e1863">2003</a>). Correspondingly, learning to read is primarily based on grapheme-phoneme rules. Accordingly, most schools in the Netherlands use a reading instructional method (mostly either Veilig Leren Lezen [learning to read safely; (Zwijsen Educatieve Uitgeverij, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2023" title="Zwijsen Educatieve Uitgeverij. (2023). Veilig leren lezen: KIM-versie [Learning to read safely: KIM-version]. Zwijsen" href="/article/10.1007/s40593-025-00480-y#ref-CR70" id="ref-link-section-d2615778e1866">2023</a>)] or Lijn 3 [Track 3; (Malmberg, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference n.d." title="Malmberg (n.d.).Lijn 3 aanvankelijk lezen groep 3 basisonderwijs [Line 3 initial reading grade 1 primary education]. Malmberg" href="/article/10.1007/s40593-025-00480-y#ref-CR34" id="ref-link-section-d2615778e1869">n.d.</a>)] that focusses on these rules to instruct decoding. These methods focus on teaching children grapheme-phoneme correspondences (including digraphs such as <i>ei</i><i>, </i><i>ui</i> and <i>ou</i>) and on learning to read simple structured words (both mono- and bi-syllabic) throughout the first half of Grade 1. Then, focus gradually shifts towards automatizing the reading process and reading more complex structured words (e.g. consonant clusters and bi-/polysyllabic words). After Grade 1, schools either use a method for advanced decoding instruction, incorporate it in instruction for other language-related instruction (e.g., reading comprehension of language arts), focus on furthering the automatization of the reading process, and/or focus instruction on advanced reading difficulties (e.g., loanwords and the use of <i>c, x</i> and <i>y</i> in words).</p><p>Likewise, SERDAs reading tasks build up in difficulty over its subtasks. Specifically, the first word decoding subtask primarily contains one-syllable words with various consonantvowel combinations and relatively basic reading difficulties (e.g. open syllable, sch-). Meanwhile, the second subtask focusses on one-, two- and three syllable words with more advanced reading difficulties (e.g. ge-, -lijk), while the third subtask contains two-to-four syllable words with more complex reading difficulties (e.g. -isch, loanwords). The same can be said for the passage reading task, which focusses on reading mono-, bi- and polysyllabic words with an increase in orthographic inconsistencies and complexities over subtasks. Finally, conform the instructional methods discussed, the reading tasks place specific focus on automatizing the reading process through a focus on both accuracy and speed in instruction and performance metrics alike. Altogether, the reading tasks closely match the way in which children are taught how to read in the Netherlands.</p><p>Figure<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s40593-025-00480-y#Fig3">3</a> shows the distribution of the LNIRT ability- and item-difficulty estimates of the word decoding and passage reading task. For both tasks, the item difficulty parameters cover the range of ability estimates, with the exception of some extremely low passage reading ability estimates. However, the difficulty of the items is generally low, showing relatively few items with positive difficulty estimates.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/3" rel="nofollow"><picture><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="382"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>LNIRT Ability and Difficulty Estimates for the Word Decoding and Passage Reading Task</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Figure<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s40593-025-00480-y#Fig4">4</a> shows the dialect region and school-weight distributions for the population and sample of primary schools in the Netherlands. Generally, the sample resembles the population. However, an underrepresentation of schools in the Western dialect region was observed, while the sample overrepresents schools with low school-weights.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="826"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Sample and Population Distributions for Dialect Region and School Weight</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><h3 class="c-article__sub-heading" id="Sec20">Extrapolation Inference</h3><p>To evaluate whether the oral reading scores allow for claims about oral reading performance, we calculated correlations between the LNIRT ability and speed estimates, the person level WCPM scores, and the categories of the DMT and AVI. In addition, we evaluated whether the word decoding and passage reading tasks provide information on all aspects of oral reading.</p><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s40593-025-00480-y#Tab5">5</a> presents the correlations between the ability estimates of the word decoding and passage reading task, the person level WCPM measures, and the categories of the DMT and AVI. Correlations varied between 0.32 and 0.88, showing weak to very strong correspondences between the oral reading metrics.
</p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Pearson and Spearman Correlations Between the LNIRT Ability and Speed Estimates, the Person Level WCPM Metrics, and the Categories of the DMT and AVI</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/article/10.1007/s40593-025-00480-y/tables/5" aria-label="Full size table 5"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>To reflect oral reading skills, the reading tasks should provide information regarding childrens oral reading accuracy, speed and automaticity. Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="/article/10.1007/s40593-025-00480-y#Tab1">1</a> shows that the word and passage reading tasks provide information on oral reading accuracy, speed and automaticity (WCPM). Meanwhile, the validation has shown that item-level information is reliable and that most of the resulting child-specific metrics moderately to strongly resemble current oral reading metrics. Therefore, we argue that child-specific information is provided on childrens oral reading accuracy, speed and automaticity through, respectively, the LNIRT ability and speed estimates, and the WCPM metrics.</p><h3 class="c-article__sub-heading" id="Sec21">Decision Making Inference</h3><p>To evaluate whether the oral reading items differentiate between good and less proficient oral readers, we evaluated the LNIRT item discrimination parameters. In addition, we investigated the classification accuracy of ordinal regression models that predicted oral reading proficiency, using the LNIRT ability and speed estimates, the person level WCPM metrics, and childrens Grade.</p><p>Figure<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s40593-025-00480-y#Fig5">5</a> shows the item discrimination parameters of the LNIRT model for the word decoding and passage reading task. Discrimination parameters primarily ranged between 0.8 and 1.4 for both the word and passage reading task, indicating that items generally discriminate moderately well or better (Baker, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2001" title="Baker, F. B. (2001).The basics of item response theory. &#xA;                http://ericae.net/irt/baker&#xA;                &#xA;              ." href="/article/10.1007/s40593-025-00480-y#ref-CR4" id="ref-link-section-d2615778e2463">2001</a>; Bichi &amp; Talib, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2018" title="Bichi, A. A., &amp; Talib, R. (2018). Item response theory: an introduction to latent trait models to test and item development. International Journal of Evaluation and Research in Education, 7(2), 142151. &#xA;                https://doi.org/10.11591/ijere.v7i2.12900&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR5" id="ref-link-section-d2615778e2466">2018</a>). Lower discrimination parameters were primarily observed for single-syllable words and articles.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/5" rel="nofollow"><picture><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="390"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>LNIRT Item Discrimination Parameters for the Word Decoding and Passage Reading Task</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s40593-025-00480-y/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The ordinal regression model used to predict the DMT proficiency classes showed a weighted kappa of 0.65 and an average F1 score of 0.70, indicating moderate to good classification accuracy. The ordinal regression model used to predict the AVI proficiency classes showed a weighted kappa of 0.73 and an average F1 score of 0.77, indicating moderate to good classification accuracy.</p><h3 class="c-article__sub-heading" id="Sec22">Validation Evaluation</h3><p>Following the presentation of validity evidence, we applied the ABP (Kane, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Kane, M. T. (1992). An argument-based approach to validity. Psychological Bulletin, 112, 527535. &#xA;                https://doi.org/10.1037/0033-2909.112.3.527&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR25" id="ref-link-section-d2615778e2498">1992</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kane, M. T. (2006). Validation. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 1764). Washington: American Council on Education/Praeger" href="/article/10.1007/s40593-025-00480-y#ref-CR27" id="ref-link-section-d2615778e2501">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Kane, M. T. (2013). Validating the interpretations and uses of test scores. Journal of Educational Measurement, 50, 173. &#xA;                https://doi.org/10.1111/jedm.12000&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR26" id="ref-link-section-d2615778e2504">2013</a>) to evaluate whether the proposed interpretations of SERDAs reading tasks can be substantiated. For these purposes, we used the three criteria specified by Wools et al. (<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wools, S., Eggen, T. J. H. M., &amp; Sanders, P. F. (2010). Evaluation of validity and validation by means of the argument-based approach. Cadmo, 18(1), 6382. &#xA;                https://doi.org/10.3280/CAD2010-001007&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR69" id="ref-link-section-d2615778e2507">2010</a>) to validate the validation process in its entirety.</p><p>The first criterion focusses on the complexity of the interpretive argument, as evidenced through the number of inferences and their level of detail. To meet the first criterion, at least four inferences should be specified, each including at least one backing, warrant and rebuttal. As shown in Appendix A, the current study specified four inferences, which were all supplied with at least one backing, warrant and rebuttal. Therefore, the interpretive argument is deemed sufficiently complex and detailed, allowing for the acceptance of the first criterion.</p><p>The second criterion focusses on evaluating the presented evidence with regard to plausibility and coherence. For each inference, the validity argument is evaluated in full, resulting in the acceptance or rejection of the inference.</p><p>For the scoring inference, we found that the ASR-based oral reading scores resemble human ratings moderately well. In addition, the reliability of the word and passage reading tasks was deemed excellent, showing high internal consistency and low posterior standard deviations for most ability levels. Therefore, the validity evidence substantiates the scoring inference sufficiently to warrant its acceptance.</p><p>For the generalization inference, the gathered validity evidence indicates that the reading tasks reflect the way in which children learn to read in the Netherlands, while the difficulty of the tasks matches the expected difficulty in Grade 2 and Grade 3 of primary education. In addition, although some differences with the population were observed, the sample of schools generally represented the population well with regard to the distribution of dialect region and school-weight. Therefore, the validity evidence sufficiently substantiates the acceptance of the generalization inference.</p><p>For the extrapolation inference, we found that most LNIRT ability estimates, all LNIRT speed estimates, and the person level WCPM metrics, resembled the DMT and AVI classifications moderately well or better. In addition, we argued that the reading tasks provide item and person level information that reflect oral reading accuracy, speed and automaticity. Based on these results, we conclude that the reading tasks provide scores that reflect oral reading skills, thereby justifying the acceptance of the extrapolation inference.</p><p>For the decision making inference, the discrimination parameters from the LNIRT model suggest that most items are able to discriminate between good and less proficient oral readers moderately well or better. In addition, we found moderate to good classification accuracy when predicting the DMT and AVI proficiency classes with the decoding metrics. Therefore, the evidence indicates that the decision making inference is validly assumed, leading to its acceptance.</p><p>The third criterion emphasizes the plausibility of the validity argument as a whole, thereby taking into account all validity evidence of all inferences. Accordingly, the third criterion can only be justified if the first two criteria have been met. Based on the acceptance of the first criterion, and each step of the second criterion, the third criterion is also deemed justified. Thus, given that sufficiently numerous and detailed validity evidence has been presented to deem each of the specified inferences plausible, the validation as a whole is also deemed plausible.</p></div></div></section><section data-title="Discussion"><div class="c-article-section" id="Sec23-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec23">Discussion</h2><div class="c-article-section__content" id="Sec23-content"><p>The aim of the current study was to investigate whether valid word decoding and passage reading metrics could be generated for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument. The validation was conducted using the extended ABP (Kane, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1992" title="Kane, M. T. (1992). An argument-based approach to validity. Psychological Bulletin, 112, 527535. &#xA;                https://doi.org/10.1037/0033-2909.112.3.527&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR25" id="ref-link-section-d2615778e2541">1992</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2006" title="Kane, M. T. (2006). Validation. In R. L. Brennan (Ed.), Educational measurement (4th ed., pp. 1764). Washington: American Council on Education/Praeger" href="/article/10.1007/s40593-025-00480-y#ref-CR27" id="ref-link-section-d2615778e2544">2006</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2013" title="Kane, M. T. (2013). Validating the interpretations and uses of test scores. Journal of Educational Measurement, 50, 173. &#xA;                https://doi.org/10.1111/jedm.12000&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR26" id="ref-link-section-d2615778e2547">2013</a>; Wools et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2010" title="Wools, S., Eggen, T. J. H. M., &amp; Sanders, P. F. (2010). Evaluation of validity and validation by means of the argument-based approach. Cadmo, 18(1), 6382. &#xA;                https://doi.org/10.3280/CAD2010-001007&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR69" id="ref-link-section-d2615778e2550">2010</a>), which includes a validation evaluation. Subsequently, we present the interpretation of the results, suggestions for future research, and the conclusion.</p><p>Based on the results of the validation, the scoring inference was deemed plausible, indicating that oral reading performances can be reliably translated into observable ASR-based oral reading scores. However, while the reliability of the ASR-based scores was excellent, the ASR-based scores showed only moderate resemblance to human raters. To be more specific, both tasks showed high sensitivity and specificity, but only moderate to low precision was observed, indicating that the ASR somewhat overestimates the number of errors a reader makes.</p><p>The lower precision could be explained through the unbalanced state of the data, as most items were read correctly. Given that reading errors were the clear minority group, and given that errors were coded as positives, false positive classifications occurred most frequently, leading to lower precision. As this unbalance was more prominently the case for the word decoding task, its precision was especially affected. More generally, a possible explanation for these moderate results is that state-of-the-art ASR models (as used in this study) are trained on adult speech, and therefore perform worse on child speech, which shows more variability than adult speech (Feng et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024" title="Feng, S., Halpern, B. M., Kudina, O., &amp; Scharenborg, O. (2024). Towards inclusive automatic speech recognition. Computer Speech &amp; Language, 84, 101567. &#xA;                https://doi.org/10.1016/j.csl.2023.101567&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR17" id="ref-link-section-d2615778e2559">2024</a>). Child speech recognition is a challenging problem, mainly because of the lack of annotated data to capture speech variability. In future research, we would like to extent the SERDA speech corpus with annotations, so that they can be used to improve child speech recognition. Based on the moderate agreement and low to moderate precision, even though the current study has shown evidence that observable and reliable scores can be generated using an ASR-based approach, we suggest against immediate usage in high-stakes settings.</p><p>While these limitations also argue against the acceptance of the scoring inference, the purpose of this validation was not to evaluate whether ASR-based oral reading metrics can be used in high stakes settings, nor whether each individual ASR prediction is correct. Instead, we evaluated whether observable ASR-based oral reading scores could be generated such that practitioners can be reliably informed about childrens oral reading skills. In short, while future researcher should focus on optimizing ASR performance for this speech corpus, and ASR based on childrens speech in general, the observed results were deemed sufficient to satisfy the scoring inference within more formative test settings, matching SERDAs developmental purposes (van der Velde et al., <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2024b" title="Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ranelovi B., Karali E., Aleksi K., uki D. (Eds.), E-testing and computer-based assessment. CIDREE Yearbook 2024 (pp. 99123). CIDREE. &#xA;                https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR60" id="ref-link-section-d2615778e2565">2024b</a>).</p><p>The investigation of the generalization inference resulted in its acceptance, suggesting that the sample of oral reading items and primary schools represent the population. However, a potential issue concerned task difficulty, as many items were shown to be relatively easy. An explanation could be found in the relatively large number of primary schools with a low school-weight. To elaborate, a low school-weight indicates that the children attending a school, on average, are expected to perform relatively well compared to the population. In other words, the prevalence of well-performing schools could have resulted in a sample with relatively many well-performing children, for whom the items are relatively easy. Thus, although the results provide evidence that generalisations towards the general population of second and third graders is possible, further investigations are required into both the performance of the ASR, and the resulting scores, in samples of predominantly highly and less skilled oral readers.</p><p>The evaluation of the validity evidence resulted in the acceptance of the extrapolation inference, indicating that the reading tasks reflect oral reading skills. Specifically, we found that most LNIRT ability and speed estimates were strongly related to the person level WCPM metrics. With regard to the DMT and AVI, the speed estimates and WCPM metrics outperformed the ability estimates. This finding is unsurprising, given that earlier research has stressed the importance of variability in reading speed, and therefore automaticity, throughout reading development (e.g. Verhoeven &amp; van Leeuwe, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2009" title="Verhoeven, L., &amp; Van Leeuwe, J. (2009). Modeling the growth of word-decoding skills: evidence from Dutch. Scientific Studies of Reading, 13(3), 205223. &#xA;                https://doi.org/10.1080/10888430902851356&#xA;                &#xA;              " href="/article/10.1007/s40593-025-00480-y#ref-CR66" id="ref-link-section-d2615778e2575">2009</a>), while accuracy tends to show lower variability between children as they progress through primary education. To conclude, the results support the assumption that the reading tasks measure oral reading skills, while simultaneously highlighting the importance of including the assessment of speed when using ASR to measure oral reading fluency.</p><p>The decision making inference was also justified, showing that the reading tasks allow users to make decisions regarding childrens oral reading proficiency and development. However, some of the passage reading items did not have much, or any, discriminative ability. Investigations unearthed that these items primarily concerned articles (e.g. a, an [<i>een, de, het]</i>), and other single-syllable words, which contain little to no orthographic complexity. Although an investigation into LNIRT model performance without these items could be of interest, this would also reduce the amount of items in the passage reading task, potentially making the passage reading task more difficult. Therefore, this consideration should be more thoroughly investigated before it is implemented.</p><p>Based on these findings, the following recommendations for further research are specified. Firstly, while the present study has demonstrated promise regarding the use of ASR to assess oral reading fluency skills for young children, researchers are advised to investigate the optimalization of ASR performance for the current speech corpus, including an evaluation of the Word Error Rate (WER). Especially interesting would be an assessment of ASR performance for samples containing primarily highly or less proficient orally fluent readers. When compared to the results of the current study, such investigations can provide a more thorough understanding of the behaviour of the ASR, and the resulting LNIRT item parameters and person estimates, potentially leading to higher ASR performances on childrens speech in general. Secondly, the performance of the LNIRT model should be compared for different subsets of items, allowing for the specification of an optimal, or minimally required, set of items or subtasks. Researchers are advised to focus on the evaluation of models that exclude items with low to no discrimination ability, and on a more specific evaluation of the word and passage decoding subtasks. Finally, now that it has been shown that oral reading metrics can be extracted from SERDA, work should focus on including and validating a prosody component.</p></div></div></section><section data-title="Conclusion"><div class="c-article-section" id="Sec24-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec24">Conclusion</h2><div class="c-article-section__content" id="Sec24-content"><p>In conclusion, the gathered evidence suggests that valid word decoding and passage reading measures can be generated for a semi-transparent language, using an ASR-based oral reading fluency assessment instrument. The results provide evidence that the reading tasks can be used to obtain observable and reliable oral reading metrics, while the samples of reading tasks and Dutch primary schools were deemed plentiful and representative enough to warrant generalizations towards their general populations. Evidence also substantiated that the reading tasks measure oral reading skills, and that the tasks allow users to make some claims and decisions regarding childrens oral reading proficiency and development. However, the ASR requires optimalization and its errors require further exploration through the analysis of, for example, Word Error Rates. Furthermore, generalizations towards high and low proficiency populations should be more thoroughly investigated, allowing for comparisons of ASR performance, and LNIRT item and person characteristics behavior, such that ASR performance for childrens speech can be improved. Finally, future researchers are advised to realize and validate a prosody component. If implemented correctly, these changes would complete the envisioned oral reading fluency assessment instrument, thereby improving the provision of detailed diagnostics, reducing teachers testing burden, and improving the assessment of oral reading fluency throughout all of primary education.</p></div></div></section>
                                </div>
                        
                    

                    
                        
                    

                    
                        
                    

                    
                    <section data-title="Data availability"><div class="c-article-section" id="data-availability-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="data-availability">Data availability</h2><div class="c-article-section__content" id="data-availability-content">
            
            <p>The data used throughout the study are available from the corresponding author upon reasonable request.</p>
          </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ul class="c-article-references" data-track-component="outbound reference" data-track-context="references section"><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR1">Aldhanhani, Z. R., &amp; Abu-Ayyash, E. A. (2020). Theories and research on oral readingfluency: What is needed? <i>Theory and Practice in Language Studies,</i> <i>10</i>(4), 379388. <a href="https://doi.org/10.17507/tpls.1004.05" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.17507/tpls.1004.05">https://doi.org/10.17507/tpls.1004.05</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.17507/tpls.1004.05" data-track-item_id="10.17507/tpls.1004.05" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.17507%2Ftpls.1004.05" aria-label="Article reference 1" data-doi="10.17507/tpls.1004.05">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Theories%20and%20Research%20on%20Oral%20ReadingFluency%3A%20What%20Is%20Needed%3F&amp;journal=Theory%20and%20Practice%20in%20Language%20Studies&amp;doi=10.17507%2Ftpls.1004.05&amp;volume=10&amp;issue=4&amp;pages=379-388&amp;publication_year=2020&amp;author=Aldhanhani%2CZR&amp;author=Abu-Ayyash%2CEA">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR2">Bai, Y., Hubers, F. C. W., Cucchiarini, C., &amp; Strik, H. (2020). <i>ASR-Based Evaluation and Feedback for Individualized Reading Practice.</i> INTERSPEECH 2020: Shanghai, China. <a href="https://www.isca-archive.org/interspeech_2020/bai20b_interspeech.pdf" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.isca-archive.org/interspeech_2020/bai20b_interspeech.pdf">https://www.isca-archive.org/interspeech_2020/bai20b_interspeech.pdf</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR3">Bai, Y., Hubers, F. C. W., Cucchiarini, C., &amp; Strik, H. (2021). <i>An ASR-based Reading Tutor for Practicing Reading Skills in the First Grade: Improving Performance through Threshold Adjustment.</i> IberSPEECH 2021: Valladolid, Spain. <a href="https://repository.ubn.ru.nl/bitstream/handle/2066/245151/245151.pdf" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://repository.ubn.ru.nl/bitstream/handle/2066/245151/245151.pdf">https://repository.ubn.ru.nl/bitstream/handle/2066/245151/245151.pdf</a>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR4">Baker, F. B. (2001).<i>The basics of item response theory</i>. <a href="http://ericae.net/irt/baker" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://ericae.net/irt/baker">http://ericae.net/irt/baker</a>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR5">Bichi, A. A., &amp; Talib, R. (2018). Item response theory: an introduction to latent trait models to test and item development. <i>International Journal of Evaluation and Research in Education,</i> <i>7</i>(2), 142151. <a href="https://doi.org/10.11591/ijere.v7i2.12900" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.11591/ijere.v7i2.12900">https://doi.org/10.11591/ijere.v7i2.12900</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.11591/ijere.v7i2.12900" data-track-item_id="10.11591/ijere.v7i2.12900" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.11591%2Fijere.v7i2.12900" aria-label="Article reference 5" data-doi="10.11591/ijere.v7i2.12900">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Item%20Response%20Theory%3A%20An%20Introduction%20to%20Latent%20Trait%20Models%20to%20Test%20and%20Item%20Development&amp;journal=International%20Journal%20of%20Evaluation%20and%20Research%20in%20Education&amp;doi=10.11591%2Fijere.v7i2.12900&amp;volume=7&amp;issue=2&amp;pages=142-151&amp;publication_year=2018&amp;author=Bichi%2CAA&amp;author=Talib%2CR">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR6">Boersma, P., &amp; Weenink, D. (2024). Praat: doing phonetics by computer [Computer program]. Version 6.4.13, retrieved 10 June 2024 from <a href="http://www.praat.org/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://www.praat.org/">http://www.praat.org/</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR7">Bolaos, D., Cole, R. A., Ward, W. H., Tindal, G. A., Hasbrouck, J., &amp; Schwanenflugel, P. J. (2013). Human and automated assessment of oral reading fluency. <i>Journal of Educational Psychology,</i> <i>105</i>(4), 11421151. <a href="https://doi.org/10.1037/a0031479" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1037/a0031479">https://doi.org/10.1037/a0031479</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/a0031479" data-track-item_id="10.1037/a0031479" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0031479" aria-label="Article reference 7" data-doi="10.1037/a0031479">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20and%20automated%20assessment%20of%20oral%20reading%20fluency&amp;journal=Journal%20of%20Educational%20Psychology&amp;doi=10.1037%2Fa0031479&amp;volume=105&amp;issue=4&amp;pages=1142-1151&amp;publication_year=2013&amp;author=Bola%C3%B1os%2CD&amp;author=Cole%2CRA&amp;author=Ward%2CWH&amp;author=Tindal%2CGA&amp;author=Hasbrouck%2CJ&amp;author=Schwanenflugel%2CPJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR8">Borgwaldt, S. R., Hellwig, F. M., &amp; de Groot, A. M. (2004). Word-initial entropy in five languages: letter to sound, and sound to letter. <i>Written Language &amp; Literacy,</i> <i>7</i>(2), 165184. <a href="https://doi.org/10.1075/wll.7.2.03bor" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1075/wll.7.2.03bor">https://doi.org/10.1075/wll.7.2.03bor</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1075/wll.7.2.03bor" data-track-item_id="10.1075/wll.7.2.03bor" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1075%2Fwll.7.2.03bor" aria-label="Article reference 8" data-doi="10.1075/wll.7.2.03bor">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Word-initial%20entropy%20in%20five%20languages%3A%20Letter%20to%20sound%2C%20and%20sound%20to%20letter&amp;journal=Written%20Language%20%26%20Literacy&amp;doi=10.1075%2Fwll.7.2.03bor&amp;volume=7&amp;issue=2&amp;pages=165-184&amp;publication_year=2004&amp;author=Borgwaldt%2CSR&amp;author=Hellwig%2CFM&amp;author=Groot%2CAM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR9">Bray, B., &amp; McClaskey, K. (2015). <i>Make learning personal</i>. SAGE Publications Ltd., USA.</p><p class="c-article-references__links u-hide-print"><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Make%20learning%20personal&amp;publication_year=2015&amp;author=Bray%2CB&amp;author=McClaskey%2CK">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR10">Cheng, J., &amp; Shen, J. (2010). <i>Towards accurate recognition for children's oral reading fluency.</i> IEEE Spoken Language Technology Workshop: Berkeley, USA. <a href="https://doi.org/10.1109/SLT.2010.5700830" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1109/SLT.2010.5700830">https://doi.org/10.1109/SLT.2010.5700830</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR11">Cheng, J. (2018). <i>Real-time scoring of an oral reading assessment on mobile devices</i>. INTERSPEECH 2018: Hyderabad. <a href="https://doi.org/10.21437/Interspeech.2018-34" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.21437/Interspeech.2018-34">https://doi.org/10.21437/Interspeech.2018-34</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR12">Chicco, D., Warrens, M. J., &amp; Jurman, G. (2021). The Matthews correlation coefficient (MCC) is more informative than Cohens Kappa and Brier score in binary classification assessment. <i>Ieee Access,</i> <i>9</i>, 7836878381. <a href="https://doi.org/10.1109/ACCESS.2021.3084050" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1109/ACCESS.2021.3084050">https://doi.org/10.1109/ACCESS.2021.3084050</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/ACCESS.2021.3084050" data-track-item_id="10.1109/ACCESS.2021.3084050" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FACCESS.2021.3084050" aria-label="Article reference 12" data-doi="10.1109/ACCESS.2021.3084050">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Matthews%20correlation%20coefficient%20%28MCC%29%20is%20more%20informative%20than%20Cohen%E2%80%99s%20Kappa%20and%20Brier%20score%20in%20binary%20classification%20assessment&amp;journal=Ieee%20Access&amp;doi=10.1109%2FACCESS.2021.3084050&amp;volume=9&amp;pages=78368-78381&amp;publication_year=2021&amp;author=Chicco%2CD&amp;author=Warrens%2CMJ&amp;author=Jurman%2CG">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR13">Clarke-Midura, J., &amp; Dede, C. (2010). Assessment, technology, and change. <i>Journal of Research on Technology in Education,</i> <i>42</i>(3), 309328. <a href="https://doi.org/10.1080/15391523.2010.10782553" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1080/15391523.2010.10782553">https://doi.org/10.1080/15391523.2010.10782553</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/15391523.2010.10782553" data-track-item_id="10.1080/15391523.2010.10782553" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F15391523.2010.10782553" aria-label="Article reference 13" data-doi="10.1080/15391523.2010.10782553">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Assessment%2C%20technology%2C%20and%20change&amp;journal=Journal%20of%20Research%20on%20Technology%20in%20Education&amp;doi=10.1080%2F15391523.2010.10782553&amp;volume=42&amp;issue=3&amp;pages=309-328&amp;publication_year=2010&amp;author=Clarke-Midura%2CJ&amp;author=Dede%2CC">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR14">Connor, C. M., &amp; Morrison, F. J. (2016). Individualizing student instruction in reading: implications for policy and practice. <i>Policy Insights from the Behavioral and Brain Sciences,</i> <i>3</i>(1), 5461. <a href="https://doi.org/10.1177/2372732215624931" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1177/2372732215624931">https://doi.org/10.1177/2372732215624931</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/2372732215624931" data-track-item_id="10.1177/2372732215624931" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F2372732215624931" aria-label="Article reference 14" data-doi="10.1177/2372732215624931">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Individualizing%20student%20instruction%20in%20reading%3A%20Implications%20for%20policy%20and%20practice&amp;journal=Policy%20Insights%20from%20the%20Behavioral%20and%20Brain%20Sciences&amp;doi=10.1177%2F2372732215624931&amp;volume=3&amp;issue=1&amp;pages=54-61&amp;publication_year=2016&amp;author=Connor%2CCM&amp;author=Morrison%2CFJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR15">Cucchiarini, C., Neri, A., &amp; Strik, H. (2009). Oral proficiency training in Dutch L2: the contribution of ASR-based corrective feedback. <i>Speech Communication,</i> <i>51</i>(10), 853863. <a href="https://doi.org/10.1016/j.specom.2009.03.003" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1016/j.specom.2009.03.003">https://doi.org/10.1016/j.specom.2009.03.003</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.specom.2009.03.003" data-track-item_id="10.1016/j.specom.2009.03.003" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.specom.2009.03.003" aria-label="Article reference 15" data-doi="10.1016/j.specom.2009.03.003">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Oral%20proficiency%20training%20in%20Dutch%20L2%3A%20The%20contribution%20of%20ASR-based%20corrective%20feedback&amp;journal=Speech%20Communication&amp;doi=10.1016%2Fj.specom.2009.03.003&amp;volume=51&amp;issue=10&amp;pages=853-863&amp;publication_year=2009&amp;author=Cucchiarini%2CC&amp;author=Neri%2CA&amp;author=Strik%2CH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR16">Cucchiarini, C., van Hamme, H., Driesen, J., Sanders, E. (2008). <i>THE JASMIN-CGN: CORPUS Design, recording, transcription and structure of the corpus</i></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR17">Feng, S., Halpern, B. M., Kudina, O., &amp; Scharenborg, O. (2024). Towards inclusive automatic speech recognition. <i>Computer Speech &amp; Language,</i> <i>84</i>, 101567. <a href="https://doi.org/10.1016/j.csl.2023.101567" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1016/j.csl.2023.101567">https://doi.org/10.1016/j.csl.2023.101567</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.csl.2023.101567" data-track-item_id="10.1016/j.csl.2023.101567" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.csl.2023.101567" aria-label="Article reference 17" data-doi="10.1016/j.csl.2023.101567">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20inclusive%20automatic%20speech%20recognition&amp;journal=Computer%20Speech%20%26%20Language&amp;doi=10.1016%2Fj.csl.2023.101567&amp;volume=84&amp;publication_year=2024&amp;author=Feng%2CS&amp;author=Halpern%2CBM&amp;author=Kudina%2CO&amp;author=Scharenborg%2CO">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR18">Fox, J. P., Klotzke, K., &amp; Simsek, A. S. (2021). LNIRT: An R package for joint modeling of response accuracy and times.<i>arXiv preprint </i><a href="http://arxiv.org/abs/2106.10144" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://arxiv.org/abs/2106.10144">arXiv:2106.10144</a>. <a href="https://arxiv.org/abs/2106.10144" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://arxiv.org/abs/2106.10144">https://arxiv.org/abs/2106.10144</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR19">Fuchs, L., Fuchs, D., Hosp, M., &amp; Jenkins, J. (2001). Oral reading fluency as an indicator of reading competence: a theoretical, empirical, and historical analysis. <i>Scient Stud Read.,</i> <i>5</i>, 239256. <a href="https://doi.org/10.1207/S1532799XSSR0503_3" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1207/S1532799XSSR0503_3">https://doi.org/10.1207/S1532799XSSR0503_3</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1207/S1532799XSSR0503_3" data-track-item_id="10.1207/S1532799XSSR0503_3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1207%2FS1532799XSSR0503_3" aria-label="Article reference 19" data-doi="10.1207/S1532799XSSR0503_3">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Oral%20reading%20fluency%20as%20an%20indicator%20of%20reading%20competence%3A%20A%20theoretical%2C%20empirical%2C%20and%20historical%20analysis&amp;journal=Scient%20Stud%20Read.&amp;doi=10.1207%2FS1532799XSSR0503_3&amp;volume=5&amp;pages=239-256&amp;publication_year=2001&amp;author=Fuchs%2CL&amp;author=Fuchs%2CD&amp;author=Hosp%2CM&amp;author=Jenkins%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR20">Grainger, J., &amp; Segui, J. (1990). Neighborhood frequency effects in visual word recognition: a comparison of lexical decision and masked identification latencies. <i>Perception &amp; Psychophysics,</i> <i>47</i>, 191198. <a href="https://doi.org/10.3758/BF03205983" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.3758/BF03205983">https://doi.org/10.3758/BF03205983</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3758/BF03205983" data-track-item_id="10.3758/BF03205983" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3758%2FBF03205983" aria-label="Article reference 20" data-doi="10.3758/BF03205983">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Neighborhood%20frequency%20effects%20in%20visual%20word%20recognition%3A%20A%20comparison%20of%20lexical%20decision%20and%20masked%20identification%20latencies&amp;journal=Perception%20%26%20Psychophysics&amp;doi=10.3758%2FBF03205983&amp;volume=47&amp;pages=191-198&amp;publication_year=1990&amp;author=Grainger%2CJ&amp;author=Segui%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR21">Groen, M. A., Veenendaal, N. J., &amp; Verhoeven, L. (2018). The role of prosody in reading comprehension: evidence from poor comprehenders. <i>Journal of Research in Reading,</i> <i>42</i>(1), 3757. <a href="https://doi.org/10.1111/1467-9817.12133" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1111/1467-9817.12133">https://doi.org/10.1111/1467-9817.12133</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1111/1467-9817.12133" data-track-item_id="10.1111/1467-9817.12133" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1111%2F1467-9817.12133" aria-label="Article reference 21" data-doi="10.1111/1467-9817.12133">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20prosody%20in%20reading%20comprehension%3A%20Evidence%20from%20poor%20comprehenders&amp;journal=Journal%20of%20Research%20in%20Reading&amp;doi=10.1111%2F1467-9817.12133&amp;volume=42&amp;issue=1&amp;pages=37-57&amp;publication_year=2018&amp;author=Groen%2CMA&amp;author=Veenendaal%2CNJ&amp;author=Verhoeven%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR22">Hambleton, R. K., &amp; Swaminathan, H. (1985).<i> Item response theory: Principles and applications</i>. Springer. <a href="https://link.springer.com/book/10.1007/978-94-017-1988-9" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://link.springer.com/book/10.1007/978-94-017-1988-9">https://link.springer.com/book/10.1007/978-94-017-1988-9</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR23">Hoover, W. A., &amp; Gough, P. B. (1990). The simple view of reading. <i>Reading and Writing,</i> <i>2</i>, 127160. <a href="https://doi.org/10.1007/BF00401799" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1007/BF00401799">https://doi.org/10.1007/BF00401799</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/BF00401799" data-track-item_id="10.1007/BF00401799" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/BF00401799" aria-label="Article reference 23" data-doi="10.1007/BF00401799">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20simple%20view%20of%20reading&amp;journal=Reading%20and%20Writing&amp;doi=10.1007%2FBF00401799&amp;volume=2&amp;pages=127-160&amp;publication_year=1990&amp;author=Hoover%2CWA&amp;author=Gough%2CPB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR24">Inspectorate of Education. (2024). <i>Schoolweging primair onderwijs</i> [Schoolweightprimary education]. <a href="https://www.onderwijsinspectie.nl/trends-en-ontwikkelingen/onderwijsdata/schoolweging-po" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.onderwijsinspectie.nl/trends-en-ontwikkelingen/onderwijsdata/schoolweging-po">https://www.onderwijsinspectie.nl/trends-en-ontwikkelingen/onderwijsdata/schoolweging-po</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR25">Kane, M. T. (1992). An argument-based approach to validity. <i>Psychological Bulletin,</i> <i>112</i>, 527535. <a href="https://doi.org/10.1037/0033-2909.112.3.527" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1037/0033-2909.112.3.527">https://doi.org/10.1037/0033-2909.112.3.527</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0033-2909.112.3.527" data-track-item_id="10.1037/0033-2909.112.3.527" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-2909.112.3.527" aria-label="Article reference 25" data-doi="10.1037/0033-2909.112.3.527">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20argument-based%20approach%20to%20validity&amp;journal=Psychological%20Bulletin&amp;doi=10.1037%2F0033-2909.112.3.527&amp;volume=112&amp;pages=527-535&amp;publication_year=1992&amp;author=Kane%2CMT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR26">Kane, M. T. (2013). Validating the interpretations and uses of test scores. <i>Journal of Educational Measurement,</i> <i>50</i>, 173. <a href="https://doi.org/10.1111/jedm.12000" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1111/jedm.12000">https://doi.org/10.1111/jedm.12000</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1111/jedm.12000" data-track-item_id="10.1111/jedm.12000" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1111%2Fjedm.12000" aria-label="Article reference 26" data-doi="10.1111/jedm.12000">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Validating%20the%20interpretations%20and%20uses%20of%20test%20scores&amp;journal=Journal%20of%20Educational%20Measurement&amp;doi=10.1111%2Fjedm.12000&amp;volume=50&amp;pages=1-73&amp;publication_year=2013&amp;author=Kane%2CMT">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR27">Kane, M. T. (2006). Validation. In R. L. Brennan (Ed.), <i>Educational measurement</i> (4th ed., pp. 1764). Washington: American Council on Education/Praeger</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR28">Kheir, Y. E., Ali, A., &amp; Chowdhury, S. A. (2023). <i>Automatic Pronunciation Assessment--A Review</i>. <i>arXiv preprint </i><a href="http://arxiv.org/abs/2310.13974" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://arxiv.org/abs/2310.13974">arXiv:2310.13974</a><i>.</i> <a href="https://doi.org/10.48550/arXiv.2310.13974" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.2310.13974">https://doi.org/10.48550/arXiv.2310.13974</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR29">Kim, Y. S. G., Quinn, J. M., &amp; Petscher, Y. (2021). What is text reading fluency and is it a predictor or an outcome of reading comprehension? <i>A longitudinal investigation. Developmental Psychology,</i> <i>57</i>(5), 718732. <a href="https://doi.org/10.1037/2Fdev0001167" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1037/2Fdev0001167">https://doi.org/10.1037/2Fdev0001167</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/2Fdev0001167" data-track-item_id="10.1037/2Fdev0001167" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F2Fdev0001167" aria-label="Article reference 29" data-doi="10.1037/2Fdev0001167">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20is%20text%20reading%20fluency%20and%20is%20it%20a%20predictor%20or%20an%20outcome%20of%20reading%20comprehension%3F&amp;journal=A%20longitudinal%20investigation.%20Developmental%20Psychology&amp;doi=10.1037%2F2Fdev0001167&amp;volume=57&amp;issue=5&amp;pages=718-732&amp;publication_year=2021&amp;author=Kim%2CYSG&amp;author=Quinn%2CJM&amp;author=Petscher%2CY">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR30">Kuhn, M., Schwanenflugel, P., &amp; Meisinger, E. (2010). Aligning theory and assessment of reading fluency: automaticity, prosody, and definitions of fluency. <i>Reading Research Quarterly,</i> <i>45</i>(2), 232253. <a href="https://doi.org/10.1598/RRQ.45.2.4" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1598/RRQ.45.2.4">https://doi.org/10.1598/RRQ.45.2.4</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1598/RRQ.45.2.4" data-track-item_id="10.1598/RRQ.45.2.4" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1598%2FRRQ.45.2.4" aria-label="Article reference 30" data-doi="10.1598/RRQ.45.2.4">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Aligning%20theory%20and%20assessment%20of%20reading%20fluency%3A%20Automaticity%2C%20prosody%2C%20and%20definitions%20of%20fluency&amp;journal=Reading%20Research%20Quarterly&amp;doi=10.1598%2FRRQ.45.2.4&amp;volume=45&amp;issue=2&amp;pages=232-253&amp;publication_year=2010&amp;author=Kuhn%2CM&amp;author=Schwanenflugel%2CP&amp;author=Meisinger%2CE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR31">Levis, J., &amp; Suvorov, R. (2012). Automatic speech recognition. In<i>The encyclopedia of applied linguistics.</i>Chapelle, C. A. (2012). Hoboken : John Wiley &amp; Sons</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR32">Logan, G. D. (1988). Toward an instance theory of automatization. <i>Psychological Review,</i> <i>95</i>(4), 492527. <a href="https://doi.org/10.1037/0033-295X.95.4.492" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1037/0033-295X.95.4.492">https://doi.org/10.1037/0033-295X.95.4.492</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0033-295X.95.4.492" data-track-item_id="10.1037/0033-295X.95.4.492" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.95.4.492" aria-label="Article reference 32" data-doi="10.1037/0033-295X.95.4.492">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Toward%20an%20instance%20theory%20of%20automatization&amp;journal=Psychological%20Review&amp;doi=10.1037%2F0033-295X.95.4.492&amp;volume=95&amp;issue=4&amp;pages=492-527&amp;publication_year=1988&amp;author=Logan%2CGD">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR33">Loukina, A., Klebanov, B. B., Lange, P. L., Qian, Y., Gyawali, B., Madnani, N., Misra, A., Zechner, K., Wang, Z., &amp; Sabatini, J. (2019)<i>. Automated Estimation of Oral Reading Fluency During Summer Camp e-Book Reading with MyTurnToRead.</i> INTERSPEECH 2019: Graz, Austria. <a href="https://www.iscaarchive.org/interspeech_2019/loukina19_interspeech.pdf" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.iscaarchive.org/interspeech_2019/loukina19_interspeech.pdf">https://www.iscaarchive.org/interspeech_2019/loukina19_interspeech.pdf</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR34">Malmberg (n.d.).<i>Lijn 3 aanvankelijk lezen groep 3 basisonderwijs [Line 3 initial reading grade 1 primary education]</i>. Malmberg</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR35">Mastropieri, M. A., &amp; Scruggs, T. E. (1997). Best practices in promoting reading comprehension in students with learning disabilities 1976 to 1996. <i>Remedial and Special Education,</i> <i>18</i>, 197213. <a href="https://doi.org/10.1177/074193259701800402" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1177/074193259701800402">https://doi.org/10.1177/074193259701800402</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/074193259701800402" data-track-item_id="10.1177/074193259701800402" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F074193259701800402" aria-label="Article reference 35" data-doi="10.1177/074193259701800402">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Best%20practices%20in%20promoting%20reading%20comprehension%20in%20students%20with%20learning%20disabilities%201976%20to%201996&amp;journal=Remedial%20and%20Special%20Education&amp;doi=10.1177%2F074193259701800402&amp;volume=18&amp;pages=197-213&amp;publication_year=1997&amp;author=Mastropieri%2CMA&amp;author=Scruggs%2CTE">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR36">Meelissen, M. R. M., Maassen, N. A. M., Gubbels, J., van Langen, A. M. L., Valk, J., Dood, C., Derks, I., In t Zandt, M., &amp; Wolbers, M. (2023). <i>Resultaten PISA-2022 in vogelvlucht [Results PISA-2022-An overview]</i>. Enschede: Universiteit Twente. <a href="https://doi.org/10.3990/1.9789036559461" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.3990/1.9789036559461">https://doi.org/10.3990/1.9789036559461</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR37">Miller, J., &amp; Schwanenflugel, P. J. (2008). A longitudinal study of the development of reading prosody as a dimension of oral reading fluency in early elementary school children. <i>Reading Research Quarterly,</i> <i>43</i>(4), 336354. <a href="https://doi.org/10.1598/RRQ.43.4.2" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1598/RRQ.43.4.2">https://doi.org/10.1598/RRQ.43.4.2</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1598/RRQ.43.4.2" data-track-item_id="10.1598/RRQ.43.4.2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1598%2FRRQ.43.4.2" aria-label="Article reference 37" data-doi="10.1598/RRQ.43.4.2">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20longitudinal%20study%20of%20the%20development%20of%20reading%20prosody%20as%20a%20dimension%20of%20oral%20reading%20fluency%20in%20early%20elementary%20school%20children&amp;journal=Reading%20Research%20Quarterly&amp;doi=10.1598%2FRRQ.43.4.2&amp;volume=43&amp;issue=4&amp;pages=336-354&amp;publication_year=2008&amp;author=Miller%2CJ&amp;author=Schwanenflugel%2CPJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR38">Morris, D., &amp; Perney, J. (2018). Using a sight word measure to predict reading fluency problems in grades 1 to 3. <i>Reading &amp; Writing Quarterly,</i> <i>34</i>(4), 338348. <a href="https://doi.org/10.1080/10573569.2018.1446857" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1080/10573569.2018.1446857">https://doi.org/10.1080/10573569.2018.1446857</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/10573569.2018.1446857" data-track-item_id="10.1080/10573569.2018.1446857" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F10573569.2018.1446857" aria-label="Article reference 38" data-doi="10.1080/10573569.2018.1446857">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20a%20sight%20word%20measure%20to%20predict%20reading%20fluency%20problems%20in%20grades%201%20to%203&amp;journal=Reading%20%26%20Writing%20Quarterly&amp;doi=10.1080%2F10573569.2018.1446857&amp;volume=34&amp;issue=4&amp;pages=338-348&amp;publication_year=2018&amp;author=Morris%2CD&amp;author=Perney%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR39">Morrison, T. G., &amp; Wilcox, B. (2020). Assessing expressive oral reading fluency. <i>Education Sciences,</i> <i>10</i>(3), 59. <a href="https://doi.org/10.3390/educsci10030059" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.3390/educsci10030059">https://doi.org/10.3390/educsci10030059</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3390/educsci10030059" data-track-item_id="10.3390/educsci10030059" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3390%2Feducsci10030059" aria-label="Article reference 39" data-doi="10.3390/educsci10030059">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Assessing%20expressive%20oral%20reading%20fluency&amp;journal=Education%20Sciences&amp;doi=10.3390%2Feducsci10030059&amp;volume=10&amp;issue=3&amp;publication_year=2020&amp;author=Morrison%2CTG&amp;author=Wilcox%2CB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR40">Mostow, J., Aist, G., Burkhead, P., Corbett, A., Cuneo, A., Eitelman, S., &amp; Tobin, B. (2003). Evaluation of an automated reading tutor that listens: comparison to human tutoring and classroom instruction. <i>Journal of Educational Computing Research,</i> <i>29</i>, 61117. <a href="https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.2190/06AX-QW99-EQ5G-RDCF">https://doi.org/10.2190/06AX-QW99-EQ5G-RDCF</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2190/06AX-QW99-EQ5G-RDCF" data-track-item_id="10.2190/06AX-QW99-EQ5G-RDCF" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.2190%2F06AX-QW99-EQ5G-RDCF" aria-label="Article reference 40" data-doi="10.2190/06AX-QW99-EQ5G-RDCF">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20an%20automated%20reading%20tutor%20that%20listens%3A%20Comparison%20to%20human%20tutoring%20and%20classroom%20instruction&amp;journal=Journal%20of%20Educational%20Computing%20Research&amp;doi=10.2190%2F06AX-QW99-EQ5G-RDCF&amp;volume=29&amp;pages=61-117&amp;publication_year=2003&amp;author=Mostow%2CJ&amp;author=Aist%2CG&amp;author=Burkhead%2CP&amp;author=Corbett%2CA&amp;author=Cuneo%2CA&amp;author=Eitelman%2CS&amp;author=Tobin%2CB">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR41">Mullis, I. V. S., von Davier, M., Foy, P., Fishbein, B., Reynolds, K. A., &amp; Wry, E. (2023).<i>PIRLS 2021 International Results in Reading</i>.Boston College, TIMSS &amp; PIRLS International Study Center.<a href="https://doi.org/10.6017/lse.tpisc.tr2103.kb5342" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.6017/lse.tpisc.tr2103.kb5342">https://doi.org/10.6017/lse.tpisc.tr2103.kb5342</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR42">Perfetti, C., &amp; Stafura, J. (2014). Word knowledge in a theory of reading comprehension. <i>Scientific Studies of Reading,</i> <i>18</i>(1), 2237. <a href="https://doi.org/10.1080/10888438.2013.827687" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1080/10888438.2013.827687">https://doi.org/10.1080/10888438.2013.827687</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/10888438.2013.827687" data-track-item_id="10.1080/10888438.2013.827687" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F10888438.2013.827687" aria-label="Article reference 42" data-doi="10.1080/10888438.2013.827687">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Word%20knowledge%20in%20a%20theory%20of%20reading%20comprehension&amp;journal=Scientific%20Studies%20of%20Reading&amp;doi=10.1080%2F10888438.2013.827687&amp;volume=18&amp;issue=1&amp;pages=22-37&amp;publication_year=2014&amp;author=Perfetti%2CC&amp;author=Stafura%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR43">Perfetti, C. (1985). <i>Reading ability.</i> New York: Oxford University Press</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR44">Pikulski, J. J., &amp; Chard, D. J. (2005). Fluency: bridge between decoding comprehension. <i>The Reading Teacher,</i> <i>58</i>(6), 510519. <a href="https://doi.org/10.1598/RT.58.6.2" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1598/RT.58.6.2">https://doi.org/10.1598/RT.58.6.2</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1598/RT.58.6.2" data-track-item_id="10.1598/RT.58.6.2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1598%2FRT.58.6.2" aria-label="Article reference 44" data-doi="10.1598/RT.58.6.2">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Fluency%3A%20Bridge%20between%20decoding%20comprehension&amp;journal=The%20Reading%20Teacher&amp;doi=10.1598%2FRT.58.6.2&amp;volume=58&amp;issue=6&amp;pages=510-519&amp;publication_year=2005&amp;author=Pikulski%2CJJ&amp;author=Chard%2CDJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR45">Posit team (2023). RStudio: Integrated Development Environment for R, version 4.3.1. [Computer software] Posit Software, PBC, Boston, MA. <a href="http://www.posit.co/" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="http://www.posit.co/">http://www.posit.co/</a>.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR46">Proena, J., Lopes, C., Tjalve, M., Stolcke, A., Candeias, S., &amp; Perdigo, F. (2017). Automatic evaluation of reading aloud performance in children. <i>Speech Communication,</i> <i>94</i>, 114. <a href="https://doi.org/10.1016/j.specom.2017.08.006" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1016/j.specom.2017.08.006">https://doi.org/10.1016/j.specom.2017.08.006</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.specom.2017.08.006" data-track-item_id="10.1016/j.specom.2017.08.006" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.specom.2017.08.006" aria-label="Article reference 46" data-doi="10.1016/j.specom.2017.08.006">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20evaluation%20of%20reading%20aloud%20performance%20in%20children&amp;journal=Speech%20Communication&amp;doi=10.1016%2Fj.specom.2017.08.006&amp;volume=94&amp;pages=1-14&amp;publication_year=2017&amp;author=Proen%C3%A7a%2CJ&amp;author=Lopes%2CC&amp;author=Tjalve%2CM&amp;author=Stolcke%2CA&amp;author=Candeias%2CS&amp;author=Perdig%C3%A3o%2CF">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR47">Proena, J., Celorico, D., Candeias, S., Lopes, C., &amp; Perdigo, F. (2015). <i>Children's Reading Aloud Performance: A Database and Automatic Detection of Disfluencies.</i> INTERSPEECH 2015: Dresden, Germany. <a href="https://doi.org/10.21437/Interspeech.2015-382" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.21437/Interspeech.2015-382">https://doi.org/10.21437/Interspeech.2015-382</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR48">Reeder, K., Shapiro, J., &amp; Wakefield, J. (2007). <i>The effectiveness of speech recognition technology in promoting reading proficiency and attitudes for Canadian immigrant children</i>. Proceedings of the 9th European Conference on Reading</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR49">Reutzel, D. R., &amp; Hollingsworth, P. M. (1993). Effects of fluency training on second graders reading comprehension. <i>Journal of Educational Research,</i> <i>86</i>, 325331. <a href="https://doi.org/10.1080/00220671.1993.9941225" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1080/00220671.1993.9941225">https://doi.org/10.1080/00220671.1993.9941225</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/00220671.1993.9941225" data-track-item_id="10.1080/00220671.1993.9941225" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F00220671.1993.9941225" aria-label="Article reference 49" data-doi="10.1080/00220671.1993.9941225">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20fluency%20training%20on%20second%20graders%20reading%20comprehension&amp;journal=Journal%20of%20Educational%20Research&amp;doi=10.1080%2F00220671.1993.9941225&amp;volume=86&amp;pages=325-331&amp;publication_year=1993&amp;author=Reutzel%2CDR&amp;author=Hollingsworth%2CPM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR50">Rokade, A. A. (2018).<i>Automated Grading System Using Natural Language Processing.</i>International Conference on Inventive Communication and Computational Technologies 2018: Coimbatore, India<i>.</i> <a href="https://doi.org/10.1109/ICICCT.2018.8473170" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1109/ICICCT.2018.8473170">https://doi.org/10.1109/ICICCT.2018.8473170</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR51">Sabu, K., &amp; Rao, P. (2018). Automatic assessment of childrens oral reading using speech recognition and prosody modeling. <i>CSI Transactions on ICT,</i> <i>6</i>, 221225. <a href="https://doi.org/10.1007/s40012-018-0202-3" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1007/s40012-018-0202-3">https://doi.org/10.1007/s40012-018-0202-3</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s40012-018-0202-3" data-track-item_id="10.1007/s40012-018-0202-3" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s40012-018-0202-3" aria-label="Article reference 51" data-doi="10.1007/s40012-018-0202-3">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20assessment%20of%20children%E2%80%99s%20oral%20reading%20using%20speech%20recognition%20and%20prosody%20modeling&amp;journal=CSI%20Transactions%20on%20ICT&amp;doi=10.1007%2Fs40012-018-0202-3&amp;volume=6&amp;pages=221-225&amp;publication_year=2018&amp;author=Sabu%2CK&amp;author=Rao%2CP">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR52">Seymour, P. H. K., Aro, M., Erskine, J. M., COST Action A8 network. (2003). Foundation literacy acquisition in European orthographies. <i>British Journal of Psychology,</i> <i>94</i>, 143174. <a href="https://doi.org/10.1348/000712603321661859" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1348/000712603321661859">https://doi.org/10.1348/000712603321661859</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1348/000712603321661859" data-track-item_id="10.1348/000712603321661859" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1348%2F000712603321661859" aria-label="Article reference 52" data-doi="10.1348/000712603321661859">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Foundation%20literacy%20acquisition%20in%20European%20orthographies&amp;journal=British%20Journal%20of%20Psychology&amp;doi=10.1348%2F000712603321661859&amp;volume=94&amp;pages=143-174&amp;publication_year=2003&amp;author=Seymour%2CPHK&amp;author=Aro%2CM&amp;author=Erskine%2CJM">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR53">Share, D. L. (2008). On the Anglocentricities of current reading research and practice: the perils of overreliance on an" outlier" orthography. <i>Psychological Bulletin,</i> <i>134</i>(4), 584615. <a href="https://doi.org/10.1037/0033-2909.134.4.584" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1037/0033-2909.134.4.584">https://doi.org/10.1037/0033-2909.134.4.584</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0033-2909.134.4.584" data-track-item_id="10.1037/0033-2909.134.4.584" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-2909.134.4.584" aria-label="Article reference 53" data-doi="10.1037/0033-2909.134.4.584">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20Anglocentricities%20of%20current%20reading%20research%20and%20practice%3A%20The%20perils%20of%20overreliance%20on%20an%22%20outlier%22%20orthography&amp;journal=Psychological%20Bulletin&amp;doi=10.1037%2F0033-2909.134.4.584&amp;volume=134&amp;issue=4&amp;pages=584-615&amp;publication_year=2008&amp;author=Share%2CDL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR54">Silva, W. A., Carchedi, L. C., Junior, J. G., de Souza, J. V., Barrere, E., &amp; de Souza, J. F. (2021). A framework for large-scale automatic fluency assessment. <i>International Journal of Distance Education Technologies,</i> <i>19</i>(3), 7088. <a href="https://doi.org/10.4018/IJDET.2021070105" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.4018/IJDET.2021070105">https://doi.org/10.4018/IJDET.2021070105</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.4018/IJDET.2021070105" data-track-item_id="10.4018/IJDET.2021070105" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.4018%2FIJDET.2021070105" aria-label="Article reference 54" data-doi="10.4018/IJDET.2021070105">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20framework%20for%20large-scale%20automatic%20fluency%20assessment&amp;journal=International%20Journal%20of%20Distance%20Education%20Technologies&amp;doi=10.4018%2FIJDET.2021070105&amp;volume=19&amp;issue=3&amp;pages=70-88&amp;publication_year=2021&amp;author=Silva%2CWA&amp;author=Carchedi%2CLC&amp;author=Junior%2CJG&amp;author=Souza%2CJV&amp;author=Barrere%2CE&amp;author=Souza%2CJF">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR55">Smith, A. C., Monaghan, P., &amp; Huettig, F. (2021). The effect of orthographic systems on the developing reading system: typological and computational analyses. <i>Psychological Review,</i> <i>128</i>(1), 125159. <a href="https://doi.org/10.1037/rev0000257" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1037/rev0000257">https://doi.org/10.1037/rev0000257</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/rev0000257" data-track-item_id="10.1037/rev0000257" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2Frev0000257" aria-label="Article reference 55" data-doi="10.1037/rev0000257">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20orthographic%20systems%20on%20the%20developing%20reading%20system%3A%20Typological%20and%20computational%20analyses&amp;journal=Psychological%20Review&amp;doi=10.1037%2Frev0000257&amp;volume=128&amp;issue=1&amp;pages=125-159&amp;publication_year=2021&amp;author=Smith%2CAC&amp;author=Monaghan%2CP&amp;author=Huettig%2CF">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR56">Torgesen, J. K., Wagner, R., &amp; Rashotte, C. (1997). <i>Test of word reading efficiency</i>. Austin, TX: PRO-ED</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR57">Toulmin, S. E. (2003). <i>The uses of argument</i>. Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511840005" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1017/CBO9780511840005">https://doi.org/10.1017/CBO9780511840005</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR58">University of Oregon (2020). <i>8th Edition of Dynamic Indicators of Basic Early Literacy Skills (DIBELS): Administration and Scoring Guide</i>. Eugene, OR: University of Oregon. <a href="https://dibels.uoregon.edu" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://dibels.uoregon.edu">https://dibels.uoregon.edu</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR59">van der Velde, M. E., Molenaar, B., Veldkamp, B. P., Feskens, R. C. W., &amp; Keuning, J. (2024a). What do they say? Assessment of oral reading fluency in early primary school children: A scoping review.<i>International Journal of Educational Research, 128,</i> 102444. <a href="https://doi.org/10.1016/j.ijer.2024.102444" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1016/j.ijer.2024.102444">https://doi.org/10.1016/j.ijer.2024.102444</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR60">Van der Velde, M. E., Veldkamp, B. P., Keuning, J., Feskens, R. C. W., Swart, N. M., Harmsen, W. N. (2024b). The framework and development of SERDA: Speech enabled reading fluency assessment for Dutch. In Ranelovi B., Karali E., Aleksi K., uki D. (Eds.), <i>E-testing and computer-based assessment. CIDREE Yearbook 2024</i> (pp. 99123). CIDREE. <a href="https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf">https://www.cidree.org/wp-content/uploads/2024/11/cidree_yearbook-2024.pdf</a></p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR61">Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., Vloedgraven, J. &amp; De Wijs, A. (2018a). <i>Wetenschappelijke verantwoording DMT [Scientific Justification DMT]</i>. Cito: Arnhem</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR62">Van Til, A., Kamphuis, F., Keuning, J., Gijsel, M., &amp; De Wijs, A. (2018b). <i>Wetenschappelijke verantwoording AVI [Scientific Justification AVI]</i>. Cito: Arnhem.</p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR63">van der Linden, W. J. (2007). A hierarchical framework for modeling speed and accuracy on test items. <i>Psychometrika,</i> <i>72</i>, 287308. <a href="https://doi.org/10.1007/s11336-006-1478-z" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1007/s11336-006-1478-z">https://doi.org/10.1007/s11336-006-1478-z</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="noopener" data-track-label="10.1007/s11336-006-1478-z" data-track-item_id="10.1007/s11336-006-1478-z" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s11336-006-1478-z" aria-label="Article reference 63" data-doi="10.1007/s11336-006-1478-z">Article</a>
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="mathscinet reference" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2361958" aria-label="MathSciNet reference 63">MathSciNet</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20Hierarchical%20Framework%20for%20Modeling%20Speed%20and%20Accuracy%20on%20Test%20Items&amp;journal=Psychometrika&amp;doi=10.1007%2Fs11336-006-1478-z&amp;volume=72&amp;pages=287-308&amp;publication_year=2007&amp;author=Linden%2CWJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR64">Veenendaal, N. J., Groen, M. A., &amp; Verhoeven, L. (2015). What speech text reading fluency can reveal about reading comprehension. <i>Journal of Research in Reading,</i> <i>38</i>(3), 213225. <a href="https://doi.org/10.1111/1467-9817.12024" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1111/1467-9817.12024">https://doi.org/10.1111/1467-9817.12024</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1111/1467-9817.12024" data-track-item_id="10.1111/1467-9817.12024" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1111%2F1467-9817.12024" aria-label="Article reference 64" data-doi="10.1111/1467-9817.12024">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20speech%20text%20reading%20fluency%20can%20reveal%20about%20reading%20comprehension&amp;journal=Journal%20of%20Research%20in%20Reading&amp;doi=10.1111%2F1467-9817.12024&amp;volume=38&amp;issue=3&amp;pages=213-225&amp;publication_year=2015&amp;author=Veenendaal%2CNJ&amp;author=Groen%2CMA&amp;author=Verhoeven%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR65">Veenendaal, N. J., Groen, M. A., &amp; Verhoeven, L. (2016). Bidirectional relations between text reading prosody and reading comprehension in the upper primary school grades: a longitudinal perspective. <i>Scientific Studies of Reading.,</i> <i>20</i>(3), 189202. <a href="https://doi.org/10.1080/10888438.2015.1128939" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1080/10888438.2015.1128939">https://doi.org/10.1080/10888438.2015.1128939</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/10888438.2015.1128939" data-track-item_id="10.1080/10888438.2015.1128939" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F10888438.2015.1128939" aria-label="Article reference 65" data-doi="10.1080/10888438.2015.1128939">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Bidirectional%20Relations%20between%20Text%20Reading%20Prosody%20and%20Reading%20Comprehension%20in%20the%20Upper%20Primary%20School%20Grades%3A%20A%20Longitudinal%20Perspective&amp;journal=Scientific%20Studies%20of%20Reading.&amp;doi=10.1080%2F10888438.2015.1128939&amp;volume=20&amp;issue=3&amp;pages=189-202&amp;publication_year=2016&amp;author=Veenendaal%2CNJ&amp;author=Groen%2CMA&amp;author=Verhoeven%2CL">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR66">Verhoeven, L., &amp; Van Leeuwe, J. (2009). Modeling the growth of word-decoding skills: evidence from Dutch. <i>Scientific Studies of Reading,</i> <i>13</i>(3), 205223. <a href="https://doi.org/10.1080/10888430902851356" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1080/10888430902851356">https://doi.org/10.1080/10888430902851356</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/10888430902851356" data-track-item_id="10.1080/10888430902851356" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F10888430902851356" aria-label="Article reference 66" data-doi="10.1080/10888430902851356">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=Modeling%20the%20Growth%20of%20Word-Decoding%20Skills%3A%20Evidence%20From%20Dutch&amp;journal=Scientific%20Studies%20of%20Reading&amp;doi=10.1080%2F10888430902851356&amp;volume=13&amp;issue=3&amp;pages=205-223&amp;publication_year=2009&amp;author=Verhoeven%2CL&amp;author=Leeuwe%2CJ">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR67">Wei, X., Cucchiarini, C., van Hout, R. W. N. M., &amp; Strik, H. (2022). Automatic speech recognition and pronunciation error detection of Dutch non-native speech: cumulating speech resources in a pluricentric language. <i>Speech Communication,</i> <i>144</i>, 19. <a href="https://doi.org/10.1016/j.specom.2022.08.004" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1016/j.specom.2022.08.004">https://doi.org/10.1016/j.specom.2022.08.004</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.specom.2022.08.004" data-track-item_id="10.1016/j.specom.2022.08.004" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.specom.2022.08.004" aria-label="Article reference 67" data-doi="10.1016/j.specom.2022.08.004">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20speech%20recognition%20and%20pronunciation%20error%20detection%20of%20Dutch%20non-native%20speech%3A%20Cumulating%20speech%20resources%20in%20a%20pluricentric%20language&amp;journal=Speech%20Communication&amp;doi=10.1016%2Fj.specom.2022.08.004&amp;volume=144&amp;pages=1-9&amp;publication_year=2022&amp;author=Wei%2CX&amp;author=Cucchiarini%2CC&amp;author=Hout%2CRWNM&amp;author=Strik%2CH">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR68">Wimmer, H., &amp; Goswami, U. (1994). The influence of orthographic consistency on reading development: word recognition in English and German children. <i>Cognition,</i> <i>51</i>, 91103. <a href="https://doi.org/10.1016/0010-0277(94)90010-8" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1016/0010-0277(94)90010-8">https://doi.org/10.1016/0010-0277(94)90010-8</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0010-0277(94)90010-8" data-track-item_id="10.1016/0010-0277(94)90010-8" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0010-0277%2894%2990010-8" aria-label="Article reference 68" data-doi="10.1016/0010-0277(94)90010-8">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20influence%20of%20orthographic%20consistency%20on%20reading%20development%3A%20Word%20recognition%20in%20English%20and%20German%20children&amp;journal=Cognition&amp;doi=10.1016%2F0010-0277%2894%2990010-8&amp;volume=51&amp;pages=91-103&amp;publication_year=1994&amp;author=Wimmer%2CH&amp;author=Goswami%2CU">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR69">Wools, S., Eggen, T. J. H. M., &amp; Sanders, P. F. (2010). Evaluation of validity and validation by means of the argument-based approach. <i>Cadmo,</i> <i>18</i>(1), 6382. <a href="https://doi.org/10.3280/CAD2010-001007" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.3280/CAD2010-001007">https://doi.org/10.3280/CAD2010-001007</a></p><p class="c-article-references__links u-hide-print"><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3280/CAD2010-001007" data-track-item_id="10.3280/CAD2010-001007" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3280%2FCAD2010-001007" aria-label="Article reference 69" data-doi="10.3280/CAD2010-001007">Article</a>
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 69" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20validity%20and%20validation%20by%20means%20of%20the%20argument-based%20approach&amp;journal=Cadmo&amp;doi=10.3280%2FCAD2010-001007&amp;volume=18&amp;issue=1&amp;pages=63-82&amp;publication_year=2010&amp;author=Wools%2CS&amp;author=Eggen%2CTJHM&amp;author=Sanders%2CPF">
                    Google Scholar</a>
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item"><p class="c-article-references__text" id="ref-CR70">Zwijsen Educatieve Uitgeverij. (2023). <i>Veilig leren lezen: KIM-versie [Learning to read safely: KIM-version]</i>. Zwijsen</p></li></ul><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/s40593-025-00480-y?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div class="c-article-section" id="Ack1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Ack1">Acknowledgements</h2><div class="c-article-section__content" id="Ack1-content"><p>The authors would like to thoroughly thank Helmer Strik and Catia Cucchiarini for their insightful contributions to the project, and throughout the funding acquisition process. In addition, we would like to thank Marlies van der Velde, Bjorn de Nooijer and Bram Groenhof for their contributions during data collection and the process of data annotation.</p></div></div></section><section data-title="Funding"><div class="c-article-section" id="Fun-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Fun">Funding</h2><div class="c-article-section__content" id="Fun-content"><p>This work was supported by the Dutch Research Council (NWO) under grant NWO 406.20.TW.009.</p></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Cognition, Data and Education Section, Faculty of BMS, University of Twente, De Zul 10, Enschede, NJ, 7522, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Max van der Velde,Bernard P. Veldkamp&amp;Remco Feskens</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">CitoLab, Cito, Arnhem, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Max van der Velde,Remco Feskens&amp;Jos Keuning</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">Expertisecentrum Nederlands, Nijmegen, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Nicole Swart</p></li><li id="Aff4"><p class="c-article-author-affiliation__address">Centre for Language Studies, Radboud University, Nijmegen, The Netherlands</p><p class="c-article-author-affiliation__authors-list">Wieke Harmsen</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Max-Velde-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Max van der Velde</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Max%20van%20der%20Velde" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Max%20van%20der%20Velde" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Max%20van%20der%20Velde%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Wieke-Harmsen-Aff4"><span class="c-article-authors-search__title u-h3 js-search-name">Wieke Harmsen</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Wieke%20Harmsen" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Wieke%20Harmsen" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Wieke%20Harmsen%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Bernard_P_-Veldkamp-Aff1"><span class="c-article-authors-search__title u-h3 js-search-name">Bernard P. Veldkamp</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Bernard%20P.%20Veldkamp" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Bernard%20P.%20Veldkamp" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Bernard%20P.%20Veldkamp%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Remco-Feskens-Aff1-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Remco Feskens</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Remco%20Feskens" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Remco%20Feskens" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Remco%20Feskens%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Jos-Keuning-Aff2"><span class="c-article-authors-search__title u-h3 js-search-name">Jos Keuning</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Jos%20Keuning" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jos%20Keuning" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jos%20Keuning%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Nicole-Swart-Aff3"><span class="c-article-authors-search__title u-h3 js-search-name">Nicole Swart</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?sortBy=newestFirst&amp;dc.creator=Nicole%20Swart" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text"><span class="c-article-authors-search__links-text">Search author on:</span><span class="c-article-identifiers"><a class="c-article-identifiers__item" href="https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nicole%20Swart" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"></span><a class="c-article-identifiers__item" href="https://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nicole%20Swart%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="contributions">Contributions</h3><p>The conception and design of the study were constructed by all authors. Data collection, methodology and analysis were primarily conducted by M.V and W.H. The first draft was constructed by M.V, and all authors provided feedback, leading to the final version of the manuscript. Fund acquisition was primarily conducted by B.V, R.F, J.K and N.S.</p><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" aria-label="email Max van der Velde" href="mailto:m.e.vandervelde@utwente.nl">Max van der Velde</a>.</p></div></div></section><section data-title="Ethics declarations"><div class="c-article-section" id="ethics-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="ethics">Ethics declarations</h2><div class="c-article-section__content" id="ethics-content">
            
            
              <h3 class="c-article__sub-heading" id="FPar7">Ethics Statement</h3>
              <p>All procedures performed during the study satisfy the standards for ethical conduct of scientific research, as assessed on 22 May 2022 by the Ethics Committee of the Faculty of Behavioral, Management and Social Sciences (BMS) of the University of Twente, domain Humanities and Social Sciences (HSS). This Committee subscribes to the Dutch Code of Ethics for research in the social and behavioural sciences involving human participants, which can be consulted here: <a href="https://nethics.nl/gedragscode-ethical-code">https://nethics.nl/gedragscode-ethical-code</a>. As data was obtained from children, informed consent was obtained from both the parents of the child, and the primary school the children attended.</p>
            
            
              <h3 class="c-article__sub-heading" id="FPar8">Informed Consent</h3>
              <p>Participation was voluntary, and the parents and schools of all participants provided informed consent before participation. Participants were free to retract consent.</p>
            
            
              <h3 class="c-article__sub-heading" id="FPar9">Competing interests</h3>
              <p>The authors declare no competing interests.</p>
            
          </div></div></section><section data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publishers Note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title="Supplementary Information"><div class="c-article-section" id="Sec25-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec25">Supplementary Information</h2><div class="c-article-section__content" id="Sec25-content"><div data-test="supplementary-info"><div id="figshareContainer" class="c-article-figshare-container" data-test="figshare-container"></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM1"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary material 1." href="https://static-content.springer.com/esm/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_MOESM1_ESM.docx" data-supp-info-image="">Supplementary Material 1.</a></h3></div><div class="c-article-supplementary__item" data-test="supp-item" id="MOESM2"><h3 class="c-article-supplementary__title u-h3"><a class="print-link" data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary material 2." href="https://static-content.springer.com/esm/art%3A10.1007%2Fs40593-025-00480-y/MediaObjects/40593_2025_480_MOESM2_ESM.docx" data-supp-info-image="">Supplementary Material 2.</a></h3></div></div></div></div></section><section data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
              <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
            <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Speech%20Enabled%20Reading%20Fluency%20Assessment%3A%20a%20Validation%20Study&amp;author=Max%20van%20der%20Velde%20et%20al&amp;contentID=10.1007%2Fs40593-025-00480-y&amp;copyright=The%20Author%28s%29&amp;publication=1560-4292&amp;publicationDate=2025-05-14&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s40593-025-00480-y" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s40593-025-00480-y" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">van der Velde, M., Harmsen, W., Veldkamp, B.P. <i>et al.</i> Speech Enabled Reading Fluency Assessment: a Validation Study.
                    <i>Int J Artif Intell Educ</i>  (2025). https://doi.org/10.1007/s40593-025-00480-y</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1007/s40593-025-00480-y?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2025-04-27">27 April 2025</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2025-05-14">14 May 2025</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Version of record<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2025-05-14">14 May 2025</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/s40593-025-00480-y</span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this article</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" type="button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" type="button" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy shareable link to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                            Provided by the Springer Nature SharedIt content-sharing initiative
                        </p></div></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span><a href="/search?query=Validation&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Validation</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Reading&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Reading</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Fluency&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Fluency</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Assessment&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Assessment</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Instrument&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Instrument</a></span></li><li class="c-article-subject-list__subject"><span><a href="/search?query=Automatic&amp;facet-discipline=&#34;Computer%20Science&#34;" data-track="click" data-track-action="view keyword" data-track-label="link">Automatic</a></span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>

                    
    <div id="researcher-profile-container">
        <h3>Profiles</h3>
        <ol>
            
                <li data-test="researcher-profile-data"  data-profile-index="0">
                    <span data-test="researcher-profile-name">Max van der Velde</span>
                    <a class="js-cta-popup-link c-article-authors-search__cta-link" href="/researchers/71293253SN" data-track="click_view_profile" data-test="researcher-profile-link">
                        <span class="eds-c-button eds-c-button--primary">
                            <svg class="c-article-authors-search__cta-icon" aria-hidden="true" focusable="false" width="24" height="24">
                                <use xlink:href="#icon-eds-i-user-single-medium"></use>
                            </svg><span>View author profile</span>
                        </span>
                    </a>
                </li>
            
        </ol>
    </div>


                    
                </div>
            </main>

            <div class="c-article-sidebar u-text-sm u-hide-print l-with-sidebar__sidebar" id="sidebar"
                 data-container-type="reading-companion" data-track-component="reading companion">
                <aside aria-label="reading companion">
                    

                    
                        
    <div class="app-card-service" data-test="article-checklist-banner">
        <div>
            <a class="app-card-service__link" data-track="click_presubmission_checklist" data-track-context="article page top of reading companion" data-track-category="pre-submission-checklist" data-track-action="clicked article page checklist banner test 2 old version" data-track-label="link" href="https://beta.springernature.com/pre-submission?journalId=40593"
            data-test="article-checklist-banner-link">
            <span class="app-card-service__link-text">Use our pre-submission checklist</span>
            <svg class="app-card-service__link-icon" aria-hidden="true" focusable="false"><use xlink:href="#icon-eds-i-arrow-right-small"></use></svg>
            </a>
            <p class="app-card-service__description">Avoid common mistakes on your manuscript.</p>
        </div>
        <div class="app-card-service__icon-container">
            <svg class="app-card-service__icon" aria-hidden="true" focusable="false">
                <use xlink:href="#icon-eds-i-clipboard-check-medium"></use>
            </svg>
        </div>
    </div>

                    

                    
                        <div data-test="collections">
                            
    

                        </div>
                    

                    <div data-test="editorial-summary">
                        
                    </div>

                    <div class="c-reading-companion">
                        <div class="c-reading-companion__sticky" data-component="reading-companion-sticky"
                             data-test="reading-companion-sticky">
                            
                            
                                
                                    
                                
                            
                            <div
                                class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active"
                                id="tabpanel-sections">
                                <div class="u-lazy-ad-wrapper u-mt-16 u-hide"
                                     data-component-mpu><div class="c-ad c-ad--300x250">
    <div class="c-ad__inner">
        <p class="c-ad__label">Advertisement</p>
        <div id="div-gpt-ad-MPU1"
             class="div-gpt-ad grade-c-hide"
             data-pa11y-ignore
             data-gpt
             data-gpt-unitpath="/270604982/springerlink/40593/article"
             data-gpt-sizes="300x250" data-test="MPU1-ad"
             data-gpt-targeting="pos=MPU1;articleid=s40593-025-00480-y;">
        </div>
    </div>
</div>

<script>
    window.SN = window.SN || {};
    window.SN.libs = window.SN.libs || {};
    window.SN.libs.ads = window.SN.libs.ads || {};
    window.SN.libs.ads.slotConfig = window.SN.libs.ads.slotConfig || {};
    window.SN.libs.ads.slotConfig['MPU1'] = {
        'pos': 'MPU1',
        'type': 'MPU1',
    };
    window.SN.libs.ads.slotConfig['unitPath'] = '/270604982/springerlink/40593/article';
</script>

</div>
                            </div>
                            <div
                                class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width"
                                id="tabpanel-figures"></div>
                            <div
                                class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width"
                                id="tabpanel-references"></div>
                        </div>
                    </div>
                </aside>
            </div>
        </div>
    </article>
    
    <div class="app-elements" data-test="footer">
    <nav aria-label="expander navigation">



    
        <div class="eds-c-header__expander eds-c-header__expander--search" id="eds-c-header-popup-search">
            <h2 class="eds-c-header__heading">Search</h2>
            <div class="u-container">
                <search class="eds-c-header__search" role="search" aria-label="Search from the header">
                    <form method="GET" action="//link.springer.com/search"
                        
                            data-test="header-search"
                        
                            data-track="search"
                        
                            data-track-context="search from header"
                        
                            data-track-action="submit search form"
                        
                            data-track-category="unified header"
                        
                            data-track-label="form"
                        
					>
                        <label for="eds-c-header-search" class="eds-c-header__search-label">Search by keyword or author</label>
                        <div class="eds-c-header__search-container">
                            <input id="eds-c-header-search" class="eds-c-header__search-input" autocomplete="off" name="query" type="search" value="" required>
                            <button class="eds-c-header__search-button" type="submit">
                                <svg class="eds-c-header__icon" aria-hidden="true" focusable="false">
                                    <use xlink:href="#icon-eds-i-search-medium"></use>
                                </svg>
                                <span class="u-visually-hidden">Search</span>
                            </button>
                        </div>
                    </form>
                </search>
            </div>
        </div>
    


<div class="eds-c-header__expander eds-c-header__expander--menu" id="eds-c-header-nav">
    
        <h2 class="eds-c-header__heading">Navigation</h2>
        <ul class="eds-c-header__list">
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://link.springer.com/journals/"
                        
                            data-track="nav_find_a_journal"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click find a journal"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Find a journal
                    </a>
                </li>
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://www.springernature.com/gp/authors"
                        
                            data-track="nav_how_to_publish"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click publish with us link"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Publish with us
                    </a>
                </li>
            
                <li class="eds-c-header__list-item">
                   <a class="eds-c-header__link" href="https://link.springernature.com/home/"
                        
                            data-track="nav_track_your_research"
                        
                            data-track-context="unified header"
                        
                            data-track-action="click track your research"
                        
                            data-track-category="unified header"
                        
                            data-track-label="link"
                        
					>
                        Track your research
                    </a>
                </li>
            
        </ul>
    
</div>
</nav>
    <footer >
	<div class="eds-c-footer"
		
	>
		
			
				<div class="eds-c-footer__container">
		<div class="eds-c-footer__grid eds-c-footer__group--separator">
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Discover content</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/journals/a/1" data-track="nav_journals_a_z" data-track-action="journals a-z" data-track-context="unified footer" data-track-label="link">Journals A-Z</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/books/a/1" data-track="nav_books_a_z" data-track-action="books a-z" data-track-context="unified footer" data-track-label="link">Books A-Z</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Publish with us</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/journals" data-track="nav_journal_finder" data-track-action="journal finder" data-track-context="unified footer" data-track-label="link">Journal finder</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/authors" data-track="nav_publish_your_research" data-track-action="publish your research" data-track-context="unified footer" data-track-label="link">Publish your research</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://authorservices.springernature.com/go/sn/?utm_source&#x3D;SNLinkfooter&amp;utm_medium&#x3D;Web&amp;utm_campaign&#x3D;SNReferral" data-track="nav_language_editing" data-track-action="language editing" data-track-context="unified footer" data-track-label="link">Language editing</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research" data-track="nav_open_access_publishing" data-track-action="open access publishing" data-track-context="unified footer" data-track-label="link">Open access publishing</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Products and services</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/products" data-track="nav_our_products" data-track-action="our products" data-track-context="unified footer" data-track-label="link">Our products</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/librarians" data-track="nav_librarians" data-track-action="librarians" data-track-context="unified footer" data-track-label="link">Librarians</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/societies" data-track="nav_societies" data-track-action="societies" data-track-context="unified footer" data-track-label="link">Societies</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.springernature.com/gp/partners" data-track="nav_partners_and_advertisers" data-track-action="partners and advertisers" data-track-context="unified footer" data-track-label="link">Partners and advertisers</a></li>
					
				</ul>
			</div>
			
			<div class="eds-c-footer__group">
				<h3 class="eds-c-footer__heading">Our brands</h3>
				<ul class="eds-c-footer__list">
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/brands/springer" data-track="nav_imprint_Springer" data-track-action="Springer" data-track-context="unified footer" data-track-label="link">Springer</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.nature.com/" data-track="nav_imprint_Nature_Portfolio" data-track-action="Nature Portfolio" data-track-context="unified footer" data-track-label="link">Nature Portfolio</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/brands/bmc" data-track="nav_imprint_BMC" data-track-action="BMC" data-track-context="unified footer" data-track-label="link">BMC</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="/brands/palgrave" data-track="nav_imprint_Palgrave_Macmillan" data-track-action="Palgrave Macmillan" data-track-context="unified footer" data-track-label="link">Palgrave Macmillan</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://www.apress.com/" data-track="nav_imprint_Apress" data-track-action="Apress" data-track-context="unified footer" data-track-label="link">Apress</a></li>
					
						<li class="eds-c-footer__item"><a class="eds-c-footer__link" href="https://link.springer.com/brands/discover" data-track="nav_imprint_Discover" data-track-action="Discover" data-track-context="unified footer" data-track-label="link">Discover</a></li>
					
				</ul>
			</div>
			
		</div>
	</div>

		
		
		<div class="eds-c-footer__container">
	
		<nav aria-label="footer navigation">
			<ul class="eds-c-footer__links">
				
					<li class="eds-c-footer__item">
						
						
							<button class="eds-c-footer__link" data-cc-action="preferences"
								 data-track="dialog_manage_cookies" data-track-action="Manage cookies" data-track-context="unified footer" data-track-label="link"><span class="eds-c-footer__button-text">Your privacy choices/Manage cookies</span></button>
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://www.springernature.com/gp/legal/ccpa"
								 data-track="nav_california_privacy_statement" data-track-action="california privacy statement" data-track-context="unified footer" data-track-label="link">Your US state privacy rights</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/accessibility"
								 data-track="nav_accessibility_statement" data-track-action="accessibility statement" data-track-context="unified footer" data-track-label="link">Accessibility statement</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/termsandconditions"
								 data-track="nav_terms_and_conditions" data-track-action="terms and conditions" data-track-context="unified footer" data-track-label="link">Terms and conditions</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/privacystatement"
								 data-track="nav_privacy_policy" data-track-action="privacy policy" data-track-context="unified footer" data-track-label="link">Privacy policy</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://support.springernature.com/en/support/home"
								 data-track="nav_help_and_support" data-track-action="help and support" data-track-context="unified footer" data-track-label="link">Help and support</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://link.springer.com/legal-notice"
								 data-track="nav_legal_notice" data-track-action="legal notice" data-track-context="unified footer" data-track-label="link">Legal notice</a>
						
						
					</li>
				
					<li class="eds-c-footer__item">
						
							<a class="eds-c-footer__link" href="https://support.springernature.com/en/support/solutions/articles/6000255911-subscription-cancellations"
								 data-track-action="cancel contracts here">Cancel contracts here</a>
						
						
					</li>
				
			</ul>
		</nav>
	
	
		
			<div class="eds-c-footer__user">
				<p class="eds-c-footer__user-info">
					
					<span data-test="footer-user-ip">76.242.67.4</span>
				</p>
				<p class="eds-c-footer__user-info" data-test="footer-business-partners">Not affiliated</p>
			</div>
		
	
	
		<a href="https://www.springernature.com/" class="eds-c-footer__link">
			<img src="/oscar-static/images/logo-springernature-white-19dd4ba190.svg" alt="Springer Nature" loading="lazy" width="200" height="20"/>
		</a>
	
	<p class="eds-c-footer__legal" data-test="copyright">&copy; 2025 Springer Nature</p>
</div>

	</div>
</footer>
</div>


    </body>
</html>


